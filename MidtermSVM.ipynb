{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7508d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd7318",
   "metadata": {},
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a198d47b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = 'rps-split\\\\train'\n",
    "test_dir = 'rps-split\\\\test'\n",
    "val_dir = 'rps-split\\\\val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f59f357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531, 22500)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5d2fdbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22490</th>\n",
       "      <th>22491</th>\n",
       "      <th>22492</th>\n",
       "      <th>22493</th>\n",
       "      <th>22494</th>\n",
       "      <th>22495</th>\n",
       "      <th>22496</th>\n",
       "      <th>22497</th>\n",
       "      <th>22498</th>\n",
       "      <th>22499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282439</td>\n",
       "      <td>0.289924</td>\n",
       "      <td>0.293366</td>\n",
       "      <td>0.300145</td>\n",
       "      <td>0.303655</td>\n",
       "      <td>0.308242</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.317845</td>\n",
       "      <td>0.324846</td>\n",
       "      <td>0.325541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309310</td>\n",
       "      <td>0.307258</td>\n",
       "      <td>0.305002</td>\n",
       "      <td>0.299647</td>\n",
       "      <td>0.298464</td>\n",
       "      <td>0.293929</td>\n",
       "      <td>0.289883</td>\n",
       "      <td>0.283850</td>\n",
       "      <td>0.283182</td>\n",
       "      <td>0.269569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.299331</td>\n",
       "      <td>0.296886</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.296857</td>\n",
       "      <td>0.306606</td>\n",
       "      <td>0.309610</td>\n",
       "      <td>0.308545</td>\n",
       "      <td>0.304403</td>\n",
       "      <td>0.308739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>0.332998</td>\n",
       "      <td>0.328856</td>\n",
       "      <td>0.331649</td>\n",
       "      <td>0.324068</td>\n",
       "      <td>0.326655</td>\n",
       "      <td>0.321872</td>\n",
       "      <td>0.321227</td>\n",
       "      <td>0.318055</td>\n",
       "      <td>0.321791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.259973</td>\n",
       "      <td>0.268775</td>\n",
       "      <td>0.275280</td>\n",
       "      <td>0.280152</td>\n",
       "      <td>0.285039</td>\n",
       "      <td>0.285782</td>\n",
       "      <td>0.288814</td>\n",
       "      <td>0.292053</td>\n",
       "      <td>0.299367</td>\n",
       "      <td>0.303309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289264</td>\n",
       "      <td>0.288739</td>\n",
       "      <td>0.285866</td>\n",
       "      <td>0.280724</td>\n",
       "      <td>0.279225</td>\n",
       "      <td>0.273654</td>\n",
       "      <td>0.267650</td>\n",
       "      <td>0.263894</td>\n",
       "      <td>0.262009</td>\n",
       "      <td>0.252174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306726</td>\n",
       "      <td>0.303777</td>\n",
       "      <td>0.305048</td>\n",
       "      <td>0.305458</td>\n",
       "      <td>0.303881</td>\n",
       "      <td>0.309817</td>\n",
       "      <td>0.311885</td>\n",
       "      <td>0.309504</td>\n",
       "      <td>0.310891</td>\n",
       "      <td>0.314309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>0.337161</td>\n",
       "      <td>0.331765</td>\n",
       "      <td>0.335954</td>\n",
       "      <td>0.328828</td>\n",
       "      <td>0.325748</td>\n",
       "      <td>0.328762</td>\n",
       "      <td>0.326534</td>\n",
       "      <td>0.322945</td>\n",
       "      <td>0.324864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216188</td>\n",
       "      <td>0.223491</td>\n",
       "      <td>0.231423</td>\n",
       "      <td>0.240872</td>\n",
       "      <td>0.241220</td>\n",
       "      <td>0.249937</td>\n",
       "      <td>0.252278</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.261174</td>\n",
       "      <td>0.265196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>0.225911</td>\n",
       "      <td>0.219907</td>\n",
       "      <td>0.219417</td>\n",
       "      <td>0.212889</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.205186</td>\n",
       "      <td>0.201541</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>0.189999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.316758</td>\n",
       "      <td>0.319122</td>\n",
       "      <td>0.315090</td>\n",
       "      <td>0.317579</td>\n",
       "      <td>0.319337</td>\n",
       "      <td>0.326543</td>\n",
       "      <td>0.325820</td>\n",
       "      <td>0.322612</td>\n",
       "      <td>0.325771</td>\n",
       "      <td>0.332192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344872</td>\n",
       "      <td>0.343667</td>\n",
       "      <td>0.348252</td>\n",
       "      <td>0.339113</td>\n",
       "      <td>0.332841</td>\n",
       "      <td>0.333563</td>\n",
       "      <td>0.330319</td>\n",
       "      <td>0.335869</td>\n",
       "      <td>0.335691</td>\n",
       "      <td>0.332603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.382267</td>\n",
       "      <td>0.381571</td>\n",
       "      <td>0.378451</td>\n",
       "      <td>0.383468</td>\n",
       "      <td>0.384683</td>\n",
       "      <td>0.388388</td>\n",
       "      <td>0.387331</td>\n",
       "      <td>0.394883</td>\n",
       "      <td>0.393906</td>\n",
       "      <td>0.397792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425765</td>\n",
       "      <td>0.420005</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>0.420270</td>\n",
       "      <td>0.416993</td>\n",
       "      <td>0.414020</td>\n",
       "      <td>0.414914</td>\n",
       "      <td>0.414313</td>\n",
       "      <td>0.415321</td>\n",
       "      <td>0.415032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.293139</td>\n",
       "      <td>0.287507</td>\n",
       "      <td>0.286387</td>\n",
       "      <td>0.289640</td>\n",
       "      <td>0.288580</td>\n",
       "      <td>0.296019</td>\n",
       "      <td>0.298054</td>\n",
       "      <td>0.285896</td>\n",
       "      <td>0.290841</td>\n",
       "      <td>0.299751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316646</td>\n",
       "      <td>0.314835</td>\n",
       "      <td>0.314268</td>\n",
       "      <td>0.311509</td>\n",
       "      <td>0.305610</td>\n",
       "      <td>0.309481</td>\n",
       "      <td>0.307940</td>\n",
       "      <td>0.304920</td>\n",
       "      <td>0.302529</td>\n",
       "      <td>0.301563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.304618</td>\n",
       "      <td>0.297201</td>\n",
       "      <td>0.304142</td>\n",
       "      <td>0.305809</td>\n",
       "      <td>0.306728</td>\n",
       "      <td>0.308514</td>\n",
       "      <td>0.317587</td>\n",
       "      <td>0.312711</td>\n",
       "      <td>0.313207</td>\n",
       "      <td>0.312118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332991</td>\n",
       "      <td>0.327786</td>\n",
       "      <td>0.325019</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.324487</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.321537</td>\n",
       "      <td>0.317153</td>\n",
       "      <td>0.316885</td>\n",
       "      <td>0.318734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.365245</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>0.358566</td>\n",
       "      <td>0.363505</td>\n",
       "      <td>0.365937</td>\n",
       "      <td>0.370626</td>\n",
       "      <td>0.369646</td>\n",
       "      <td>0.366513</td>\n",
       "      <td>0.364120</td>\n",
       "      <td>0.372314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414483</td>\n",
       "      <td>0.408990</td>\n",
       "      <td>0.411071</td>\n",
       "      <td>0.402824</td>\n",
       "      <td>0.396042</td>\n",
       "      <td>0.404752</td>\n",
       "      <td>0.404763</td>\n",
       "      <td>0.404851</td>\n",
       "      <td>0.402566</td>\n",
       "      <td>0.406675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows Ã— 22500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     0.282439  0.289924  0.293366  0.300145  0.303655  0.308242  0.314224   \n",
       "1     0.307829  0.299331  0.296886  0.301255  0.296857  0.306606  0.309610   \n",
       "2     0.259973  0.268775  0.275280  0.280152  0.285039  0.285782  0.288814   \n",
       "3     0.306726  0.303777  0.305048  0.305458  0.303881  0.309817  0.311885   \n",
       "4     0.216188  0.223491  0.231423  0.240872  0.241220  0.249937  0.252278   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.316758  0.319122  0.315090  0.317579  0.319337  0.326543  0.325820   \n",
       "1527  0.382267  0.381571  0.378451  0.383468  0.384683  0.388388  0.387331   \n",
       "1528  0.293139  0.287507  0.286387  0.289640  0.288580  0.296019  0.298054   \n",
       "1529  0.304618  0.297201  0.304142  0.305809  0.306728  0.308514  0.317587   \n",
       "1530  0.365245  0.362014  0.358566  0.363505  0.365937  0.370626  0.369646   \n",
       "\n",
       "         7         8         9      ...     22490     22491     22492  \\\n",
       "0     0.317845  0.324846  0.325541  ...  0.309310  0.307258  0.305002   \n",
       "1     0.308545  0.304403  0.308739  ...  0.333674  0.332998  0.328856   \n",
       "2     0.292053  0.299367  0.303309  ...  0.289264  0.288739  0.285866   \n",
       "3     0.309504  0.310891  0.314309  ...  0.334475  0.337161  0.331765   \n",
       "4     0.255959  0.261174  0.265196  ...  0.228960  0.225911  0.219907   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.322612  0.325771  0.332192  ...  0.344872  0.343667  0.348252   \n",
       "1527  0.394883  0.393906  0.397792  ...  0.425765  0.420005  0.422743   \n",
       "1528  0.285896  0.290841  0.299751  ...  0.316646  0.314835  0.314268   \n",
       "1529  0.312711  0.313207  0.312118  ...  0.332991  0.327786  0.325019   \n",
       "1530  0.366513  0.364120  0.372314  ...  0.414483  0.408990  0.411071   \n",
       "\n",
       "         22493     22494     22495     22496     22497     22498     22499  \n",
       "0     0.299647  0.298464  0.293929  0.289883  0.283850  0.283182  0.269569  \n",
       "1     0.331649  0.324068  0.326655  0.321872  0.321227  0.318055  0.321791  \n",
       "2     0.280724  0.279225  0.273654  0.267650  0.263894  0.262009  0.252174  \n",
       "3     0.335954  0.328828  0.325748  0.328762  0.326534  0.322945  0.324864  \n",
       "4     0.219417  0.212889  0.205368  0.205186  0.201541  0.197776  0.189999  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.339113  0.332841  0.333563  0.330319  0.335869  0.335691  0.332603  \n",
       "1527  0.420270  0.416993  0.414020  0.414914  0.414313  0.415321  0.415032  \n",
       "1528  0.311509  0.305610  0.309481  0.307940  0.304920  0.302529  0.301563  \n",
       "1529  0.329533  0.324487  0.320900  0.321537  0.317153  0.316885  0.318734  \n",
       "1530  0.402824  0.396042  0.404752  0.404763  0.404851  0.402566  0.406675  \n",
       "\n",
       "[1531 rows x 22500 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "857b9476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "1526    2\n",
       "1527    2\n",
       "1528    1\n",
       "1529    2\n",
       "1530    2\n",
       "Name: Target, Length: 1531, dtype: int32"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443e956",
   "metadata": {},
   "source": [
    "### Searching for best-performing model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1fded43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.342 total time=  32.1s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  30.8s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  30.4s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  41.5s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  33.5s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.342 total time=  26.5s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  24.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  20.9s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  23.4s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  21.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.704 total time=  32.7s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.641 total time=  35.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.706 total time=  33.8s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.634 total time=  38.4s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.725 total time=  37.8s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.792 total time=  12.7s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.778 total time=  11.9s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.804 total time=  15.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.758 total time=  12.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.794 total time=  11.9s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.342 total time=  40.6s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  36.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  32.4s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  37.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  32.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.844 total time=  13.9s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.824 total time=  13.7s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.827 total time=  11.8s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.837 total time=  15.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.850 total time=  12.7s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.342 total time=  36.5s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  36.5s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  31.7s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  37.9s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  40.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.844 total time=  12.6s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.824 total time=  13.7s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.827 total time=  13.7s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.837 total time=  13.9s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.850 total time=  11.8s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.678 total time=  29.9s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.614 total time=  29.7s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.686 total time=  32.6s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.608 total time=  29.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.693 total time=  30.2s\n",
      "[CV 1/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.381 total time=  26.6s\n",
      "[CV 2/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.428 total time=  18.6s\n",
      "[CV 3/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.415 total time=  18.2s\n",
      "[CV 4/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.379 total time=  18.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.425 total time=  18.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.821 total time=  21.5s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.801 total time=  21.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.843 total time=  23.1s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.804 total time=  31.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.837 total time=  31.3s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.863 total time=  13.7s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.827 total time=  11.4s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.853 total time=  12.1s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.850 total time=  15.1s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.879 total time=  12.8s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.381 total time=  38.3s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.376 total time=  35.8s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.376 total time=  38.7s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.369 total time=  35.8s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.350 total time=  33.7s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.844 total time=  10.9s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.824 total time=  13.2s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.827 total time=  12.1s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.837 total time=  15.8s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.850 total time=  10.8s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.342 total time=  33.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  32.7s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  37.9s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  36.5s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  37.5s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.844 total time=  16.4s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.824 total time=  14.2s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.827 total time=  18.3s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.837 total time=  15.5s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.850 total time=  13.7s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.746 total time=  25.1s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.735 total time=  25.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.775 total time=  22.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.732 total time=  21.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.765 total time=  22.2s\n",
      "[CV 1/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.697 total time=  20.5s\n",
      "[CV 2/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.670 total time=  15.7s\n",
      "[CV 3/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.729 total time=  15.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.647 total time=  17.5s\n",
      "[CV 5/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.719 total time=  16.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.889 total time=  17.5s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.7s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.915 total time=  17.2s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.908 total time=  16.9s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.8s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.844 total time=  10.6s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.824 total time=  13.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.827 total time=  12.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.837 total time=  12.8s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.850 total time=  10.6s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.404 total time=  30.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.392 total time=  32.3s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.395 total time=  36.6s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.392 total time=  31.5s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.363 total time=  30.5s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.844 total time=  10.2s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.824 total time=  15.9s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.827 total time=  14.5s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.837 total time=  16.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.850 total time=   9.4s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.342 total time=  28.8s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  27.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  32.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  29.7s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  28.2s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.844 total time=   9.1s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.824 total time=  11.3s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.827 total time=  10.0s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.837 total time=  11.3s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.850 total time=   9.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.814 total time=  16.9s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.781 total time=  16.9s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.817 total time=  17.2s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.824 total time=  16.9s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.817 total time=  17.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.792 total time=  10.2s\n",
      "[CV 2/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.778 total time=   9.9s\n",
      "[CV 3/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.804 total time=  10.2s\n",
      "[CV 4/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.758 total time=  10.1s\n",
      "[CV 5/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.794 total time=  10.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.896 total time=  15.2s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.7s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.915 total time=  17.1s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.2s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.844 total time=   9.5s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.824 total time=  11.6s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.827 total time=  10.1s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.837 total time=  11.2s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.850 total time=   9.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.404 total time=  28.6s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.392 total time=  28.5s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.395 total time=  29.3s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.392 total time=  28.7s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.363 total time=  29.6s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.844 total time=  10.4s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.824 total time=  11.8s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.827 total time=  10.9s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.837 total time=  11.3s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.850 total time=   9.9s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.342 total time=  30.3s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  28.3s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  27.2s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  27.6s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  27.8s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.844 total time=   8.8s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.824 total time=   9.9s\n",
      "[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=0.827 total time=   9.7s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.837 total time=  10.9s\n",
      "[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=0.850 total time=   8.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "#param_grid={'C':[0.1],'gamma':[0.0001],'kernel':['rbf','poly']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0792b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f095ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(x_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b8e0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Data is :\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 0 1 1 1 1 0 1 1 1 2 1 0 1 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 1 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "The actual data is:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "print(\"The predicted Data is :\")\n",
    "print(y_pred)\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(y_test))\n",
    "#print(f\"The model is {accuracy_score(y_pred,y_test)*100}% accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "25d711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(trained_model):\n",
    "    pred_y = trained_model.predict(x_test)\n",
    "    print(confusion_matrix(y_test,pred_y))\n",
    "    print(classification_report(y_test,pred_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ac18fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   1   5]\n",
      " [  7  93   7]\n",
      " [  7   1 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       109\n",
      "           1       0.98      0.87      0.92       107\n",
      "           2       0.90      0.93      0.91       113\n",
      "\n",
      "    accuracy                           0.91       329\n",
      "   macro avg       0.92      0.91      0.92       329\n",
      "weighted avg       0.92      0.91      0.92       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C=100, gamma=0.001, kernel=rbf\n",
    "score(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe73cfa",
   "metadata": {},
   "source": [
    "### Testing alternative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4e28569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   1   7]\n",
      " [  7  92   8]\n",
      " [ 10   8  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       109\n",
      "           1       0.91      0.86      0.88       107\n",
      "           2       0.86      0.84      0.85       113\n",
      "\n",
      "    accuracy                           0.88       329\n",
      "   macro avg       0.88      0.88      0.88       329\n",
      "weighted avg       0.88      0.88      0.88       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C=0.1, gamma=0.001, kernel=poly\n",
    "score(svm.SVC(C=0.1, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "be75f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   1   6]\n",
      " [  9  90   8]\n",
      " [ 10   8  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       109\n",
      "           1       0.91      0.84      0.87       107\n",
      "           2       0.87      0.84      0.86       113\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.87      0.87      0.87       329\n",
      "weighted avg       0.87      0.87      0.87       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=1, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "72e38b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   1   6]\n",
      " [  9  90   8]\n",
      " [ 10   8  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       109\n",
      "           1       0.91      0.84      0.87       107\n",
      "           2       0.87      0.84      0.86       113\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.87      0.87      0.87       329\n",
      "weighted avg       0.87      0.87      0.87       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=10, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "89e37fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   1   6]\n",
      " [  9  90   8]\n",
      " [ 10   8  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       109\n",
      "           1       0.91      0.84      0.87       107\n",
      "           2       0.87      0.84      0.86       113\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.87      0.87      0.87       329\n",
      "weighted avg       0.87      0.87      0.87       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=100, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9d33b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72 13 24]\n",
      " [13 72 22]\n",
      " [17  2 94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       109\n",
      "           1       0.83      0.67      0.74       107\n",
      "           2       0.67      0.83      0.74       113\n",
      "\n",
      "    accuracy                           0.72       329\n",
      "   macro avg       0.73      0.72      0.72       329\n",
      "weighted avg       0.73      0.72      0.72       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=0.1, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "73ef6b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95   3  11]\n",
      " [  5  88  14]\n",
      " [  9   1 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       109\n",
      "           1       0.96      0.82      0.88       107\n",
      "           2       0.80      0.91      0.85       113\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.88      0.87      0.87       329\n",
      "weighted avg       0.88      0.87      0.87       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=1, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "de616e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   1   5]\n",
      " [  5  94   8]\n",
      " [  7   3 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       109\n",
      "           1       0.96      0.88      0.92       107\n",
      "           2       0.89      0.91      0.90       113\n",
      "\n",
      "    accuracy                           0.91       329\n",
      "   macro avg       0.91      0.91      0.91       329\n",
      "weighted avg       0.91      0.91      0.91       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=10, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dd3495e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 109]\n",
      " [  0   0 107]\n",
      " [  0   0 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       109\n",
      "           1       0.00      0.00      0.00       107\n",
      "           2       0.34      1.00      0.51       113\n",
      "\n",
      "    accuracy                           0.34       329\n",
      "   macro avg       0.11      0.33      0.17       329\n",
      "weighted avg       0.12      0.34      0.18       329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "score(svm.SVC(C=0.1, gamma=0.0001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512dc89",
   "metadata": {},
   "source": [
    "### RBF with c=100, gamma=0.001 still the most accurate with 91-92% on testing data\n",
    "### c=0.001 classifies all into scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59198c7",
   "metadata": {},
   "source": [
    "### Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0e76e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   3   8]\n",
      " [  4  92  11]\n",
      " [  3   1 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       109\n",
      "           1       0.96      0.86      0.91       107\n",
      "           2       0.85      0.96      0.90       112\n",
      "\n",
      "    accuracy                           0.91       328\n",
      "   macro avg       0.91      0.91      0.91       328\n",
      "weighted avg       0.91      0.91      0.91       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = model.predict(x_val)\n",
    "print(confusion_matrix(y_val,y_pred_val))\n",
    "print(classification_report(y_val,y_pred_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
