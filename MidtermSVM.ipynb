{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7508d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd7318",
   "metadata": {},
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a198d47b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = 'rps-split\\\\train'\n",
    "test_dir = 'rps-split\\\\test'\n",
    "val_dir = 'rps-split\\\\val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f59f357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531, 22500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2fdbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22490</th>\n",
       "      <th>22491</th>\n",
       "      <th>22492</th>\n",
       "      <th>22493</th>\n",
       "      <th>22494</th>\n",
       "      <th>22495</th>\n",
       "      <th>22496</th>\n",
       "      <th>22497</th>\n",
       "      <th>22498</th>\n",
       "      <th>22499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282439</td>\n",
       "      <td>0.289924</td>\n",
       "      <td>0.293366</td>\n",
       "      <td>0.300145</td>\n",
       "      <td>0.303655</td>\n",
       "      <td>0.308242</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.317845</td>\n",
       "      <td>0.324846</td>\n",
       "      <td>0.325541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309310</td>\n",
       "      <td>0.307258</td>\n",
       "      <td>0.305002</td>\n",
       "      <td>0.299647</td>\n",
       "      <td>0.298464</td>\n",
       "      <td>0.293929</td>\n",
       "      <td>0.289883</td>\n",
       "      <td>0.283850</td>\n",
       "      <td>0.283182</td>\n",
       "      <td>0.269569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.299331</td>\n",
       "      <td>0.296886</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.296857</td>\n",
       "      <td>0.306606</td>\n",
       "      <td>0.309610</td>\n",
       "      <td>0.308545</td>\n",
       "      <td>0.304403</td>\n",
       "      <td>0.308739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>0.332998</td>\n",
       "      <td>0.328856</td>\n",
       "      <td>0.331649</td>\n",
       "      <td>0.324068</td>\n",
       "      <td>0.326655</td>\n",
       "      <td>0.321872</td>\n",
       "      <td>0.321227</td>\n",
       "      <td>0.318055</td>\n",
       "      <td>0.321791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.259973</td>\n",
       "      <td>0.268775</td>\n",
       "      <td>0.275280</td>\n",
       "      <td>0.280152</td>\n",
       "      <td>0.285039</td>\n",
       "      <td>0.285782</td>\n",
       "      <td>0.288814</td>\n",
       "      <td>0.292053</td>\n",
       "      <td>0.299367</td>\n",
       "      <td>0.303309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289264</td>\n",
       "      <td>0.288739</td>\n",
       "      <td>0.285866</td>\n",
       "      <td>0.280724</td>\n",
       "      <td>0.279225</td>\n",
       "      <td>0.273654</td>\n",
       "      <td>0.267650</td>\n",
       "      <td>0.263894</td>\n",
       "      <td>0.262009</td>\n",
       "      <td>0.252174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306726</td>\n",
       "      <td>0.303777</td>\n",
       "      <td>0.305048</td>\n",
       "      <td>0.305458</td>\n",
       "      <td>0.303881</td>\n",
       "      <td>0.309817</td>\n",
       "      <td>0.311885</td>\n",
       "      <td>0.309504</td>\n",
       "      <td>0.310891</td>\n",
       "      <td>0.314309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>0.337161</td>\n",
       "      <td>0.331765</td>\n",
       "      <td>0.335954</td>\n",
       "      <td>0.328828</td>\n",
       "      <td>0.325748</td>\n",
       "      <td>0.328762</td>\n",
       "      <td>0.326534</td>\n",
       "      <td>0.322945</td>\n",
       "      <td>0.324864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216188</td>\n",
       "      <td>0.223491</td>\n",
       "      <td>0.231423</td>\n",
       "      <td>0.240872</td>\n",
       "      <td>0.241220</td>\n",
       "      <td>0.249937</td>\n",
       "      <td>0.252278</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.261174</td>\n",
       "      <td>0.265196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>0.225911</td>\n",
       "      <td>0.219907</td>\n",
       "      <td>0.219417</td>\n",
       "      <td>0.212889</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.205186</td>\n",
       "      <td>0.201541</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>0.189999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.316758</td>\n",
       "      <td>0.319122</td>\n",
       "      <td>0.315090</td>\n",
       "      <td>0.317579</td>\n",
       "      <td>0.319337</td>\n",
       "      <td>0.326543</td>\n",
       "      <td>0.325820</td>\n",
       "      <td>0.322612</td>\n",
       "      <td>0.325771</td>\n",
       "      <td>0.332192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344872</td>\n",
       "      <td>0.343667</td>\n",
       "      <td>0.348252</td>\n",
       "      <td>0.339113</td>\n",
       "      <td>0.332841</td>\n",
       "      <td>0.333563</td>\n",
       "      <td>0.330319</td>\n",
       "      <td>0.335869</td>\n",
       "      <td>0.335691</td>\n",
       "      <td>0.332603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.382267</td>\n",
       "      <td>0.381571</td>\n",
       "      <td>0.378451</td>\n",
       "      <td>0.383468</td>\n",
       "      <td>0.384683</td>\n",
       "      <td>0.388388</td>\n",
       "      <td>0.387331</td>\n",
       "      <td>0.394883</td>\n",
       "      <td>0.393906</td>\n",
       "      <td>0.397792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425765</td>\n",
       "      <td>0.420005</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>0.420270</td>\n",
       "      <td>0.416993</td>\n",
       "      <td>0.414020</td>\n",
       "      <td>0.414914</td>\n",
       "      <td>0.414313</td>\n",
       "      <td>0.415321</td>\n",
       "      <td>0.415032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.293139</td>\n",
       "      <td>0.287507</td>\n",
       "      <td>0.286387</td>\n",
       "      <td>0.289640</td>\n",
       "      <td>0.288580</td>\n",
       "      <td>0.296019</td>\n",
       "      <td>0.298054</td>\n",
       "      <td>0.285896</td>\n",
       "      <td>0.290841</td>\n",
       "      <td>0.299751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316646</td>\n",
       "      <td>0.314835</td>\n",
       "      <td>0.314268</td>\n",
       "      <td>0.311509</td>\n",
       "      <td>0.305610</td>\n",
       "      <td>0.309481</td>\n",
       "      <td>0.307940</td>\n",
       "      <td>0.304920</td>\n",
       "      <td>0.302529</td>\n",
       "      <td>0.301563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.304618</td>\n",
       "      <td>0.297201</td>\n",
       "      <td>0.304142</td>\n",
       "      <td>0.305809</td>\n",
       "      <td>0.306728</td>\n",
       "      <td>0.308514</td>\n",
       "      <td>0.317587</td>\n",
       "      <td>0.312711</td>\n",
       "      <td>0.313207</td>\n",
       "      <td>0.312118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332991</td>\n",
       "      <td>0.327786</td>\n",
       "      <td>0.325019</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.324487</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.321537</td>\n",
       "      <td>0.317153</td>\n",
       "      <td>0.316885</td>\n",
       "      <td>0.318734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.365245</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>0.358566</td>\n",
       "      <td>0.363505</td>\n",
       "      <td>0.365937</td>\n",
       "      <td>0.370626</td>\n",
       "      <td>0.369646</td>\n",
       "      <td>0.366513</td>\n",
       "      <td>0.364120</td>\n",
       "      <td>0.372314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414483</td>\n",
       "      <td>0.408990</td>\n",
       "      <td>0.411071</td>\n",
       "      <td>0.402824</td>\n",
       "      <td>0.396042</td>\n",
       "      <td>0.404752</td>\n",
       "      <td>0.404763</td>\n",
       "      <td>0.404851</td>\n",
       "      <td>0.402566</td>\n",
       "      <td>0.406675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows Ã— 22500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     0.282439  0.289924  0.293366  0.300145  0.303655  0.308242  0.314224   \n",
       "1     0.307829  0.299331  0.296886  0.301255  0.296857  0.306606  0.309610   \n",
       "2     0.259973  0.268775  0.275280  0.280152  0.285039  0.285782  0.288814   \n",
       "3     0.306726  0.303777  0.305048  0.305458  0.303881  0.309817  0.311885   \n",
       "4     0.216188  0.223491  0.231423  0.240872  0.241220  0.249937  0.252278   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.316758  0.319122  0.315090  0.317579  0.319337  0.326543  0.325820   \n",
       "1527  0.382267  0.381571  0.378451  0.383468  0.384683  0.388388  0.387331   \n",
       "1528  0.293139  0.287507  0.286387  0.289640  0.288580  0.296019  0.298054   \n",
       "1529  0.304618  0.297201  0.304142  0.305809  0.306728  0.308514  0.317587   \n",
       "1530  0.365245  0.362014  0.358566  0.363505  0.365937  0.370626  0.369646   \n",
       "\n",
       "         7         8         9      ...     22490     22491     22492  \\\n",
       "0     0.317845  0.324846  0.325541  ...  0.309310  0.307258  0.305002   \n",
       "1     0.308545  0.304403  0.308739  ...  0.333674  0.332998  0.328856   \n",
       "2     0.292053  0.299367  0.303309  ...  0.289264  0.288739  0.285866   \n",
       "3     0.309504  0.310891  0.314309  ...  0.334475  0.337161  0.331765   \n",
       "4     0.255959  0.261174  0.265196  ...  0.228960  0.225911  0.219907   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.322612  0.325771  0.332192  ...  0.344872  0.343667  0.348252   \n",
       "1527  0.394883  0.393906  0.397792  ...  0.425765  0.420005  0.422743   \n",
       "1528  0.285896  0.290841  0.299751  ...  0.316646  0.314835  0.314268   \n",
       "1529  0.312711  0.313207  0.312118  ...  0.332991  0.327786  0.325019   \n",
       "1530  0.366513  0.364120  0.372314  ...  0.414483  0.408990  0.411071   \n",
       "\n",
       "         22493     22494     22495     22496     22497     22498     22499  \n",
       "0     0.299647  0.298464  0.293929  0.289883  0.283850  0.283182  0.269569  \n",
       "1     0.331649  0.324068  0.326655  0.321872  0.321227  0.318055  0.321791  \n",
       "2     0.280724  0.279225  0.273654  0.267650  0.263894  0.262009  0.252174  \n",
       "3     0.335954  0.328828  0.325748  0.328762  0.326534  0.322945  0.324864  \n",
       "4     0.219417  0.212889  0.205368  0.205186  0.201541  0.197776  0.189999  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.339113  0.332841  0.333563  0.330319  0.335869  0.335691  0.332603  \n",
       "1527  0.420270  0.416993  0.414020  0.414914  0.414313  0.415321  0.415032  \n",
       "1528  0.311509  0.305610  0.309481  0.307940  0.304920  0.302529  0.301563  \n",
       "1529  0.329533  0.324487  0.320900  0.321537  0.317153  0.316885  0.318734  \n",
       "1530  0.402824  0.396042  0.404752  0.404763  0.404851  0.402566  0.406675  \n",
       "\n",
       "[1531 rows x 22500 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857b9476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "1526    2\n",
       "1527    2\n",
       "1528    1\n",
       "1529    2\n",
       "1530    2\n",
       "Name: Target, Length: 1531, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443e956",
   "metadata": {},
   "source": [
    "### Searching for best-performing model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1fded43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.342 total time=  32.1s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  30.8s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  30.4s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  41.5s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=  33.5s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.342 total time=  26.5s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  24.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  20.9s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  23.4s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.343 total time=  21.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.704 total time=  32.7s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.641 total time=  35.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.706 total time=  33.8s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.634 total time=  38.4s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.725 total time=  37.8s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.792 total time=  12.7s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.778 total time=  11.9s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.804 total time=  15.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.758 total time=  12.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.794 total time=  11.9s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.342 total time=  40.6s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  36.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  32.4s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  37.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=  32.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.844 total time=  13.9s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.824 total time=  13.7s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.827 total time=  11.8s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.837 total time=  15.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.850 total time=  12.7s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.342 total time=  36.5s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  36.5s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  31.7s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  37.9s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=  40.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.844 total time=  12.6s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.824 total time=  13.7s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.827 total time=  13.7s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.837 total time=  13.9s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.850 total time=  11.8s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.678 total time=  29.9s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.614 total time=  29.7s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.686 total time=  32.6s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.608 total time=  29.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.693 total time=  30.2s\n",
      "[CV 1/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.381 total time=  26.6s\n",
      "[CV 2/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.428 total time=  18.6s\n",
      "[CV 3/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.415 total time=  18.2s\n",
      "[CV 4/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.379 total time=  18.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.425 total time=  18.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.821 total time=  21.5s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.801 total time=  21.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.843 total time=  23.1s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.804 total time=  31.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.837 total time=  31.3s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.863 total time=  13.7s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.827 total time=  11.4s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.853 total time=  12.1s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.850 total time=  15.1s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.879 total time=  12.8s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.381 total time=  38.3s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.376 total time=  35.8s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.376 total time=  38.7s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.369 total time=  35.8s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.350 total time=  33.7s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.844 total time=  10.9s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.824 total time=  13.2s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.827 total time=  12.1s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.837 total time=  15.8s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.850 total time=  10.8s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.342 total time=  33.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  32.7s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  37.9s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  36.5s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.343 total time=  37.5s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.844 total time=  16.4s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.824 total time=  14.2s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.827 total time=  18.3s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.837 total time=  15.5s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.850 total time=  13.7s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.746 total time=  25.1s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.735 total time=  25.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.775 total time=  22.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.732 total time=  21.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.765 total time=  22.2s\n",
      "[CV 1/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.697 total time=  20.5s\n",
      "[CV 2/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.670 total time=  15.7s\n",
      "[CV 3/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.729 total time=  15.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.647 total time=  17.5s\n",
      "[CV 5/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.719 total time=  16.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.889 total time=  17.5s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.7s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.915 total time=  17.2s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.908 total time=  16.9s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.8s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.844 total time=  10.6s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.824 total time=  13.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.827 total time=  12.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.837 total time=  12.8s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.850 total time=  10.6s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.404 total time=  30.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.392 total time=  32.3s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.395 total time=  36.6s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.392 total time=  31.5s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.363 total time=  30.5s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.844 total time=  10.2s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.824 total time=  15.9s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.827 total time=  14.5s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.837 total time=  16.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.850 total time=   9.4s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.342 total time=  28.8s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  27.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  32.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  29.7s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.343 total time=  28.2s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.844 total time=   9.1s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.824 total time=  11.3s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.827 total time=  10.0s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.837 total time=  11.3s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.850 total time=   9.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.814 total time=  16.9s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.781 total time=  16.9s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.817 total time=  17.2s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.824 total time=  16.9s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.817 total time=  17.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.792 total time=  10.2s\n",
      "[CV 2/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.778 total time=   9.9s\n",
      "[CV 3/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.804 total time=  10.2s\n",
      "[CV 4/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.758 total time=  10.1s\n",
      "[CV 5/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.794 total time=  10.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.896 total time=  15.2s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.7s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.915 total time=  17.1s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.2s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.844 total time=   9.5s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.824 total time=  11.6s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.827 total time=  10.1s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.837 total time=  11.2s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.850 total time=   9.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.404 total time=  28.6s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.392 total time=  28.5s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.395 total time=  29.3s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.392 total time=  28.7s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.363 total time=  29.6s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.844 total time=  10.4s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.824 total time=  11.8s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.827 total time=  10.9s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.837 total time=  11.3s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.850 total time=   9.9s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.342 total time=  30.3s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  28.3s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  27.2s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  27.6s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.343 total time=  27.8s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.844 total time=   8.8s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.824 total time=   9.9s\n",
      "[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=0.827 total time=   9.7s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.837 total time=  10.9s\n",
      "[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=0.850 total time=   8.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "#param_grid={'C':[0.1],'gamma':[0.0001],'kernel':['rbf','poly']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0792b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f330bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.001, kernel=rbf;, score=0.889 total time=  18.5s\n",
      "[CV 2/5] END C=10, degree=3, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.5s\n",
      "[CV 3/5] END C=10, degree=3, gamma=0.001, kernel=rbf;, score=0.915 total time=  15.7s\n",
      "[CV 4/5] END C=10, degree=3, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.6s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.5s\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.844 total time=  10.5s\n",
      "[CV 2/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.824 total time=  13.1s\n",
      "[CV 3/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.827 total time=  11.7s\n",
      "[CV 4/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.837 total time=  12.6s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.850 total time=  10.5s\n",
      "[CV 1/5] END C=10, degree=4, gamma=0.001, kernel=rbf;, score=0.889 total time=  15.4s\n",
      "[CV 2/5] END C=10, degree=4, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.4s\n",
      "[CV 3/5] END C=10, degree=4, gamma=0.001, kernel=rbf;, score=0.915 total time=  15.4s\n",
      "[CV 4/5] END C=10, degree=4, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.5s\n",
      "[CV 5/5] END C=10, degree=4, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.4s\n",
      "[CV 1/5] END C=10, degree=4, gamma=0.001, kernel=poly;, score=0.857 total time=   9.8s\n",
      "[CV 2/5] END C=10, degree=4, gamma=0.001, kernel=poly;, score=0.843 total time=  10.2s\n",
      "[CV 3/5] END C=10, degree=4, gamma=0.001, kernel=poly;, score=0.840 total time=   9.8s\n",
      "[CV 4/5] END C=10, degree=4, gamma=0.001, kernel=poly;, score=0.859 total time=   9.9s\n",
      "[CV 5/5] END C=10, degree=4, gamma=0.001, kernel=poly;, score=0.856 total time=  10.0s\n",
      "[CV 1/5] END C=10, degree=5, gamma=0.001, kernel=rbf;, score=0.889 total time=  15.5s\n",
      "[CV 2/5] END C=10, degree=5, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.4s\n",
      "[CV 3/5] END C=10, degree=5, gamma=0.001, kernel=rbf;, score=0.915 total time=  15.4s\n",
      "[CV 4/5] END C=10, degree=5, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.4s\n",
      "[CV 5/5] END C=10, degree=5, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.4s\n",
      "[CV 1/5] END C=10, degree=5, gamma=0.001, kernel=poly;, score=0.863 total time=   9.9s\n",
      "[CV 2/5] END C=10, degree=5, gamma=0.001, kernel=poly;, score=0.837 total time=   9.8s\n",
      "[CV 3/5] END C=10, degree=5, gamma=0.001, kernel=poly;, score=0.843 total time=   9.7s\n",
      "[CV 4/5] END C=10, degree=5, gamma=0.001, kernel=poly;, score=0.866 total time=   9.7s\n",
      "[CV 5/5] END C=10, degree=5, gamma=0.001, kernel=poly;, score=0.856 total time=   9.3s\n",
      "[CV 1/5] END C=100, degree=3, gamma=0.001, kernel=rbf;, score=0.896 total time=  15.2s\n",
      "[CV 2/5] END C=100, degree=3, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.1s\n",
      "[CV 3/5] END C=100, degree=3, gamma=0.001, kernel=rbf;, score=0.915 total time=  14.9s\n",
      "[CV 4/5] END C=100, degree=3, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.1s\n",
      "[CV 5/5] END C=100, degree=3, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.0s\n",
      "[CV 1/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.844 total time=  10.4s\n",
      "[CV 2/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.824 total time=  12.8s\n",
      "[CV 3/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.827 total time=  11.5s\n",
      "[CV 4/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.837 total time=  12.7s\n",
      "[CV 5/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.850 total time=  10.5s\n",
      "[CV 1/5] END C=100, degree=4, gamma=0.001, kernel=rbf;, score=0.896 total time=  16.0s\n",
      "[CV 2/5] END C=100, degree=4, gamma=0.001, kernel=rbf;, score=0.908 total time=  18.0s\n",
      "[CV 3/5] END C=100, degree=4, gamma=0.001, kernel=rbf;, score=0.915 total time=  15.3s\n",
      "[CV 4/5] END C=100, degree=4, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.7s\n",
      "[CV 5/5] END C=100, degree=4, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.1s\n",
      "[CV 1/5] END C=100, degree=4, gamma=0.001, kernel=poly;, score=0.857 total time=  16.0s\n",
      "[CV 2/5] END C=100, degree=4, gamma=0.001, kernel=poly;, score=0.843 total time=  11.1s\n",
      "[CV 3/5] END C=100, degree=4, gamma=0.001, kernel=poly;, score=0.840 total time=  16.8s\n",
      "[CV 4/5] END C=100, degree=4, gamma=0.001, kernel=poly;, score=0.859 total time=  12.8s\n",
      "[CV 5/5] END C=100, degree=4, gamma=0.001, kernel=poly;, score=0.856 total time=  11.6s\n",
      "[CV 1/5] END C=100, degree=5, gamma=0.001, kernel=rbf;, score=0.896 total time=  18.1s\n",
      "[CV 2/5] END C=100, degree=5, gamma=0.001, kernel=rbf;, score=0.908 total time=  16.5s\n",
      "[CV 3/5] END C=100, degree=5, gamma=0.001, kernel=rbf;, score=0.915 total time=  16.6s\n",
      "[CV 4/5] END C=100, degree=5, gamma=0.001, kernel=rbf;, score=0.902 total time=  17.1s\n",
      "[CV 5/5] END C=100, degree=5, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.1s\n",
      "[CV 1/5] END C=100, degree=5, gamma=0.001, kernel=poly;, score=0.863 total time=  10.2s\n",
      "[CV 2/5] END C=100, degree=5, gamma=0.001, kernel=poly;, score=0.837 total time=  12.6s\n",
      "[CV 3/5] END C=100, degree=5, gamma=0.001, kernel=poly;, score=0.843 total time=  11.2s\n",
      "[CV 4/5] END C=100, degree=5, gamma=0.001, kernel=poly;, score=0.866 total time=  11.9s\n",
      "[CV 5/5] END C=100, degree=5, gamma=0.001, kernel=poly;, score=0.856 total time=  12.3s\n",
      "[CV 1/5] END C=1000, degree=3, gamma=0.001, kernel=rbf;, score=0.896 total time=  16.7s\n",
      "[CV 2/5] END C=1000, degree=3, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.7s\n",
      "[CV 3/5] END C=1000, degree=3, gamma=0.001, kernel=rbf;, score=0.915 total time=  15.4s\n",
      "[CV 4/5] END C=1000, degree=3, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.9s\n",
      "[CV 5/5] END C=1000, degree=3, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.8s\n",
      "[CV 1/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.844 total time=  10.5s\n",
      "[CV 2/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.824 total time=  13.2s\n",
      "[CV 3/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.827 total time=  11.8s\n",
      "[CV 4/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.837 total time=  12.8s\n",
      "[CV 5/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.850 total time=  10.8s\n",
      "[CV 1/5] END C=1000, degree=4, gamma=0.001, kernel=rbf;, score=0.896 total time=  15.5s\n",
      "[CV 2/5] END C=1000, degree=4, gamma=0.001, kernel=rbf;, score=0.908 total time=  15.4s\n",
      "[CV 3/5] END C=1000, degree=4, gamma=0.001, kernel=rbf;, score=0.915 total time=  15.4s\n",
      "[CV 4/5] END C=1000, degree=4, gamma=0.001, kernel=rbf;, score=0.902 total time=  15.6s\n",
      "[CV 5/5] END C=1000, degree=4, gamma=0.001, kernel=rbf;, score=0.902 total time=  16.3s\n",
      "[CV 1/5] END C=1000, degree=4, gamma=0.001, kernel=poly;, score=0.857 total time=  11.3s\n",
      "[CV 2/5] END C=1000, degree=4, gamma=0.001, kernel=poly;, score=0.843 total time=   8.9s\n",
      "[CV 3/5] END C=1000, degree=4, gamma=0.001, kernel=poly;, score=0.840 total time=   8.7s\n",
      "[CV 4/5] END C=1000, degree=4, gamma=0.001, kernel=poly;, score=0.859 total time=   8.5s\n",
      "[CV 5/5] END C=1000, degree=4, gamma=0.001, kernel=poly;, score=0.856 total time=   8.2s\n",
      "[CV 1/5] END C=1000, degree=5, gamma=0.001, kernel=rbf;, score=0.896 total time=  13.4s\n",
      "[CV 2/5] END C=1000, degree=5, gamma=0.001, kernel=rbf;, score=0.908 total time=  13.5s\n",
      "[CV 3/5] END C=1000, degree=5, gamma=0.001, kernel=rbf;, score=0.915 total time=  13.7s\n",
      "[CV 4/5] END C=1000, degree=5, gamma=0.001, kernel=rbf;, score=0.902 total time=  14.2s\n",
      "[CV 5/5] END C=1000, degree=5, gamma=0.001, kernel=rbf;, score=0.902 total time=  14.0s\n",
      "[CV 1/5] END C=1000, degree=5, gamma=0.001, kernel=poly;, score=0.863 total time=   8.3s\n",
      "[CV 2/5] END C=1000, degree=5, gamma=0.001, kernel=poly;, score=0.837 total time=   8.4s\n",
      "[CV 3/5] END C=1000, degree=5, gamma=0.001, kernel=poly;, score=0.843 total time=   8.5s\n",
      "[CV 4/5] END C=1000, degree=5, gamma=0.001, kernel=poly;, score=0.866 total time=   8.7s\n",
      "[CV 5/5] END C=1000, degree=5, gamma=0.001, kernel=poly;, score=0.856 total time=   8.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [10, 100, 1000], 'degree': [3, 4, 5],\n",
       "                         'gamma': [0.001], 'kernel': ['rbf', 'poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[10,100,1000],'gamma':[0.001],'kernel':['rbf','poly'],'degree':[3,4,5]}\n",
    "#param_grid={'C':[0.1],'gamma':[0.0001],'kernel':['rbf','poly']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee45032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'degree': 3, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27dd8772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END ..............C=0.1, kernel=linear;, score=0.733 total time=  12.9s\n",
      "[CV 2/5] END ..............C=0.1, kernel=linear;, score=0.696 total time=  10.8s\n",
      "[CV 3/5] END ..............C=0.1, kernel=linear;, score=0.739 total time=  10.6s\n",
      "[CV 4/5] END ..............C=0.1, kernel=linear;, score=0.686 total time=  10.7s\n",
      "[CV 5/5] END ..............C=0.1, kernel=linear;, score=0.709 total time=  10.2s\n",
      "[CV 1/5] END ................C=1, kernel=linear;, score=0.658 total time=  12.7s\n",
      "[CV 2/5] END ................C=1, kernel=linear;, score=0.683 total time=  13.7s\n",
      "[CV 3/5] END ................C=1, kernel=linear;, score=0.683 total time=  11.8s\n",
      "[CV 4/5] END ................C=1, kernel=linear;, score=0.647 total time=  12.7s\n",
      "[CV 5/5] END ................C=1, kernel=linear;, score=0.683 total time=  12.6s\n",
      "[CV 1/5] END ...............C=10, kernel=linear;, score=0.658 total time=  12.3s\n",
      "[CV 2/5] END ...............C=10, kernel=linear;, score=0.683 total time=  12.6s\n",
      "[CV 3/5] END ...............C=10, kernel=linear;, score=0.683 total time=  11.6s\n",
      "[CV 4/5] END ...............C=10, kernel=linear;, score=0.647 total time=  11.5s\n",
      "[CV 5/5] END ...............C=10, kernel=linear;, score=0.683 total time=  12.4s\n",
      "[CV 1/5] END ..............C=100, kernel=linear;, score=0.658 total time=  12.7s\n",
      "[CV 2/5] END ..............C=100, kernel=linear;, score=0.683 total time=  12.7s\n",
      "[CV 3/5] END ..............C=100, kernel=linear;, score=0.683 total time=  12.0s\n",
      "[CV 4/5] END ..............C=100, kernel=linear;, score=0.647 total time=  12.1s\n",
      "[CV 5/5] END ..............C=100, kernel=linear;, score=0.683 total time=  12.4s\n",
      "[CV 1/5] END .............C=1000, kernel=linear;, score=0.658 total time=  12.2s\n",
      "[CV 2/5] END .............C=1000, kernel=linear;, score=0.683 total time=  12.9s\n",
      "[CV 3/5] END .............C=1000, kernel=linear;, score=0.683 total time=  12.1s\n",
      "[CV 4/5] END .............C=1000, kernel=linear;, score=0.647 total time=  12.0s\n",
      "[CV 5/5] END .............C=1000, kernel=linear;, score=0.683 total time=  12.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[0.1,1,10,100,1000],'kernel':['linear']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d822f21",
   "metadata": {},
   "source": [
    "### RBF with c=100, gamma=0.001 performs best on training set\n",
    "### Changing polynomial dimensions does not have significant impact on training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961ccb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_model = svm.SVC(kernel='rbf', gamma=0.001, C=100).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8e0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Data is :\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 0 1 1 1 1 0 1 1 1 2 1 0 1 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 1 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "The actual data is:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#model.fit(x_train,y_train)\n",
    "y_pred=best_train_model.predict(x_test)\n",
    "print(\"The predicted Data is :\")\n",
    "print(y_pred)\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(y_test))\n",
    "#print(f\"The model is {accuracy_score(y_pred,y_test)*100}% accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25d711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_test)\n",
    "    print(confusion_matrix(y_test,pred_y))\n",
    "    print(classification_report(y_test,pred_y))\n",
    "    \n",
    "def train_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_train)\n",
    "    print(confusion_matrix(y_train,pred_y))\n",
    "    print(classification_report(y_train,pred_y))\n",
    "    \n",
    "def val_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_val)\n",
    "    print(confusion_matrix(y_val,pred_y))\n",
    "    print(classification_report(y_val,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac18fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   3   8]\n",
      " [  4  92  11]\n",
      " [  3   1 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       109\n",
      "           1       0.96      0.86      0.91       107\n",
      "           2       0.85      0.96      0.90       112\n",
      "\n",
      "    accuracy                           0.91       328\n",
      "   macro avg       0.91      0.91      0.91       328\n",
      "weighted avg       0.91      0.91      0.91       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C=100, gamma=0.001, kernel=rbf\n",
    "val_score(best_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d51644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(best_train_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe73cfa",
   "metadata": {},
   "source": [
    "### Testing alternative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9f2cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   3   8]\n",
      " [  4  92  11]\n",
      " [  3   1 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       109\n",
      "           1       0.96      0.86      0.91       107\n",
      "           2       0.85      0.96      0.90       112\n",
      "\n",
      "    accuracy                           0.91       328\n",
      "   macro avg       0.91      0.91      0.91       328\n",
      "weighted avg       0.91      0.91      0.91       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=1000,kernel='rbf',gamma=0.001).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e28569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97  3  9]\n",
      " [10 88  9]\n",
      " [10  5 97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       109\n",
      "           1       0.92      0.82      0.87       107\n",
      "           2       0.84      0.87      0.85       112\n",
      "\n",
      "    accuracy                           0.86       328\n",
      "   macro avg       0.86      0.86      0.86       328\n",
      "weighted avg       0.86      0.86      0.86       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C=0.1, gamma=0.001, kernel=poly\n",
    "val_score(svm.SVC(C=0.1, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be75f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  4  7]\n",
      " [10 88  9]\n",
      " [10  4 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       109\n",
      "           1       0.92      0.82      0.87       107\n",
      "           2       0.86      0.88      0.87       112\n",
      "\n",
      "    accuracy                           0.87       328\n",
      "   macro avg       0.87      0.87      0.87       328\n",
      "weighted avg       0.87      0.87      0.87       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=1, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e38b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  4  7]\n",
      " [10 88  9]\n",
      " [10  4 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       109\n",
      "           1       0.92      0.82      0.87       107\n",
      "           2       0.86      0.88      0.87       112\n",
      "\n",
      "    accuracy                           0.87       328\n",
      "   macro avg       0.87      0.87      0.87       328\n",
      "weighted avg       0.87      0.87      0.87       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=10, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e37fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  4  7]\n",
      " [10 88  9]\n",
      " [10  4 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       109\n",
      "           1       0.92      0.82      0.87       107\n",
      "           2       0.86      0.88      0.87       112\n",
      "\n",
      "    accuracy                           0.87       328\n",
      "   macro avg       0.87      0.87      0.87       328\n",
      "weighted avg       0.87      0.87      0.87       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d33b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72 10 27]\n",
      " [10 72 25]\n",
      " [18  4 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       109\n",
      "           1       0.84      0.67      0.75       107\n",
      "           2       0.63      0.80      0.71       112\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.73      0.71      0.71       328\n",
      "weighted avg       0.73      0.71      0.71       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb97f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[346  61 101]\n",
      " [ 50 323 125]\n",
      " [ 79  19 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       508\n",
      "           1       0.80      0.65      0.72       498\n",
      "           2       0.65      0.81      0.72       525\n",
      "\n",
      "    accuracy                           0.72      1531\n",
      "   macro avg       0.73      0.71      0.72      1531\n",
      "weighted avg       0.73      0.72      0.72      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73ef6b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  5 19]\n",
      " [ 7 85 15]\n",
      " [12  5 95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       109\n",
      "           1       0.89      0.79      0.84       107\n",
      "           2       0.74      0.85      0.79       112\n",
      "\n",
      "    accuracy                           0.81       328\n",
      "   macro avg       0.82      0.81      0.81       328\n",
      "weighted avg       0.81      0.81      0.81       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=1, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de616e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95   3  11]\n",
      " [  5  92  10]\n",
      " [  5   2 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89       109\n",
      "           1       0.95      0.86      0.90       107\n",
      "           2       0.83      0.94      0.88       112\n",
      "\n",
      "    accuracy                           0.89       328\n",
      "   macro avg       0.90      0.89      0.89       328\n",
      "weighted avg       0.89      0.89      0.89       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=10, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f351502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  4  7]\n",
      " [10 88  9]\n",
      " [10  4 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       109\n",
      "           1       0.92      0.82      0.87       107\n",
      "           2       0.86      0.88      0.87       112\n",
      "\n",
      "    accuracy                           0.87       328\n",
      "   macro avg       0.87      0.87      0.87       328\n",
      "weighted avg       0.87      0.87      0.87       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, degree=3, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b07d7614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96  4  9]\n",
      " [10 89  8]\n",
      " [ 9  4 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       109\n",
      "           1       0.92      0.83      0.87       107\n",
      "           2       0.85      0.88      0.87       112\n",
      "\n",
      "    accuracy                           0.87       328\n",
      "   macro avg       0.87      0.87      0.87       328\n",
      "weighted avg       0.87      0.87      0.87       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, degree=4, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce572aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96  4  9]\n",
      " [10 89  8]\n",
      " [ 8  6 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       109\n",
      "           1       0.90      0.83      0.86       107\n",
      "           2       0.85      0.88      0.86       112\n",
      "\n",
      "    accuracy                           0.86       328\n",
      "   macro avg       0.86      0.86      0.86       328\n",
      "weighted avg       0.86      0.86      0.86       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e530e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=100, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e29fde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82  5 22]\n",
      " [20 75 12]\n",
      " [24 13 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.75      0.70       109\n",
      "           1       0.81      0.70      0.75       107\n",
      "           2       0.69      0.67      0.68       112\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.72      0.71      0.71       328\n",
      "weighted avg       0.71      0.71      0.71       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e6e268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[481  10  17]\n",
      " [  1 489   8]\n",
      " [ 12   0 513]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       508\n",
      "           1       0.98      0.98      0.98       498\n",
      "           2       0.95      0.98      0.97       525\n",
      "\n",
      "    accuracy                           0.97      1531\n",
      "   macro avg       0.97      0.97      0.97      1531\n",
      "weighted avg       0.97      0.97      0.97      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a88db",
   "metadata": {},
   "source": [
    "### Increasing polynomial dimensions marginally improves testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd3495e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0 108]\n",
      " [  0   0 107]\n",
      " [  0   0 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       109\n",
      "           1       0.00      0.00      0.00       107\n",
      "           2       0.34      1.00      0.51       112\n",
      "\n",
      "    accuracy                           0.34       328\n",
      "   macro avg       0.45      0.34      0.18       328\n",
      "weighted avg       0.45      0.34      0.18       328\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, gamma=0.0001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4720eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0 505]\n",
      " [  0   0 498]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01       508\n",
      "           1       0.00      0.00      0.00       498\n",
      "           2       0.34      1.00      0.51       525\n",
      "\n",
      "    accuracy                           0.34      1531\n",
      "   macro avg       0.45      0.34      0.17      1531\n",
      "weighted avg       0.45      0.34      0.18      1531\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, gamma=0.0001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512dc89",
   "metadata": {},
   "source": [
    "### RBF with c=100, gamma=0.001 still the most accurate with 91-92% on testing data and 100% on training data\n",
    "### c=0.001 classifies all into scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4aa53",
   "metadata": {},
   "source": [
    "## Decrease image quality from 150x150 to 32x32 for better comparison to neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6637b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = 'rps-split\\\\train'\n",
    "test_dir = 'rps-split\\\\test'\n",
    "val_dir = 'rps-split\\\\val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac00ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf9015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300570</td>\n",
       "      <td>0.321333</td>\n",
       "      <td>0.339861</td>\n",
       "      <td>0.356015</td>\n",
       "      <td>0.368621</td>\n",
       "      <td>0.375393</td>\n",
       "      <td>0.386557</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.396568</td>\n",
       "      <td>0.401079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366491</td>\n",
       "      <td>0.364223</td>\n",
       "      <td>0.361065</td>\n",
       "      <td>0.355037</td>\n",
       "      <td>0.347758</td>\n",
       "      <td>0.338876</td>\n",
       "      <td>0.328757</td>\n",
       "      <td>0.317450</td>\n",
       "      <td>0.305523</td>\n",
       "      <td>0.289068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.305769</td>\n",
       "      <td>0.309675</td>\n",
       "      <td>0.316426</td>\n",
       "      <td>0.327396</td>\n",
       "      <td>0.332671</td>\n",
       "      <td>0.341594</td>\n",
       "      <td>0.347691</td>\n",
       "      <td>0.352916</td>\n",
       "      <td>0.357916</td>\n",
       "      <td>0.363374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371226</td>\n",
       "      <td>0.368799</td>\n",
       "      <td>0.363895</td>\n",
       "      <td>0.358266</td>\n",
       "      <td>0.353350</td>\n",
       "      <td>0.345255</td>\n",
       "      <td>0.337634</td>\n",
       "      <td>0.334755</td>\n",
       "      <td>0.330602</td>\n",
       "      <td>0.322242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279768</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.317711</td>\n",
       "      <td>0.332790</td>\n",
       "      <td>0.345631</td>\n",
       "      <td>0.352844</td>\n",
       "      <td>0.363831</td>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.374380</td>\n",
       "      <td>0.378595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352845</td>\n",
       "      <td>0.349581</td>\n",
       "      <td>0.346031</td>\n",
       "      <td>0.339196</td>\n",
       "      <td>0.330828</td>\n",
       "      <td>0.320949</td>\n",
       "      <td>0.309510</td>\n",
       "      <td>0.298604</td>\n",
       "      <td>0.285769</td>\n",
       "      <td>0.269304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.309114</td>\n",
       "      <td>0.312441</td>\n",
       "      <td>0.320083</td>\n",
       "      <td>0.330972</td>\n",
       "      <td>0.337421</td>\n",
       "      <td>0.344661</td>\n",
       "      <td>0.348730</td>\n",
       "      <td>0.355505</td>\n",
       "      <td>0.360473</td>\n",
       "      <td>0.367050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369720</td>\n",
       "      <td>0.368379</td>\n",
       "      <td>0.364475</td>\n",
       "      <td>0.357779</td>\n",
       "      <td>0.353295</td>\n",
       "      <td>0.345417</td>\n",
       "      <td>0.341060</td>\n",
       "      <td>0.337860</td>\n",
       "      <td>0.332617</td>\n",
       "      <td>0.324913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238294</td>\n",
       "      <td>0.259614</td>\n",
       "      <td>0.275919</td>\n",
       "      <td>0.290672</td>\n",
       "      <td>0.297517</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.314081</td>\n",
       "      <td>0.321606</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.328438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252287</td>\n",
       "      <td>0.253382</td>\n",
       "      <td>0.257844</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0.265494</td>\n",
       "      <td>0.258059</td>\n",
       "      <td>0.249070</td>\n",
       "      <td>0.238190</td>\n",
       "      <td>0.221616</td>\n",
       "      <td>0.203713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.320905</td>\n",
       "      <td>0.328758</td>\n",
       "      <td>0.336999</td>\n",
       "      <td>0.347664</td>\n",
       "      <td>0.354435</td>\n",
       "      <td>0.363455</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>0.373455</td>\n",
       "      <td>0.379199</td>\n",
       "      <td>0.384777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386852</td>\n",
       "      <td>0.385306</td>\n",
       "      <td>0.381406</td>\n",
       "      <td>0.377614</td>\n",
       "      <td>0.370012</td>\n",
       "      <td>0.362756</td>\n",
       "      <td>0.356964</td>\n",
       "      <td>0.349564</td>\n",
       "      <td>0.344221</td>\n",
       "      <td>0.338484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.389369</td>\n",
       "      <td>0.392769</td>\n",
       "      <td>0.389571</td>\n",
       "      <td>0.386150</td>\n",
       "      <td>0.392524</td>\n",
       "      <td>0.402755</td>\n",
       "      <td>0.406559</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0.418259</td>\n",
       "      <td>0.437901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456071</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.450985</td>\n",
       "      <td>0.448131</td>\n",
       "      <td>0.443195</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>0.431848</td>\n",
       "      <td>0.426035</td>\n",
       "      <td>0.423116</td>\n",
       "      <td>0.421126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.292997</td>\n",
       "      <td>0.296107</td>\n",
       "      <td>0.303562</td>\n",
       "      <td>0.315029</td>\n",
       "      <td>0.321099</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.333897</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.344243</td>\n",
       "      <td>0.350723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356617</td>\n",
       "      <td>0.356413</td>\n",
       "      <td>0.350368</td>\n",
       "      <td>0.343588</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.331346</td>\n",
       "      <td>0.324399</td>\n",
       "      <td>0.320611</td>\n",
       "      <td>0.314091</td>\n",
       "      <td>0.307539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.308246</td>\n",
       "      <td>0.313464</td>\n",
       "      <td>0.319537</td>\n",
       "      <td>0.331429</td>\n",
       "      <td>0.337286</td>\n",
       "      <td>0.345225</td>\n",
       "      <td>0.350081</td>\n",
       "      <td>0.354131</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.363382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369423</td>\n",
       "      <td>0.367132</td>\n",
       "      <td>0.361423</td>\n",
       "      <td>0.354030</td>\n",
       "      <td>0.349208</td>\n",
       "      <td>0.340947</td>\n",
       "      <td>0.335438</td>\n",
       "      <td>0.333584</td>\n",
       "      <td>0.329611</td>\n",
       "      <td>0.323610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.366861</td>\n",
       "      <td>0.371842</td>\n",
       "      <td>0.378550</td>\n",
       "      <td>0.385710</td>\n",
       "      <td>0.393506</td>\n",
       "      <td>0.397996</td>\n",
       "      <td>0.392798</td>\n",
       "      <td>0.395073</td>\n",
       "      <td>0.401743</td>\n",
       "      <td>0.417879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446343</td>\n",
       "      <td>0.442008</td>\n",
       "      <td>0.437226</td>\n",
       "      <td>0.435007</td>\n",
       "      <td>0.428910</td>\n",
       "      <td>0.423053</td>\n",
       "      <td>0.418466</td>\n",
       "      <td>0.414347</td>\n",
       "      <td>0.411190</td>\n",
       "      <td>0.409410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.300570  0.321333  0.339861  0.356015  0.368621  0.375393  0.386557   \n",
       "1     0.305769  0.309675  0.316426  0.327396  0.332671  0.341594  0.347691   \n",
       "2     0.279768  0.298246  0.317711  0.332790  0.345631  0.352844  0.363831   \n",
       "3     0.309114  0.312441  0.320083  0.330972  0.337421  0.344661  0.348730   \n",
       "4     0.238294  0.259614  0.275919  0.290672  0.297517  0.306122  0.314081   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.320905  0.328758  0.336999  0.347664  0.354435  0.363455  0.368484   \n",
       "1527  0.389369  0.392769  0.389571  0.386150  0.392524  0.402755  0.406559   \n",
       "1528  0.292997  0.296107  0.303562  0.315029  0.321099  0.329147  0.333897   \n",
       "1529  0.308246  0.313464  0.319537  0.331429  0.337286  0.345225  0.350081   \n",
       "1530  0.366861  0.371842  0.378550  0.385710  0.393506  0.397996  0.392798   \n",
       "\n",
       "          7         8         9     ...      1014      1015      1016  \\\n",
       "0     0.392265  0.396568  0.401079  ...  0.366491  0.364223  0.361065   \n",
       "1     0.352916  0.357916  0.363374  ...  0.371226  0.368799  0.363895   \n",
       "2     0.369659  0.374380  0.378595  ...  0.352845  0.349581  0.346031   \n",
       "3     0.355505  0.360473  0.367050  ...  0.369720  0.368379  0.364475   \n",
       "4     0.321606  0.325926  0.328438  ...  0.252287  0.253382  0.257844   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.373455  0.379199  0.384777  ...  0.386852  0.385306  0.381406   \n",
       "1527  0.410655  0.418259  0.437901  ...  0.456071  0.454156  0.450985   \n",
       "1528  0.339125  0.344243  0.350723  ...  0.356617  0.356413  0.350368   \n",
       "1529  0.354131  0.357728  0.363382  ...  0.369423  0.367132  0.361423   \n",
       "1530  0.395073  0.401743  0.417879  ...  0.446343  0.442008  0.437226   \n",
       "\n",
       "          1017      1018      1019      1020      1021      1022      1023  \n",
       "0     0.355037  0.347758  0.338876  0.328757  0.317450  0.305523  0.289068  \n",
       "1     0.358266  0.353350  0.345255  0.337634  0.334755  0.330602  0.322242  \n",
       "2     0.339196  0.330828  0.320949  0.309510  0.298604  0.285769  0.269304  \n",
       "3     0.357779  0.353295  0.345417  0.341060  0.337860  0.332617  0.324913  \n",
       "4     0.265044  0.265494  0.258059  0.249070  0.238190  0.221616  0.203713  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.377614  0.370012  0.362756  0.356964  0.349564  0.344221  0.338484  \n",
       "1527  0.448131  0.443195  0.436381  0.431848  0.426035  0.423116  0.421126  \n",
       "1528  0.343588  0.339844  0.331346  0.324399  0.320611  0.314091  0.307539  \n",
       "1529  0.354030  0.349208  0.340947  0.335438  0.333584  0.329611  0.323610  \n",
       "1530  0.435007  0.428910  0.423053  0.418466  0.414347  0.411190  0.409410  \n",
       "\n",
       "[1531 rows x 1024 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9da2d47a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.342 total time=   2.5s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.5s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.5s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.5s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.342 total time=   2.5s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.343 total time=   2.5s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.343 total time=   2.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.795 total time=   2.1s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.765 total time=   2.1s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.791 total time=   2.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.755 total time=   2.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.761 total time=   2.1s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.342 total time=   2.4s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.342 total time=   2.3s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   2.4s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.547 total time=   2.7s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.523 total time=   2.5s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.569 total time=   2.4s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.503 total time=   2.4s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.588 total time=   2.4s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.896 total time=   1.4s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.908 total time=   1.4s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.922 total time=   1.4s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.908 total time=   1.4s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.892 total time=   1.5s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.756 total time=   2.4s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.755 total time=   2.5s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.761 total time=   2.4s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.807 total time=   2.4s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.748 total time=   2.4s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.541 total time=   2.4s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.523 total time=   2.4s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.572 total time=   2.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.503 total time=   2.3s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.588 total time=   2.3s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.710 total time=   1.9s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.683 total time=   1.9s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.735 total time=   2.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.683 total time=   1.8s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.735 total time=   1.2s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.906 total time=   1.4s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.935 total time=   1.4s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.938 total time=   1.4s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.931 total time=   1.4s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.908 total time=   1.3s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.779 total time=   2.5s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.775 total time=   2.5s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.791 total time=   2.5s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.820 total time=   2.4s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.768 total time=   2.5s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.704 total time=   2.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.683 total time=   1.9s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.732 total time=   2.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.680 total time=   1.9s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.716 total time=   1.2s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.788 total time=   1.5s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.784 total time=   1.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.791 total time=   1.5s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.761 total time=   1.4s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.801 total time=   1.5s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.906 total time=   1.5s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.935 total time=   1.4s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.938 total time=   1.4s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.931 total time=   1.4s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.908 total time=   1.5s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.779 total time=   2.7s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.775 total time=   2.5s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.791 total time=   2.7s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.820 total time=   2.6s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.768 total time=   2.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "059d66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c6af6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END ......C=0.1, degree=3, kernel=poly;, score=0.853 total time=   0.5s\n",
      "[CV 2/5] END ......C=0.1, degree=3, kernel=poly;, score=0.846 total time=   0.6s\n",
      "[CV 3/5] END ......C=0.1, degree=3, kernel=poly;, score=0.846 total time=   0.6s\n",
      "[CV 4/5] END ......C=0.1, degree=3, kernel=poly;, score=0.846 total time=   0.6s\n",
      "[CV 5/5] END ......C=0.1, degree=3, kernel=poly;, score=0.863 total time=   0.6s\n",
      "[CV 1/5] END ......C=0.1, degree=4, kernel=poly;, score=0.863 total time=   0.5s\n",
      "[CV 2/5] END ......C=0.1, degree=4, kernel=poly;, score=0.859 total time=   0.5s\n",
      "[CV 3/5] END ......C=0.1, degree=4, kernel=poly;, score=0.843 total time=   0.5s\n",
      "[CV 4/5] END ......C=0.1, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 5/5] END ......C=0.1, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 1/5] END ......C=0.1, degree=5, kernel=poly;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END ......C=0.1, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 3/5] END ......C=0.1, degree=5, kernel=poly;, score=0.840 total time=   0.5s\n",
      "[CV 4/5] END ......C=0.1, degree=5, kernel=poly;, score=0.882 total time=   0.5s\n",
      "[CV 5/5] END ......C=0.1, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 1/5] END ........C=1, degree=3, kernel=poly;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END ........C=1, degree=3, kernel=poly;, score=0.853 total time=   0.6s\n",
      "[CV 3/5] END ........C=1, degree=3, kernel=poly;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END ........C=1, degree=3, kernel=poly;, score=0.866 total time=   0.5s\n",
      "[CV 5/5] END ........C=1, degree=3, kernel=poly;, score=0.856 total time=   0.5s\n",
      "[CV 1/5] END ........C=1, degree=4, kernel=poly;, score=0.863 total time=   0.5s\n",
      "[CV 2/5] END ........C=1, degree=4, kernel=poly;, score=0.859 total time=   0.5s\n",
      "[CV 3/5] END ........C=1, degree=4, kernel=poly;, score=0.843 total time=   0.5s\n",
      "[CV 4/5] END ........C=1, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 5/5] END ........C=1, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 1/5] END ........C=1, degree=5, kernel=poly;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END ........C=1, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 3/5] END ........C=1, degree=5, kernel=poly;, score=0.840 total time=   0.5s\n",
      "[CV 4/5] END ........C=1, degree=5, kernel=poly;, score=0.882 total time=   0.5s\n",
      "[CV 5/5] END ........C=1, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 1/5] END .......C=10, degree=3, kernel=poly;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END .......C=10, degree=3, kernel=poly;, score=0.853 total time=   0.6s\n",
      "[CV 3/5] END .......C=10, degree=3, kernel=poly;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END .......C=10, degree=3, kernel=poly;, score=0.866 total time=   0.6s\n",
      "[CV 5/5] END .......C=10, degree=3, kernel=poly;, score=0.856 total time=   0.5s\n",
      "[CV 1/5] END .......C=10, degree=4, kernel=poly;, score=0.863 total time=   0.5s\n",
      "[CV 2/5] END .......C=10, degree=4, kernel=poly;, score=0.859 total time=   0.5s\n",
      "[CV 3/5] END .......C=10, degree=4, kernel=poly;, score=0.843 total time=   0.5s\n",
      "[CV 4/5] END .......C=10, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 5/5] END .......C=10, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 1/5] END .......C=10, degree=5, kernel=poly;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END .......C=10, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 3/5] END .......C=10, degree=5, kernel=poly;, score=0.840 total time=   0.5s\n",
      "[CV 4/5] END .......C=10, degree=5, kernel=poly;, score=0.882 total time=   0.5s\n",
      "[CV 5/5] END .......C=10, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 1/5] END ......C=100, degree=3, kernel=poly;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END ......C=100, degree=3, kernel=poly;, score=0.853 total time=   0.6s\n",
      "[CV 3/5] END ......C=100, degree=3, kernel=poly;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END ......C=100, degree=3, kernel=poly;, score=0.866 total time=   0.6s\n",
      "[CV 5/5] END ......C=100, degree=3, kernel=poly;, score=0.856 total time=   0.6s\n",
      "[CV 1/5] END ......C=100, degree=4, kernel=poly;, score=0.863 total time=   0.5s\n",
      "[CV 2/5] END ......C=100, degree=4, kernel=poly;, score=0.859 total time=   0.5s\n",
      "[CV 3/5] END ......C=100, degree=4, kernel=poly;, score=0.843 total time=   0.5s\n",
      "[CV 4/5] END ......C=100, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 5/5] END ......C=100, degree=4, kernel=poly;, score=0.876 total time=   0.5s\n",
      "[CV 1/5] END ......C=100, degree=5, kernel=poly;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END ......C=100, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n",
      "[CV 3/5] END ......C=100, degree=5, kernel=poly;, score=0.840 total time=   0.5s\n",
      "[CV 4/5] END ......C=100, degree=5, kernel=poly;, score=0.882 total time=   0.5s\n",
      "[CV 5/5] END ......C=100, degree=5, kernel=poly;, score=0.879 total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'degree': [3, 4, 5],\n",
       "                         'kernel': ['poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[0.1,1,10,100],'degree':[3,4,5],'kernel':['poly']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7975b1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'degree': 5, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35f268",
   "metadata": {},
   "source": [
    "### Compare with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12438b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'kernel':['linear']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2a604",
   "metadata": {},
   "source": [
    "### Lower-quality images: best gamma 0.1 instead of 0.001, best C 10 instead of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "779ed1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   2   6]\n",
      " [  4  94   9]\n",
      " [  3   1 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       109\n",
      "           1       0.97      0.88      0.92       107\n",
      "           2       0.88      0.96      0.92       112\n",
      "\n",
      "    accuracy                           0.92       328\n",
      "   macro avg       0.93      0.92      0.92       328\n",
      "weighted avg       0.93      0.92      0.92       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=10, gamma=0.1, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a42ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=10, gamma=0.1, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4e06b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   0   7]\n",
      " [  3  98   6]\n",
      " [  5   2 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       109\n",
      "           1       0.98      0.92      0.95       107\n",
      "           2       0.89      0.94      0.91       113\n",
      "\n",
      "    accuracy                           0.93       329\n",
      "   macro avg       0.93      0.93      0.93       329\n",
      "weighted avg       0.93      0.93      0.93       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(kernel='rbf', gamma=0.1, C=10).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a142fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76  8 25]\n",
      " [10 77 20]\n",
      " [16  9 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       109\n",
      "           1       0.82      0.72      0.77       107\n",
      "           2       0.66      0.78      0.71       112\n",
      "\n",
      "    accuracy                           0.73       328\n",
      "   macro avg       0.74      0.73      0.73       328\n",
      "weighted avg       0.74      0.73      0.73       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=10, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4512c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   2   6]\n",
      " [  4  94   9]\n",
      " [  3   1 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       109\n",
      "           1       0.97      0.88      0.92       107\n",
      "           2       0.88      0.96      0.92       112\n",
      "\n",
      "    accuracy                           0.92       328\n",
      "   macro avg       0.93      0.92      0.92       328\n",
      "weighted avg       0.93      0.92      0.92       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, gamma=0.1, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e95fdae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   0   7]\n",
      " [  3  98   6]\n",
      " [  5   2 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       109\n",
      "           1       0.98      0.92      0.95       107\n",
      "           2       0.89      0.94      0.91       113\n",
      "\n",
      "    accuracy                           0.93       329\n",
      "   macro avg       0.93      0.93      0.93       329\n",
      "weighted avg       0.93      0.93      0.93       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(C=100, gamma=0.1, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeb08b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406  38  64]\n",
      " [ 39 369  90]\n",
      " [ 62  29 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       508\n",
      "           1       0.85      0.74      0.79       498\n",
      "           2       0.74      0.83      0.78       525\n",
      "\n",
      "    accuracy                           0.79      1531\n",
      "   macro avg       0.80      0.79      0.79      1531\n",
      "weighted avg       0.79      0.79      0.79      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8131a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  4 22]\n",
      " [14 78 15]\n",
      " [14 11 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       109\n",
      "           1       0.84      0.73      0.78       107\n",
      "           2       0.70      0.78      0.74       112\n",
      "\n",
      "    accuracy                           0.76       328\n",
      "   macro avg       0.76      0.76      0.76       328\n",
      "weighted avg       0.76      0.76      0.76       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8722adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89  4 16]\n",
      " [ 9 73 25]\n",
      " [17 10 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       109\n",
      "           1       0.84      0.68      0.75       107\n",
      "           2       0.68      0.76      0.72       113\n",
      "\n",
      "    accuracy                           0.75       329\n",
      "   macro avg       0.76      0.75      0.75       329\n",
      "weighted avg       0.76      0.75      0.75       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78bbfa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[442  24  42]\n",
      " [ 22 436  40]\n",
      " [ 48  19 458]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       508\n",
      "           1       0.91      0.88      0.89       498\n",
      "           2       0.85      0.87      0.86       525\n",
      "\n",
      "    accuracy                           0.87      1531\n",
      "   macro avg       0.87      0.87      0.87      1531\n",
      "weighted avg       0.87      0.87      0.87      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "544e1cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  4 20]\n",
      " [13 77 17]\n",
      " [17 11 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       109\n",
      "           1       0.84      0.72      0.77       107\n",
      "           2       0.69      0.75      0.72       112\n",
      "\n",
      "    accuracy                           0.75       328\n",
      "   macro avg       0.76      0.75      0.75       328\n",
      "weighted avg       0.76      0.75      0.75       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78eb22e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93  4 12]\n",
      " [11 77 19]\n",
      " [20 13 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       109\n",
      "           1       0.82      0.72      0.77       107\n",
      "           2       0.72      0.71      0.71       113\n",
      "\n",
      "    accuracy                           0.76       329\n",
      "   macro avg       0.76      0.76      0.76       329\n",
      "weighted avg       0.76      0.76      0.76       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(C=1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "224b2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, kernel='poly',degree=5).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8f9ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95  6  8]\n",
      " [ 9 90  8]\n",
      " [ 8  6 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       109\n",
      "           1       0.88      0.84      0.86       107\n",
      "           2       0.86      0.88      0.87       112\n",
      "\n",
      "    accuracy                           0.86       328\n",
      "   macro avg       0.86      0.86      0.86       328\n",
      "weighted avg       0.86      0.86      0.86       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, kernel='poly',degree=5).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28f97f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   1   4]\n",
      " [  4  94   9]\n",
      " [ 11   7  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       109\n",
      "           1       0.92      0.88      0.90       107\n",
      "           2       0.88      0.84      0.86       113\n",
      "\n",
      "    accuracy                           0.89       329\n",
      "   macro avg       0.89      0.89      0.89       329\n",
      "weighted avg       0.89      0.89      0.89       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(C=0.1, kernel='poly',degree=5).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a35fe",
   "metadata": {},
   "source": [
    "### Slightly higher accuracy with lower-quality images (93% test/train, 92% val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87238b",
   "metadata": {},
   "source": [
    "### Show first image in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "638b3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9195681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2149cb453a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = np.array(x_train.T[0])\n",
    "first_image = np.reshape(first_image, (32, 32))\n",
    "plt.imshow(first_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bcb5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22490</th>\n",
       "      <th>22491</th>\n",
       "      <th>22492</th>\n",
       "      <th>22493</th>\n",
       "      <th>22494</th>\n",
       "      <th>22495</th>\n",
       "      <th>22496</th>\n",
       "      <th>22497</th>\n",
       "      <th>22498</th>\n",
       "      <th>22499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.327006</td>\n",
       "      <td>0.318834</td>\n",
       "      <td>0.323973</td>\n",
       "      <td>0.330377</td>\n",
       "      <td>0.326415</td>\n",
       "      <td>0.328089</td>\n",
       "      <td>0.337242</td>\n",
       "      <td>0.328654</td>\n",
       "      <td>0.329932</td>\n",
       "      <td>0.333666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331515</td>\n",
       "      <td>0.333384</td>\n",
       "      <td>0.330452</td>\n",
       "      <td>0.328314</td>\n",
       "      <td>0.322628</td>\n",
       "      <td>0.322367</td>\n",
       "      <td>0.322702</td>\n",
       "      <td>0.319377</td>\n",
       "      <td>0.313815</td>\n",
       "      <td>0.311721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315090</td>\n",
       "      <td>0.305533</td>\n",
       "      <td>0.310188</td>\n",
       "      <td>0.315768</td>\n",
       "      <td>0.307949</td>\n",
       "      <td>0.315844</td>\n",
       "      <td>0.323197</td>\n",
       "      <td>0.314478</td>\n",
       "      <td>0.315038</td>\n",
       "      <td>0.322184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.335710</td>\n",
       "      <td>0.333242</td>\n",
       "      <td>0.332373</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>0.329524</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.326194</td>\n",
       "      <td>0.321476</td>\n",
       "      <td>0.322470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.359144</td>\n",
       "      <td>0.358328</td>\n",
       "      <td>0.355936</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.362130</td>\n",
       "      <td>0.367018</td>\n",
       "      <td>0.364811</td>\n",
       "      <td>0.367274</td>\n",
       "      <td>0.365174</td>\n",
       "      <td>0.369566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389686</td>\n",
       "      <td>0.390984</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>0.378935</td>\n",
       "      <td>0.370978</td>\n",
       "      <td>0.372878</td>\n",
       "      <td>0.372166</td>\n",
       "      <td>0.370863</td>\n",
       "      <td>0.374950</td>\n",
       "      <td>0.382550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401388</td>\n",
       "      <td>0.402302</td>\n",
       "      <td>0.398677</td>\n",
       "      <td>0.402693</td>\n",
       "      <td>0.402017</td>\n",
       "      <td>0.407019</td>\n",
       "      <td>0.412162</td>\n",
       "      <td>0.412566</td>\n",
       "      <td>0.407532</td>\n",
       "      <td>0.412417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428547</td>\n",
       "      <td>0.426874</td>\n",
       "      <td>0.428182</td>\n",
       "      <td>0.419629</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.412099</td>\n",
       "      <td>0.416260</td>\n",
       "      <td>0.418466</td>\n",
       "      <td>0.418462</td>\n",
       "      <td>0.417367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.258747</td>\n",
       "      <td>0.268818</td>\n",
       "      <td>0.276975</td>\n",
       "      <td>0.280129</td>\n",
       "      <td>0.289476</td>\n",
       "      <td>0.297191</td>\n",
       "      <td>0.295294</td>\n",
       "      <td>0.301408</td>\n",
       "      <td>0.307391</td>\n",
       "      <td>0.307857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.202054</td>\n",
       "      <td>0.200099</td>\n",
       "      <td>0.194811</td>\n",
       "      <td>0.192479</td>\n",
       "      <td>0.185021</td>\n",
       "      <td>0.179744</td>\n",
       "      <td>0.177956</td>\n",
       "      <td>0.173525</td>\n",
       "      <td>0.164161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.346733</td>\n",
       "      <td>0.351356</td>\n",
       "      <td>0.343962</td>\n",
       "      <td>0.347722</td>\n",
       "      <td>0.348351</td>\n",
       "      <td>0.350051</td>\n",
       "      <td>0.353727</td>\n",
       "      <td>0.353337</td>\n",
       "      <td>0.352340</td>\n",
       "      <td>0.356897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373575</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>0.373009</td>\n",
       "      <td>0.367935</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>0.359693</td>\n",
       "      <td>0.359442</td>\n",
       "      <td>0.360760</td>\n",
       "      <td>0.364004</td>\n",
       "      <td>0.364267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.311937</td>\n",
       "      <td>0.303902</td>\n",
       "      <td>0.306983</td>\n",
       "      <td>0.313511</td>\n",
       "      <td>0.315812</td>\n",
       "      <td>0.320161</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>0.318960</td>\n",
       "      <td>0.322235</td>\n",
       "      <td>0.322686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324158</td>\n",
       "      <td>0.326775</td>\n",
       "      <td>0.327040</td>\n",
       "      <td>0.322469</td>\n",
       "      <td>0.312277</td>\n",
       "      <td>0.313013</td>\n",
       "      <td>0.314554</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.308911</td>\n",
       "      <td>0.311173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.387385</td>\n",
       "      <td>0.390794</td>\n",
       "      <td>0.392158</td>\n",
       "      <td>0.391510</td>\n",
       "      <td>0.392019</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.397026</td>\n",
       "      <td>0.396776</td>\n",
       "      <td>0.396274</td>\n",
       "      <td>0.401210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418971</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.422798</td>\n",
       "      <td>0.414337</td>\n",
       "      <td>0.404071</td>\n",
       "      <td>0.405130</td>\n",
       "      <td>0.406824</td>\n",
       "      <td>0.407180</td>\n",
       "      <td>0.413245</td>\n",
       "      <td>0.412668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.298772</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.303790</td>\n",
       "      <td>0.302127</td>\n",
       "      <td>0.305902</td>\n",
       "      <td>0.306402</td>\n",
       "      <td>0.310475</td>\n",
       "      <td>0.310777</td>\n",
       "      <td>0.310876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325296</td>\n",
       "      <td>0.325342</td>\n",
       "      <td>0.322559</td>\n",
       "      <td>0.315430</td>\n",
       "      <td>0.313968</td>\n",
       "      <td>0.316459</td>\n",
       "      <td>0.316828</td>\n",
       "      <td>0.317484</td>\n",
       "      <td>0.319236</td>\n",
       "      <td>0.319784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.265387</td>\n",
       "      <td>0.272453</td>\n",
       "      <td>0.283083</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.298789</td>\n",
       "      <td>0.305251</td>\n",
       "      <td>0.298716</td>\n",
       "      <td>0.296695</td>\n",
       "      <td>0.293735</td>\n",
       "      <td>0.303763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241893</td>\n",
       "      <td>0.242037</td>\n",
       "      <td>0.238980</td>\n",
       "      <td>0.236019</td>\n",
       "      <td>0.232405</td>\n",
       "      <td>0.230781</td>\n",
       "      <td>0.227324</td>\n",
       "      <td>0.222891</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>0.210335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows Ã— 22500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6      \\\n",
       "0    0.327006  0.318834  0.323973  0.330377  0.326415  0.328089  0.337242   \n",
       "1    0.315090  0.305533  0.310188  0.315768  0.307949  0.315844  0.323197   \n",
       "2    0.359144  0.358328  0.355936  0.361630  0.362130  0.367018  0.364811   \n",
       "3    0.401388  0.402302  0.398677  0.402693  0.402017  0.407019  0.412162   \n",
       "4    0.258747  0.268818  0.276975  0.280129  0.289476  0.297191  0.295294   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324  0.346733  0.351356  0.343962  0.347722  0.348351  0.350051  0.353727   \n",
       "325  0.311937  0.303902  0.306983  0.313511  0.315812  0.320161  0.324157   \n",
       "326  0.387385  0.390794  0.392158  0.391510  0.392019  0.394232  0.397026   \n",
       "327  0.300849  0.298772  0.295340  0.303790  0.302127  0.305902  0.306402   \n",
       "328  0.265387  0.272453  0.283083  0.297297  0.298789  0.305251  0.298716   \n",
       "\n",
       "        7         8         9      ...     22490     22491     22492  \\\n",
       "0    0.328654  0.329932  0.333666  ...  0.331515  0.333384  0.330452   \n",
       "1    0.314478  0.315038  0.322184  ...  0.334386  0.335710  0.333242   \n",
       "2    0.367274  0.365174  0.369566  ...  0.389686  0.390984  0.386920   \n",
       "3    0.412566  0.407532  0.412417  ...  0.428547  0.426874  0.428182   \n",
       "4    0.301408  0.307391  0.307857  ...  0.201299  0.202054  0.200099   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "324  0.353337  0.352340  0.356897  ...  0.373575  0.370718  0.373009   \n",
       "325  0.318960  0.322235  0.322686  ...  0.324158  0.326775  0.327040   \n",
       "326  0.396776  0.396274  0.401210  ...  0.418971  0.415215  0.422798   \n",
       "327  0.310475  0.310777  0.310876  ...  0.325296  0.325342  0.322559   \n",
       "328  0.296695  0.293735  0.303763  ...  0.241893  0.242037  0.238980   \n",
       "\n",
       "        22493     22494     22495     22496     22497     22498     22499  \n",
       "0    0.328314  0.322628  0.322367  0.322702  0.319377  0.313815  0.311721  \n",
       "1    0.332373  0.327756  0.329524  0.329309  0.326194  0.321476  0.322470  \n",
       "2    0.378935  0.370978  0.372878  0.372166  0.370863  0.374950  0.382550  \n",
       "3    0.419629  0.410377  0.412099  0.416260  0.418466  0.418462  0.417367  \n",
       "4    0.194811  0.192479  0.185021  0.179744  0.177956  0.173525  0.164161  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "324  0.367935  0.363422  0.359693  0.359442  0.360760  0.364004  0.364267  \n",
       "325  0.322469  0.312277  0.313013  0.314554  0.308421  0.308911  0.311173  \n",
       "326  0.414337  0.404071  0.405130  0.406824  0.407180  0.413245  0.412668  \n",
       "327  0.315430  0.313968  0.316459  0.316828  0.317484  0.319236  0.319784  \n",
       "328  0.236019  0.232405  0.230781  0.227324  0.222891  0.218296  0.210335  \n",
       "\n",
       "[329 rows x 22500 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da2984",
   "metadata": {},
   "source": [
    "### Compare misclassified and correctly classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48cd4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = svm.SVC(kernel='rbf', gamma=0.1, C=10).fit(x_train, y_train)\n",
    "pred_test = best_model.predict(x_test)\n",
    "missclassified_indices = []\n",
    "for i in range(0,y_test.size):\n",
    "    if y_test[i] != pred_test[i]:\n",
    "        missclassified_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd054e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27,\n",
       " 29,\n",
       " 41,\n",
       " 77,\n",
       " 85,\n",
       " 87,\n",
       " 93,\n",
       " 113,\n",
       " 126,\n",
       " 134,\n",
       " 138,\n",
       " 140,\n",
       " 144,\n",
       " 152,\n",
       " 156,\n",
       " 212,\n",
       " 219,\n",
       " 229,\n",
       " 231,\n",
       " 252,\n",
       " 261,\n",
       " 273,\n",
       " 302]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missclassified_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cc7cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 2\n",
      "Actual class 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[77]), (32, 32)))\n",
    "print(\"Predicted class\",pred_test[77])\n",
    "print(\"Actual class\",y_test[77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3b27c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 0\n",
      "Actual class 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYhklEQVR4nO2dbYxcZ3XH/2dedse7Xsfe+DWOE4cotI1ScMLKQg1CFChKKVKCVBCoQvkQYT4QtUi0UpRKJf1GqwJKpQrJlAhTUSAloKRVREnTpikSDWxCcJw4EByM7Xjx+t3rfZ+Z0w9zUznh/s/O3nkzef4/abWz98xz77nP3DN39vnPOcfcHUKINz6lQTsghOgPCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhEqnQw2s9sA3A+gDOAf3f2z0fOrQ6NeG9mw6uO4GXEgGhPsMLIVIDxWRJf9uKwocm5FVeAuq8eh6z3w0ZgtHJNvXJg7i+Wl2dxTKBzsZlYG8A8A/gDAMQA/MrNH3P0FNqY2sgE3v+NPc21e4lPcrObb2HYAaJapCc0KH+fBZx1mC8cEfvTzzYq+YRbc34oU2Wcz2F3wfRBrROOKHIvbogAs1SMbH8hs4f6W88c8++T9fAzf3YrsBvBzd3/Z3ZcAfAPA7R3sTwjRQzoJ9u0Ajl7y97FsmxDiMqSTYM/7oPZrny3MbI+ZTZrZ5PLSbAeHE0J0QifBfgzAjkv+vhrA8dc/yd33uvuEu09Uh0Y7OJwQohM6CfYfAbjBzK4zsyEAHwHwSHfcEkJ0m8Kr8e5eN7O7Afw7WtLbA+7+/IrjyKq7B54UWgWP3saKrnQzWw/8iNSJEDYsWmEuqgoUoejcNyMng5Mjq+4WvWbRSj03Fb4evUxiIjgv5mP0enWks7v7owAe7WQfQoj+oG/QCZEICnYhEkHBLkQiKNiFSAQFuxCJ0NFq/Gpx44khTSI/AIE0UUDOWHFcAVuUdNN1CQ0F5bBQ5is2rusUyQzDCnNMBkZqXXgHDJJuikqpTGKLYsKoPMjH6M4uRCIo2IVIBAW7EImgYBciERTsQiRCX1fjASu0ss5Wu4uuqker52FSC1voLLpiXVQV6PJqfNGV/6Llm+j+ogSURpfLUhWsJRcqFwHRudF9hgoEOxAfozu7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEqG/0psFMlqYCJO/PUye6UFyB62FF3RbKdwRpmjtOmLriWQUyXJkXGmZj6nMc62pshh1VIn8WL3GFp1X3IWoWNcdOldRFxnSESbK8NGdXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EInQkfRmZocBzKBVmavu7hPR892AZqVAPTnWMqpoZljBLC/qR1iDLvAjoqAsR/2P/CiSXYVYlisTqWz4fEF5jUlNACyQqIpIb0Xr3bFrG4ivESaxlRb5BJeJLZLruqGz/767n+rCfoQQPUQf44VIhE6D3QF8z8yeNrM93XBICNEbOv0Yf6u7HzezzQAeM7MX3f3JS5+QvQnsAYChkQ0dHk4IUZSO7uzufjz7PQ3gOwB25zxnr7tPuPtEpTbayeGEEB1QONjNbNTMxl59DOB9AA50yzEhRHfp5GP8FgDfsVbGVwXAP7v7d1ccRbOyomwiNiY4TkFZrlC2WSTzFXw7jVtbBTbiSywncVskr0XZZrVz+QdcM83T3kI/onZNde5kYzh/siK5rjLHfbTgWGGLpzI/OSOZatGxbCF/8qPCnIWD3d1fBvDWouOFEP1F0psQiaBgFyIRFOxCJIKCXYhEULALkQh97vUWFG0s0vesB73SQvmkiO9dLm5Z+HiR9Fawn1tllhuZxBYVbDx3/RC1NWrcj8jHpXX526PCl2umuR/rjvCBtZdPU5tdnKM2rxMNsxHIfEtL+YZFsh26swuRDAp2IRJBwS5EIijYhUgEBbsQidDX1XhrAtW5/KXT5RE+jq3gFl+xLlYrjNkKt2rqgZpAE40KqgLW4Lbaeb5avHRF/qX1yh18NXvtFWepbWZqjNpK83yy2GtWmecTsrSemjC3ha/Uj23ZSm2jU3yVvLyQP8le4ee1vDZ/fptP/gcdozu7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEqGv0ltjGLhwbb4WsmY6KHZWQDaK5LXwLa6AVNZ36a3IW3TBdljlRW6rXuSv2cm3VnO3//Y1R+mYZqAPHm3wk16Y43KYL+Vfb/Xg0h86F9SLCy7T2au4/xevHqY2J67UR3iGT5OMWfox90F3diESQcEuRCIo2IVIBAW7EImgYBciERTsQiTCitKbmT0A4AMApt39pmzbOIBvAtgJ4DCAD7s7T1lqAy+vvv1TLyiSUdYLorpqCOSfQrJcsL/yQtBOaJb3f7JGvvR2+PQ4HbNxbJbaNq+7SG1Lo/wCmVvMl+UuDK2hYxZHeFjYHD9WlEnXrPB5LC2xnl10CFCKLhAypI3nfAXAba/bdg+Ax939BgCPZ38LIS5jVgz2rN/6mddtvh3AvuzxPgB3dNctIUS3Kfo/+xZ3nwKA7Pfm7rkkhOgFPV+gM7M9ZjZpZpONOf4/mRCitxQN9hNmtg0Ast/T7InuvtfdJ9x9ojwyWvBwQohOKRrsjwC4M3t8J4CHu+OOEKJXtCO9fR3AuwBsNLNjAD4D4LMAHjSzuwAcAfChdg5mDaA6QwpOBjd9lsFmvnr5obXDgsOYFNIDua6wBMgKTgZv62VeCxHVoMWTNbltbnu+nnfDOFdox4d5i6RttfPU1gjuWWeW8iuZPoer6Jhz9eBi3MArcDY3BvJamY9bniVZe4vRi0aOxbajjWB3948S03tWGiuEuHzQN+iESAQFuxCJoGAXIhEU7EIkgoJdiEToa8HJCC+tXqMKi0pGhR7DbKLV24r2UeuFZEcJzst48hqGZnhK3IWdNWp79+89l7v9bWOH6Zj9szuobW2FV75cDtIip5v5PeLGakElTZ6Yh+UGP1YjKIq5vBRk0jG5rBn0JGSHCmRl3dmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCH2X3qhkEElNRE4oVFxxhXHd7qNWNHvNCxbZpP3ootZ3y9xWmefZWuev45fP+FB+oZJfLG7iBwtYaOYXsASAWnAC64fmc7f/0jfQMUt1Pvkjw/xYo0M8ffDMHC9wOT+X3weuPhxcjMur12Z1ZxciERTsQiSCgl2IRFCwC5EICnYhEqHvq/G0rVHBunD8QMVs0ao1XekO3jKb0Qz3IIHGWVug4MSqc0Hdshm+wlyZI7XTADx6+Mbc7TdvPUbHDJf4yn/VitlYksyOsXN0zNgQT5I5coav4p+/yBODmkECTbNOXptG8EJXyWsWqS7cJIR4I6FgFyIRFOxCJIKCXYhEULALkQgKdiESoZ32Tw8A+ACAaXe/Kdt2H4CPAziZPe1ed390xX15UO+M5zkUeksq3D6pyD4D2dB4CbeeJNAwSkGdueHz/ATqa7m8VlkM2j+RemzjQ7zFU0QzmJDlIGtoDeltde2a03RMaYyf1wu1bdQ2NbeO2k5e5C2l6iTxZiG6PuokKDqU3r4C4Lac7V9w913Zz4qBLoQYLCsGu7s/CeBMH3wRQvSQTv5nv9vM9pvZA2bGv1YkhLgsKBrsXwRwPYBdAKYAfI490cz2mNmkmU3WF/ILGgghek+hYHf3E+7ecPcmgC8B2B08d6+7T7j7RKUW9L0WQvSUQsFuZpcuSX4QwIHuuCOE6BXtSG9fB/AuABvN7BiAzwB4l5ntQkt0OgzgE+0ekGa9RbAxPZDXIv+ojBYdiydkhdlyFtXJi+aQSFSVQPGqznIn66Nc1jp9Ez/xf3nbl3O3LwX3l5kmzxqrGa/9dmhpM7U9evEtudvXVRbomIiloNXUcDnQN6N9ktZQPs+PVZolNpZBhzaC3d0/mrM5/5UUQly26Bt0QiSCgl2IRFCwC5EICnYhEkHBLkQi9L3gZCGYmlC0YGNAmG1GBwW26O20B1lvTDqMWjx5ie+wXuO2xhhP6Vvw/EvrdJN/sWpr+QK11YKikocWt1DbFdX89k8bqzN0zKnlMWq7sMTlwdNz/NyWl3molUr589io8AurFEhsdMyqRwghfiNRsAuRCAp2IRJBwS5EIijYhUgEBbsQidBf6c2CTK9uS14FbdG7X5P4GNQ7jOlBP7oiY6ozPFtrYcMwtY0c5Tv9+6n35m7/ky0/oGO2kOKQAHBg6Upq21DhRVHeXPtV7vbjy+vpmP3nt1Pb4VPj1OaFdFvQF8dYZhuAtYfzx5R5mzrd2YVIBQW7EImgYBciERTsQiSCgl2IROjrarwjWLnuclJLVEsuXDQtUiOvF4Qr9at3MkqcsDpPaKnOcVuzyleLd4yczd3+u0On6JiacR/HSvkJLQCwo8p7mBxdzl89/9dX8mvTAcCxE7wNggVzb2VuayzwUCufzbetf4nPx+iJ/MSgKOFJd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkQjvtn3YA+CqArQCaAPa6+/1mNg7gmwB2otUC6sPunq+3/CbR7bp2PUjWiaTDUoO0f5rnO5y9mtdVm93G7wcLG7ks986xF3O3X1NZS8ecavCEll/V11Pbw6d3UdvRi/ky2rl5fs5O5hAAfInLjVbjdfJK53mobX8ifx5Hf3qajkEzf0x5nmtv7dzZ6wA+7e6/A+DtAD5pZjcCuAfA4+5+A4DHs7+FEJcpKwa7u0+5+zPZ4xkABwFsB3A7gH3Z0/YBuKNHPgohusCq/mc3s50AbgbwFIAt7j4FtN4QAPBWmkKIgdN2sJvZWgAPAfiUu/MC378+bo+ZTZrZZH2B/08mhOgtbQW7mVXRCvSvufu3s80nzGxbZt8GYDpvrLvvdfcJd5+o1HgRfSFEb1kx2M3M0OrHftDdP3+J6REAd2aP7wTwcPfdE0J0i3ay3m4F8DEAz5nZs9m2ewF8FsCDZnYXgCMAPrTinqIadAWyzcLktYL13UKIj8YVqLA+XTQu8pHJawBgpJxc7Sw/WGWOS0bz40PckfW8ZtwtNLuNS2/fmnkztX335E3UttTkk7xheC53+5U1/i/lwQZvJzV3eoTaSqf4XF33CC8OV/rvH+dubw7z+n8lZqvzeoIrBru7fx/80nvPSuOFEJcH+gadEImgYBciERTsQiSCgl2IRFCwC5EIfW//1KzmL+xXL3Ltrb4mf7uXoh5JgR9dLipZtOtPYQLJjrX/qZ3iMlllhstCw5v4JeJ1fq94YfmK3O3PLFXpmCfO/ha13bhuitrmmlzyGinln/fPLvJvd8/P8Iy42jHu/9Yf8oyz6vNHqM2uuzZ3e2Ocy5SNcv7c+4FArqMWIcQbCgW7EImgYBciERTsQiSCgl2IRFCwC5EI/e31VgKWiZpQvcjHGUnKiiSvKKMsapUWJFAVIuw5Fw0M/C8FtgpJ5jp9E5eTFjcQbRPA6HHu5cghLnn9xaY/zt2+eS1/oRfqXNZaavAXZlMtuHgIL5+9ktqGf8Hlq83P8KyyNYeCApFbNlLT4qb8Og/1keBiJC+Ll3lQ6M4uRCIo2IVIBAW7EImgYBciERTsQiRCX1fjy4vA+pfyl9ZZggwANCv5tlKDrxTTWneIVywj6Mp6wRX30Iton9FbNLEZz9HA3HXcWN7NV7r96fzWSgBQfyJ/tfvQ5nE6pjLPZ+SXW/gq+PiOc9TGmHmB+3HN/wSJQVO8inrzCl6fbmEzVzwW1+evujejlXVy7bNYAXRnFyIZFOxCJIKCXYhEULALkQgKdiESQcEuRCKsKL2Z2Q4AXwWwFa30jL3ufr+Z3Qfg4wBOZk+9190fjfblBjSG86WBSDKgMlQgT4WtlYKBrdZ2BLLPUArrcquplfZZJ+rPul/wCbnqMZ5wMX0HTwr5ozt+SG1HZvNluQPHt9Exiye5PFU9z32cOc+TWobO5U/WNZOBvParGWqrrw/ktS18rhau4P43SRTG7cHIRRBcG+3o7HUAn3b3Z8xsDMDTZvZYZvuCu/9dG/sQQgyYdnq9TQGYyh7PmNlBANt77ZgQorus6n92M9sJ4GYAT2Wb7jaz/Wb2gJnxr1MJIQZO28FuZmsBPATgU+5+AcAXAVwPYBdad/7PkXF7zGzSzCbrC7xNrhCit7QV7GZWRSvQv+bu3wYAdz/h7g13bwL4EoDdeWPdfa+7T7j7RKWWX5FDCNF7Vgx2ay1PfxnAQXf//CXbL11W/SCAA913TwjRLdpZjb8VwMcAPGdmz2bb7gXwUTPbhZZIdBjAJ9o6YgEZrURq0DUjtS6qJVdQsvNuS4CRLBe9DQf7ZDLO3BY+IRt+xltDjf4vl5oOb+eS11Uj53O3L23ll9wra/JbRgHAuekxahs7GLRkemoud3t5lp/z0hbedml+Y1Anb4y/aEVahEX1C63JitDxMe2sxn8f+ZdlqKkLIS4v9A06IRJBwS5EIijYhUgEBbsQiaBgFyIR+lpw0sDlBCol/P/InK2RnFFY1goy4hqk8GWwu7DwZWALlZpon2T7EleucPEqLietP8SLUf70P6+ntheJj0P5ihwAoHaGz/1Vc9w2dJ7LaIz5bfwLXgtXcpmyvoa/MuHrSeRjgMuzoWwb9g7LR3d2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEJfpTc4UKozzSDo9UZ0hhKRwoA4I65w1luRzKVof0FmHs2wA2LZJcr2IyxcyU/MGvwSGT/IT469zqXlApoR4l6AjTX8nrU8ll8EcjHIUGvwupEh0WtdxBbL0atHd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkQt+lNyozNIJssxKRXQJpolQPZLlI8gre/krEx2aUo3aZvJ1G58WKVAKxLFcN2gCwDMFQvgxsRTPAmiShL5LyIsLrtMvSWygRK+tNCMFQsAuRCAp2IRJBwS5EIijYhUiEFVfjzawG4EkAw9nzv+XunzGzcQDfBLATrfZPH3b3s/HenH65vxQsxdKV5DBZhBvLUXIKW/kHwMqIlQJH4oSWYivC3SZaqY+SQpqV7vofrjBH7cF4mTy+zyKtlcBbkbXGcVuR44Xtn4gf0Zh27uyLAN7t7m9Fqz3zbWb2dgD3AHjc3W8A8Hj2txDiMmXFYPcWF7M/q9mPA7gdwL5s+z4Ad/TCQSFEd2i3P3s56+A6DeAxd38KwBZ3nwKA7PfmnnkphOiYtoLd3RvuvgvA1QB2m9lN7R7AzPaY2aSZTdYXg69cCSF6yqpW4939HIAnANwG4ISZbQOA7Pc0GbPX3SfcfaIyzAvzCyF6y4rBbmabzGx99ngNgPcCeBHAIwDuzJ52J4CHe+SjEKILtJMIsw3APjMro/Xm8KC7/5uZ/QDAg2Z2F4AjAD600o7MozY4q5c7wgSUgDDZhdbIA1imRlQqLEoyifWY4NwiF4ukNkX7i24HURsq4n7UBikiTCQpINlF8lpxCY3bWBJVuM9IRov2R1jx0nD3/QBuztl+GsB7Vn1EIcRA0DfohEgEBbsQiaBgFyIRFOxCJIKCXYhEMA/Tsrp8MLOTAH6Z/bkRwKm+HZwjP16L/Hgtv2l+XOvum/IMfQ321xzYbNLdJwZycPkhPxL0Qx/jhUgEBbsQiTDIYN87wGNfivx4LfLjtbxh/BjY/+xCiP6ij/FCJMJAgt3MbjOzn5rZz81sYLXrzOywmT1nZs+a2WQfj/uAmU2b2YFLto2b2WNm9lL2e8OA/LjPzF7J5uRZM3t/H/zYYWb/ZWYHzex5M/uzbHtf5yTwo69zYmY1M/uhmf0k8+Ovs+2dzYe79/UHQBnAIQBvAjAE4CcAbuy3H5kvhwFsHMBx3wngFgAHLtn2twDuyR7fA+BvBuTHfQD+vM/zsQ3ALdnjMQA/A3Bjv+ck8KOvc4JWLvXa7HEVwFMA3t7pfAzizr4bwM/d/WV3XwLwDbSKVyaDuz8J4MzrNve9gCfxo++4+5S7P5M9ngFwEMB29HlOAj/6irfoepHXQQT7dgBHL/n7GAYwoRkO4Htm9rSZ7RmQD69yORXwvNvM9mcf83v+78SlmNlOtOonDLSo6ev8APo8J70o8jqIYM+rYTIoSeBWd78FwB8C+KSZvXNAflxOfBHA9Wj1CJgC8Ll+HdjM1gJ4CMCn3P1Cv47bhh99nxPvoMgrYxDBfgzAjkv+vhrA8QH4AXc/nv2eBvAdtP7FGBRtFfDsNe5+IrvQmgC+hD7NiZlV0Qqwr7n7t7PNfZ+TPD8GNSfZsc9hlUVeGYMI9h8BuMHMrjOzIQAfQat4ZV8xs1EzG3v1MYD3ATgQj+opl0UBz1cvpowPog9zYmYG4MsADrr75y8x9XVOmB/9npOeFXnt1wrj61Yb34/WSuchAH85IB/ehJYS8BMAz/fTDwBfR+vj4DJan3TuAnAlWm20Xsp+jw/Ij38C8ByA/dnFta0PfrwDrX/l9gN4Nvt5f7/nJPCjr3MC4C0Afpwd7wCAv8q2dzQf+gadEImgb9AJkQgKdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiSCgl2IRPg/1XE9vOxHtLcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[78]), (32, 32)))\n",
    "print(\"Predicted class\",pred_test[78])\n",
    "print(\"Actual class\",y_test[78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c8cdb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 2\n",
      "Actual class 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[152]), (32, 32)))\n",
    "print(\"Predicted class\",pred_test[152])\n",
    "print(\"Actual class\",y_test[152])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f2ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 1\n",
      "Actual class 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[153]), (32, 32)))\n",
    "print(\"Predicted class\",pred_test[153])\n",
    "print(\"Actual class\",y_test[153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a47a5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 0\n",
      "Actual class 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[231]), (32, 32)))\n",
    "print(\"Predicted class\",pred_test[231])\n",
    "print(\"Actual class\",y_test[231])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f600fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 2\n",
      "Actual class 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[232]), (32, 32)))\n",
    "print(\"Predicted class\",pred_test[232])\n",
    "print(\"Actual class\",y_test[232])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512de34",
   "metadata": {},
   "source": [
    "### Test model on new dataset: 3 images of my own hand from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96756876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = 'rps-self'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d480156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178039</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.165139</td>\n",
       "      <td>0.172490</td>\n",
       "      <td>0.176392</td>\n",
       "      <td>0.166528</td>\n",
       "      <td>0.174237</td>\n",
       "      <td>0.190188</td>\n",
       "      <td>0.197409</td>\n",
       "      <td>0.186793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140960</td>\n",
       "      <td>0.133996</td>\n",
       "      <td>0.109639</td>\n",
       "      <td>0.111961</td>\n",
       "      <td>0.111690</td>\n",
       "      <td>0.111101</td>\n",
       "      <td>0.112002</td>\n",
       "      <td>0.107377</td>\n",
       "      <td>0.101553</td>\n",
       "      <td>0.113385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143245</td>\n",
       "      <td>0.153305</td>\n",
       "      <td>0.164382</td>\n",
       "      <td>0.168630</td>\n",
       "      <td>0.161523</td>\n",
       "      <td>0.167237</td>\n",
       "      <td>0.162833</td>\n",
       "      <td>0.183976</td>\n",
       "      <td>0.197247</td>\n",
       "      <td>0.183611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090048</td>\n",
       "      <td>0.092607</td>\n",
       "      <td>0.085328</td>\n",
       "      <td>0.089864</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>0.094777</td>\n",
       "      <td>0.100788</td>\n",
       "      <td>0.104504</td>\n",
       "      <td>0.107505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.176348</td>\n",
       "      <td>0.201244</td>\n",
       "      <td>0.195703</td>\n",
       "      <td>0.200994</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>0.198313</td>\n",
       "      <td>0.202585</td>\n",
       "      <td>0.227009</td>\n",
       "      <td>0.236194</td>\n",
       "      <td>0.218017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150978</td>\n",
       "      <td>0.154657</td>\n",
       "      <td>0.170402</td>\n",
       "      <td>0.172479</td>\n",
       "      <td>0.163641</td>\n",
       "      <td>0.151358</td>\n",
       "      <td>0.144133</td>\n",
       "      <td>0.143959</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.109082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156532</td>\n",
       "      <td>0.170136</td>\n",
       "      <td>0.183074</td>\n",
       "      <td>0.169675</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.173977</td>\n",
       "      <td>0.175296</td>\n",
       "      <td>0.179433</td>\n",
       "      <td>0.198849</td>\n",
       "      <td>0.203328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185190</td>\n",
       "      <td>0.177184</td>\n",
       "      <td>0.180812</td>\n",
       "      <td>0.161494</td>\n",
       "      <td>0.173493</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.146008</td>\n",
       "      <td>0.166176</td>\n",
       "      <td>0.182307</td>\n",
       "      <td>0.172834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176548</td>\n",
       "      <td>0.178792</td>\n",
       "      <td>0.208152</td>\n",
       "      <td>0.189680</td>\n",
       "      <td>0.181414</td>\n",
       "      <td>0.171399</td>\n",
       "      <td>0.187340</td>\n",
       "      <td>0.193791</td>\n",
       "      <td>0.206729</td>\n",
       "      <td>0.202104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175421</td>\n",
       "      <td>0.174297</td>\n",
       "      <td>0.179069</td>\n",
       "      <td>0.159136</td>\n",
       "      <td>0.144950</td>\n",
       "      <td>0.156650</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.171002</td>\n",
       "      <td>0.189619</td>\n",
       "      <td>0.178380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.218505</td>\n",
       "      <td>0.194592</td>\n",
       "      <td>0.182571</td>\n",
       "      <td>0.211803</td>\n",
       "      <td>0.201469</td>\n",
       "      <td>0.186450</td>\n",
       "      <td>0.182295</td>\n",
       "      <td>0.201280</td>\n",
       "      <td>0.196275</td>\n",
       "      <td>0.223188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201933</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>0.194983</td>\n",
       "      <td>0.187534</td>\n",
       "      <td>0.169350</td>\n",
       "      <td>0.191301</td>\n",
       "      <td>0.164963</td>\n",
       "      <td>0.150963</td>\n",
       "      <td>0.180181</td>\n",
       "      <td>0.181682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.229906</td>\n",
       "      <td>0.226549</td>\n",
       "      <td>0.223941</td>\n",
       "      <td>0.266388</td>\n",
       "      <td>0.253189</td>\n",
       "      <td>0.241487</td>\n",
       "      <td>0.230407</td>\n",
       "      <td>0.228665</td>\n",
       "      <td>0.220661</td>\n",
       "      <td>0.252231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226982</td>\n",
       "      <td>0.239590</td>\n",
       "      <td>0.207875</td>\n",
       "      <td>0.192654</td>\n",
       "      <td>0.205396</td>\n",
       "      <td>0.207685</td>\n",
       "      <td>0.232830</td>\n",
       "      <td>0.221853</td>\n",
       "      <td>0.192103</td>\n",
       "      <td>0.216310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.223898</td>\n",
       "      <td>0.237708</td>\n",
       "      <td>0.232963</td>\n",
       "      <td>0.256087</td>\n",
       "      <td>0.248619</td>\n",
       "      <td>0.251376</td>\n",
       "      <td>0.275604</td>\n",
       "      <td>0.259643</td>\n",
       "      <td>0.252373</td>\n",
       "      <td>0.256310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227808</td>\n",
       "      <td>0.241162</td>\n",
       "      <td>0.234708</td>\n",
       "      <td>0.247154</td>\n",
       "      <td>0.233753</td>\n",
       "      <td>0.234250</td>\n",
       "      <td>0.244511</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.243997</td>\n",
       "      <td>0.262670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.213048</td>\n",
       "      <td>0.228964</td>\n",
       "      <td>0.218947</td>\n",
       "      <td>0.203342</td>\n",
       "      <td>0.212881</td>\n",
       "      <td>0.227640</td>\n",
       "      <td>0.252077</td>\n",
       "      <td>0.247121</td>\n",
       "      <td>0.233355</td>\n",
       "      <td>0.232729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243442</td>\n",
       "      <td>0.239191</td>\n",
       "      <td>0.233412</td>\n",
       "      <td>0.236160</td>\n",
       "      <td>0.203854</td>\n",
       "      <td>0.221795</td>\n",
       "      <td>0.217661</td>\n",
       "      <td>0.201253</td>\n",
       "      <td>0.211146</td>\n",
       "      <td>0.206282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.178039  0.182196  0.165139  0.172490  0.176392  0.166528  0.174237   \n",
       "1  0.143245  0.153305  0.164382  0.168630  0.161523  0.167237  0.162833   \n",
       "2  0.176348  0.201244  0.195703  0.200994  0.195285  0.198313  0.202585   \n",
       "3  0.156532  0.170136  0.183074  0.169675  0.160600  0.173977  0.175296   \n",
       "4  0.176548  0.178792  0.208152  0.189680  0.181414  0.171399  0.187340   \n",
       "5  0.218505  0.194592  0.182571  0.211803  0.201469  0.186450  0.182295   \n",
       "6  0.229906  0.226549  0.223941  0.266388  0.253189  0.241487  0.230407   \n",
       "7  0.223898  0.237708  0.232963  0.256087  0.248619  0.251376  0.275604   \n",
       "8  0.213048  0.228964  0.218947  0.203342  0.212881  0.227640  0.252077   \n",
       "\n",
       "       7         8         9     ...      1014      1015      1016      1017  \\\n",
       "0  0.190188  0.197409  0.186793  ...  0.140960  0.133996  0.109639  0.111961   \n",
       "1  0.183976  0.197247  0.183611  ...  0.090048  0.092607  0.085328  0.089864   \n",
       "2  0.227009  0.236194  0.218017  ...  0.150978  0.154657  0.170402  0.172479   \n",
       "3  0.179433  0.198849  0.203328  ...  0.185190  0.177184  0.180812  0.161494   \n",
       "4  0.193791  0.206729  0.202104  ...  0.175421  0.174297  0.179069  0.159136   \n",
       "5  0.201280  0.196275  0.223188  ...  0.201933  0.188073  0.194983  0.187534   \n",
       "6  0.228665  0.220661  0.252231  ...  0.226982  0.239590  0.207875  0.192654   \n",
       "7  0.259643  0.252373  0.256310  ...  0.227808  0.241162  0.234708  0.247154   \n",
       "8  0.247121  0.233355  0.232729  ...  0.243442  0.239191  0.233412  0.236160   \n",
       "\n",
       "       1018      1019      1020      1021      1022      1023  \n",
       "0  0.111690  0.111101  0.112002  0.107377  0.101553  0.113385  \n",
       "1  0.098328  0.087142  0.094777  0.100788  0.104504  0.107505  \n",
       "2  0.163641  0.151358  0.144133  0.143959  0.132867  0.109082  \n",
       "3  0.173493  0.170275  0.146008  0.166176  0.182307  0.172834  \n",
       "4  0.144950  0.156650  0.155396  0.171002  0.189619  0.178380  \n",
       "5  0.169350  0.191301  0.164963  0.150963  0.180181  0.181682  \n",
       "6  0.205396  0.207685  0.232830  0.221853  0.192103  0.216310  \n",
       "7  0.233753  0.234250  0.244511  0.215764  0.243997  0.262670  \n",
       "8  0.203854  0.221795  0.217661  0.201253  0.211146  0.206282  \n",
       "\n",
       "[9 rows x 1024 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740f7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "517504d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21db30b2f10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(self_test.T[8]), (32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c10af4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = svm.SVC(kernel='rbf', gamma=0.1, C=10).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b01e4130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(self_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f9e46",
   "metadata": {},
   "source": [
    "### RBF classifies all new images as scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f376cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model = svm.SVC(C=0.1, kernel='poly',degree=5).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aa6e695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 0, 0, 2, 2, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_model.predict(self_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77523712",
   "metadata": {},
   "source": [
    "### Polynomial model confuses rock for scissors and paper for rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bea619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be23c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.predict(self_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d67587",
   "metadata": {},
   "source": [
    "### Linear model predicts nearly all as paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65403c26",
   "metadata": {},
   "source": [
    "## Test Yite's images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7323047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = 'rps-self-yite'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1457a78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2790b56b640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(self_test.T[1]), (32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088e9d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = svm.SVC(kernel='rbf', gamma=0.1, C=10).fit(x_train, y_train)\n",
    "best_model.predict(self_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03123e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_model = svm.SVC(C=0.1, kernel='poly',degree=5).fit(x_train, y_train)\n",
    "poly_model.predict(self_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b38eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train)\n",
    "linear_model.predict(self_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b7369",
   "metadata": {},
   "source": [
    "### Test all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef89d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = 'rps-self-all'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd826ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual 0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    2\n",
      "11    2\n",
      "12    2\n",
      "13    2\n",
      "Name: Target, dtype: int32\n",
      "Predicted [2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[[0 0 5]\n",
      " [0 0 5]\n",
      " [0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.29        14\n",
      "   macro avg       0.10      0.33      0.15        14\n",
      "weighted avg       0.08      0.29      0.13        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_model = svm.SVC(kernel='rbf', gamma=0.1, C=10).fit(x_train, y_train)\n",
    "print('Actual',y_self_test)\n",
    "print('Predicted',best_model.predict(self_test))\n",
    "print(confusion_matrix(y_self_test,best_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,best_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52887075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 3]\n",
      " [3 2 0]\n",
      " [0 1 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22         5\n",
      "           1       0.50      0.40      0.44         5\n",
      "           2       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.42      0.45      0.42        14\n",
      "weighted avg       0.41      0.43      0.41        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poly_model = svm.SVC(C=0.1, kernel='poly',degree=5).fit(x_train, y_train)\n",
    "poly_model.predict(self_test)\n",
    "print(confusion_matrix(y_self_test,poly_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,poly_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "837532f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 0]\n",
      " [0 5 0]\n",
      " [0 3 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      1.00      0.56         5\n",
      "           2       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.46      0.42      0.32        14\n",
      "weighted avg       0.42      0.43      0.31        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "linear_model = svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train)\n",
    "linear_model.predict(self_test)\n",
    "print(confusion_matrix(y_self_test,linear_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,linear_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a531040",
   "metadata": {},
   "source": [
    "## Try additional color channels and data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faafea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3baf66",
   "metadata": {},
   "source": [
    "#### Import dataset with 3 color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4a45dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = 'rps-split\\\\train'\n",
    "test_dir = 'rps-split\\\\test'\n",
    "val_dir = 'rps-split\\\\val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef814196",
   "metadata": {},
   "source": [
    "#### Import real data with 3 color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c8edab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = 'rps-self-all'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef483741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108830</td>\n",
       "      <td>0.463414</td>\n",
       "      <td>0.157114</td>\n",
       "      <td>0.124407</td>\n",
       "      <td>0.489254</td>\n",
       "      <td>0.172612</td>\n",
       "      <td>0.138039</td>\n",
       "      <td>0.513397</td>\n",
       "      <td>0.184481</td>\n",
       "      <td>0.150127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178772</td>\n",
       "      <td>0.135868</td>\n",
       "      <td>0.477676</td>\n",
       "      <td>0.169225</td>\n",
       "      <td>0.128376</td>\n",
       "      <td>0.461942</td>\n",
       "      <td>0.160699</td>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.443389</td>\n",
       "      <td>0.142613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129428</td>\n",
       "      <td>0.470184</td>\n",
       "      <td>0.143679</td>\n",
       "      <td>0.131994</td>\n",
       "      <td>0.475316</td>\n",
       "      <td>0.146401</td>\n",
       "      <td>0.135608</td>\n",
       "      <td>0.484888</td>\n",
       "      <td>0.150483</td>\n",
       "      <td>0.142385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161022</td>\n",
       "      <td>0.143173</td>\n",
       "      <td>0.514002</td>\n",
       "      <td>0.157377</td>\n",
       "      <td>0.145854</td>\n",
       "      <td>0.506688</td>\n",
       "      <td>0.152899</td>\n",
       "      <td>0.145579</td>\n",
       "      <td>0.493592</td>\n",
       "      <td>0.146199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078939</td>\n",
       "      <td>0.451715</td>\n",
       "      <td>0.126664</td>\n",
       "      <td>0.092288</td>\n",
       "      <td>0.476566</td>\n",
       "      <td>0.137153</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.501697</td>\n",
       "      <td>0.150728</td>\n",
       "      <td>0.117815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159440</td>\n",
       "      <td>0.105213</td>\n",
       "      <td>0.464285</td>\n",
       "      <td>0.150961</td>\n",
       "      <td>0.098209</td>\n",
       "      <td>0.449014</td>\n",
       "      <td>0.137307</td>\n",
       "      <td>0.087127</td>\n",
       "      <td>0.430828</td>\n",
       "      <td>0.119002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140160</td>\n",
       "      <td>0.466437</td>\n",
       "      <td>0.154236</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>0.471882</td>\n",
       "      <td>0.157326</td>\n",
       "      <td>0.144727</td>\n",
       "      <td>0.480557</td>\n",
       "      <td>0.165120</td>\n",
       "      <td>0.153548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.144018</td>\n",
       "      <td>0.512511</td>\n",
       "      <td>0.172204</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>0.503935</td>\n",
       "      <td>0.166650</td>\n",
       "      <td>0.143984</td>\n",
       "      <td>0.492599</td>\n",
       "      <td>0.160677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088967</td>\n",
       "      <td>0.385828</td>\n",
       "      <td>0.083938</td>\n",
       "      <td>0.102310</td>\n",
       "      <td>0.416022</td>\n",
       "      <td>0.094970</td>\n",
       "      <td>0.114495</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.101970</td>\n",
       "      <td>0.125345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>0.103394</td>\n",
       "      <td>0.377319</td>\n",
       "      <td>0.086606</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.357588</td>\n",
       "      <td>0.070008</td>\n",
       "      <td>0.081573</td>\n",
       "      <td>0.337626</td>\n",
       "      <td>0.050206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.476359</td>\n",
       "      <td>0.175379</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.181696</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>0.496879</td>\n",
       "      <td>0.187580</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187209</td>\n",
       "      <td>0.151214</td>\n",
       "      <td>0.528120</td>\n",
       "      <td>0.180376</td>\n",
       "      <td>0.152756</td>\n",
       "      <td>0.519160</td>\n",
       "      <td>0.175594</td>\n",
       "      <td>0.156123</td>\n",
       "      <td>0.509827</td>\n",
       "      <td>0.168156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.183925</td>\n",
       "      <td>0.563155</td>\n",
       "      <td>0.237095</td>\n",
       "      <td>0.187686</td>\n",
       "      <td>0.566899</td>\n",
       "      <td>0.239423</td>\n",
       "      <td>0.186889</td>\n",
       "      <td>0.563707</td>\n",
       "      <td>0.233813</td>\n",
       "      <td>0.185417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281364</td>\n",
       "      <td>0.181962</td>\n",
       "      <td>0.618131</td>\n",
       "      <td>0.274702</td>\n",
       "      <td>0.183103</td>\n",
       "      <td>0.612920</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.186219</td>\n",
       "      <td>0.607259</td>\n",
       "      <td>0.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.123528</td>\n",
       "      <td>0.452343</td>\n",
       "      <td>0.134468</td>\n",
       "      <td>0.124134</td>\n",
       "      <td>0.457455</td>\n",
       "      <td>0.135964</td>\n",
       "      <td>0.130137</td>\n",
       "      <td>0.466220</td>\n",
       "      <td>0.142174</td>\n",
       "      <td>0.139311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159352</td>\n",
       "      <td>0.130332</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.154037</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.484625</td>\n",
       "      <td>0.144838</td>\n",
       "      <td>0.136010</td>\n",
       "      <td>0.471652</td>\n",
       "      <td>0.141260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.118283</td>\n",
       "      <td>0.469137</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>0.120079</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>0.171203</td>\n",
       "      <td>0.124662</td>\n",
       "      <td>0.484316</td>\n",
       "      <td>0.175231</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175046</td>\n",
       "      <td>0.127169</td>\n",
       "      <td>0.512215</td>\n",
       "      <td>0.172307</td>\n",
       "      <td>0.129316</td>\n",
       "      <td>0.505641</td>\n",
       "      <td>0.167567</td>\n",
       "      <td>0.132661</td>\n",
       "      <td>0.495388</td>\n",
       "      <td>0.160971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.161738</td>\n",
       "      <td>0.539194</td>\n",
       "      <td>0.217256</td>\n",
       "      <td>0.163675</td>\n",
       "      <td>0.546841</td>\n",
       "      <td>0.219793</td>\n",
       "      <td>0.169299</td>\n",
       "      <td>0.554800</td>\n",
       "      <td>0.225009</td>\n",
       "      <td>0.175303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253370</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.605169</td>\n",
       "      <td>0.250210</td>\n",
       "      <td>0.185849</td>\n",
       "      <td>0.600204</td>\n",
       "      <td>0.247468</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.593737</td>\n",
       "      <td>0.249707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows Ã— 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.108830  0.463414  0.157114  0.124407  0.489254  0.172612  0.138039   \n",
       "1     0.129428  0.470184  0.143679  0.131994  0.475316  0.146401  0.135608   \n",
       "2     0.078939  0.451715  0.126664  0.092288  0.476566  0.137153  0.105979   \n",
       "3     0.140160  0.466437  0.154236  0.139363  0.471882  0.157326  0.144727   \n",
       "4     0.088967  0.385828  0.083938  0.102310  0.416022  0.094970  0.114495   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.146447  0.476359  0.175379  0.151458  0.486339  0.181696  0.157324   \n",
       "1527  0.183925  0.563155  0.237095  0.187686  0.566899  0.239423  0.186889   \n",
       "1528  0.123528  0.452343  0.134468  0.124134  0.457455  0.135964  0.130137   \n",
       "1529  0.118283  0.469137  0.167031  0.120079  0.476526  0.171203  0.124662   \n",
       "1530  0.161738  0.539194  0.217256  0.163675  0.546841  0.219793  0.169299   \n",
       "\n",
       "          7         8         9     ...      3062      3063      3064  \\\n",
       "0     0.513397  0.184481  0.150127  ...  0.178772  0.135868  0.477676   \n",
       "1     0.484888  0.150483  0.142385  ...  0.161022  0.143173  0.514002   \n",
       "2     0.501697  0.150728  0.117815  ...  0.159440  0.105213  0.464285   \n",
       "3     0.480557  0.165120  0.153548  ...  0.174945  0.144018  0.512511   \n",
       "4     0.438849  0.101970  0.125345  ...  0.093792  0.103394  0.377319   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.496879  0.187580  0.158730  ...  0.187209  0.151214  0.528120   \n",
       "1527  0.563707  0.233813  0.185417  ...  0.281364  0.181962  0.618131   \n",
       "1528  0.466220  0.142174  0.139311  ...  0.159352  0.130332  0.493976   \n",
       "1529  0.484316  0.175231  0.135098  ...  0.175046  0.127169  0.512215   \n",
       "1530  0.554800  0.225009  0.175303  ...  0.253370  0.185700  0.605169   \n",
       "\n",
       "          3065      3066      3067      3068      3069      3070      3071  \n",
       "0     0.169225  0.128376  0.461942  0.160699  0.117872  0.443389  0.142613  \n",
       "1     0.157377  0.145854  0.506688  0.152899  0.145579  0.493592  0.146199  \n",
       "2     0.150961  0.098209  0.449014  0.137307  0.087127  0.430828  0.119002  \n",
       "3     0.172204  0.145946  0.503935  0.166650  0.143984  0.492599  0.160677  \n",
       "4     0.086606  0.093341  0.357588  0.070008  0.081573  0.337626  0.050206  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.180376  0.152756  0.519160  0.175594  0.156123  0.509827  0.168156  \n",
       "1527  0.274702  0.183103  0.612920  0.272439  0.186219  0.607259  0.272900  \n",
       "1528  0.154037  0.132317  0.484625  0.144838  0.136010  0.471652  0.141260  \n",
       "1529  0.172307  0.129316  0.505641  0.167567  0.132661  0.495388  0.160971  \n",
       "1530  0.250210  0.185849  0.600204  0.247468  0.189700  0.593737  0.249707  \n",
       "\n",
       "[1531 rows x 3072 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28267ba",
   "metadata": {},
   "source": [
    "### 3 color channels without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31aeaca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.342 total time=   5.5s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.5s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.2s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time=   4.2s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.503 total time=   4.2s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.487 total time=   3.8s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.484 total time=   3.7s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.520 total time=   3.7s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.619 total time=   3.7s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.601 total time=   3.7s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.588 total time=   3.7s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.650 total time=   3.8s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.585 total time=   3.8s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.342 total time=   3.8s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   3.8s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   3.9s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   3.9s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   3.9s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.541 total time=   3.7s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.542 total time=   3.8s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.526 total time=   3.7s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.526 total time=   3.8s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.552 total time=   3.8s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.873 total time=   2.6s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.863 total time=   2.7s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.876 total time=   2.7s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.863 total time=   2.6s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.882 total time=   2.6s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.896 total time=   3.7s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.869 total time=   3.7s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.908 total time=   3.6s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.918 total time=   3.7s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.873 total time=   3.6s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.378 total time=   4.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.369 total time=   4.1s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.376 total time=   4.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.366 total time=   3.8s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.353 total time=   3.9s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.866 total time=   2.6s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.863 total time=   2.5s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.866 total time=   2.5s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.850 total time=   2.5s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.879 total time=   2.6s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.954 total time=   1.5s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.951 total time=   1.4s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.951 total time=   1.4s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.928 total time=   1.4s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.928 total time=   1.4s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.902 total time=   3.7s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.886 total time=   3.7s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.915 total time=   3.6s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.915 total time=   3.6s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.873 total time=   3.7s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.404 total time=   3.8s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.392 total time=   3.9s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.386 total time=   3.8s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.395 total time=   3.9s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.353 total time=   3.9s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.948 total time=   1.5s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.944 total time=   1.6s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.935 total time=   1.5s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.912 total time=   1.5s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.908 total time=   1.5s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.961 total time=   1.1s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.961 total time=   1.1s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.961 total time=   1.1s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.951 total time=   1.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.958 total time=   1.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.902 total time=   3.7s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.886 total time=   4.1s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.915 total time=   3.9s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.915 total time=   3.7s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.873 total time=   3.6s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.404 total time=   4.1s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.392 total time=   4.3s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.386 total time=   3.9s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.395 total time=   3.9s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.353 total time=   3.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "306f3500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END ......C=0.1, degree=3, kernel=poly;, score=0.964 total time=   1.2s\n",
      "[CV 2/5] END ......C=0.1, degree=3, kernel=poly;, score=0.964 total time=   1.3s\n",
      "[CV 3/5] END ......C=0.1, degree=3, kernel=poly;, score=0.948 total time=   1.4s\n",
      "[CV 4/5] END ......C=0.1, degree=3, kernel=poly;, score=0.944 total time=   1.3s\n",
      "[CV 5/5] END ......C=0.1, degree=3, kernel=poly;, score=0.935 total time=   1.2s\n",
      "[CV 1/5] END ......C=0.1, degree=4, kernel=poly;, score=0.974 total time=   0.9s\n",
      "[CV 2/5] END ......C=0.1, degree=4, kernel=poly;, score=0.967 total time=   0.9s\n",
      "[CV 3/5] END ......C=0.1, degree=4, kernel=poly;, score=0.961 total time=   0.9s\n",
      "[CV 4/5] END ......C=0.1, degree=4, kernel=poly;, score=0.944 total time=   0.9s\n",
      "[CV 5/5] END ......C=0.1, degree=4, kernel=poly;, score=0.964 total time=   0.9s\n",
      "[CV 1/5] END ......C=0.1, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 2/5] END ......C=0.1, degree=5, kernel=poly;, score=0.971 total time=   0.9s\n",
      "[CV 3/5] END ......C=0.1, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 4/5] END ......C=0.1, degree=5, kernel=poly;, score=0.954 total time=   1.0s\n",
      "[CV 5/5] END ......C=0.1, degree=5, kernel=poly;, score=0.958 total time=   0.9s\n",
      "[CV 1/5] END ........C=1, degree=3, kernel=poly;, score=0.971 total time=   1.0s\n",
      "[CV 2/5] END ........C=1, degree=3, kernel=poly;, score=0.964 total time=   1.0s\n",
      "[CV 3/5] END ........C=1, degree=3, kernel=poly;, score=0.961 total time=   1.0s\n",
      "[CV 4/5] END ........C=1, degree=3, kernel=poly;, score=0.951 total time=   1.0s\n",
      "[CV 5/5] END ........C=1, degree=3, kernel=poly;, score=0.958 total time=   1.1s\n",
      "[CV 1/5] END ........C=1, degree=4, kernel=poly;, score=0.967 total time=   1.0s\n",
      "[CV 2/5] END ........C=1, degree=4, kernel=poly;, score=0.974 total time=   0.9s\n",
      "[CV 3/5] END ........C=1, degree=4, kernel=poly;, score=0.958 total time=   1.0s\n",
      "[CV 4/5] END ........C=1, degree=4, kernel=poly;, score=0.958 total time=   1.0s\n",
      "[CV 5/5] END ........C=1, degree=4, kernel=poly;, score=0.964 total time=   0.9s\n",
      "[CV 1/5] END ........C=1, degree=5, kernel=poly;, score=0.954 total time=   1.0s\n",
      "[CV 2/5] END ........C=1, degree=5, kernel=poly;, score=0.971 total time=   0.9s\n",
      "[CV 3/5] END ........C=1, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 4/5] END ........C=1, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 5/5] END ........C=1, degree=5, kernel=poly;, score=0.958 total time=   0.9s\n",
      "[CV 1/5] END .......C=10, degree=3, kernel=poly;, score=0.967 total time=   1.0s\n",
      "[CV 2/5] END .......C=10, degree=3, kernel=poly;, score=0.971 total time=   1.0s\n",
      "[CV 3/5] END .......C=10, degree=3, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 4/5] END .......C=10, degree=3, kernel=poly;, score=0.948 total time=   1.0s\n",
      "[CV 5/5] END .......C=10, degree=3, kernel=poly;, score=0.961 total time=   1.1s\n",
      "[CV 1/5] END .......C=10, degree=4, kernel=poly;, score=0.967 total time=   1.0s\n",
      "[CV 2/5] END .......C=10, degree=4, kernel=poly;, score=0.974 total time=   1.0s\n",
      "[CV 3/5] END .......C=10, degree=4, kernel=poly;, score=0.958 total time=   0.9s\n",
      "[CV 4/5] END .......C=10, degree=4, kernel=poly;, score=0.958 total time=   1.0s\n",
      "[CV 5/5] END .......C=10, degree=4, kernel=poly;, score=0.964 total time=   0.9s\n",
      "[CV 1/5] END .......C=10, degree=5, kernel=poly;, score=0.954 total time=   1.0s\n",
      "[CV 2/5] END .......C=10, degree=5, kernel=poly;, score=0.971 total time=   0.9s\n",
      "[CV 3/5] END .......C=10, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 4/5] END .......C=10, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 5/5] END .......C=10, degree=5, kernel=poly;, score=0.958 total time=   0.9s\n",
      "[CV 1/5] END ......C=100, degree=3, kernel=poly;, score=0.967 total time=   1.0s\n",
      "[CV 2/5] END ......C=100, degree=3, kernel=poly;, score=0.971 total time=   1.0s\n",
      "[CV 3/5] END ......C=100, degree=3, kernel=poly;, score=0.954 total time=   1.0s\n",
      "[CV 4/5] END ......C=100, degree=3, kernel=poly;, score=0.948 total time=   1.0s\n",
      "[CV 5/5] END ......C=100, degree=3, kernel=poly;, score=0.961 total time=   0.9s\n",
      "[CV 1/5] END ......C=100, degree=4, kernel=poly;, score=0.967 total time=   1.0s\n",
      "[CV 2/5] END ......C=100, degree=4, kernel=poly;, score=0.974 total time=   0.9s\n",
      "[CV 3/5] END ......C=100, degree=4, kernel=poly;, score=0.958 total time=   0.9s\n",
      "[CV 4/5] END ......C=100, degree=4, kernel=poly;, score=0.958 total time=   1.0s\n",
      "[CV 5/5] END ......C=100, degree=4, kernel=poly;, score=0.964 total time=   1.0s\n",
      "[CV 1/5] END ......C=100, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 2/5] END ......C=100, degree=5, kernel=poly;, score=0.971 total time=   0.9s\n",
      "[CV 3/5] END ......C=100, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 4/5] END ......C=100, degree=5, kernel=poly;, score=0.954 total time=   0.9s\n",
      "[CV 5/5] END ......C=100, degree=5, kernel=poly;, score=0.958 total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'degree': [3, 4, 5],\n",
       "                         'kernel': ['poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[0.1,1,10,100],'degree':[3,4,5],'kernel':['poly']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40d3703f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END ..............C=0.1, kernel=linear;, score=0.958 total time=   1.0s\n",
      "[CV 2/5] END ..............C=0.1, kernel=linear;, score=0.958 total time=   1.0s\n",
      "[CV 3/5] END ..............C=0.1, kernel=linear;, score=0.944 total time=   1.0s\n",
      "[CV 4/5] END ..............C=0.1, kernel=linear;, score=0.928 total time=   1.0s\n",
      "[CV 5/5] END ..............C=0.1, kernel=linear;, score=0.935 total time=   1.0s\n",
      "[CV 1/5] END ................C=1, kernel=linear;, score=0.925 total time=   0.9s\n",
      "[CV 2/5] END ................C=1, kernel=linear;, score=0.941 total time=   0.9s\n",
      "[CV 3/5] END ................C=1, kernel=linear;, score=0.922 total time=   0.9s\n",
      "[CV 4/5] END ................C=1, kernel=linear;, score=0.931 total time=   0.9s\n",
      "[CV 5/5] END ................C=1, kernel=linear;, score=0.912 total time=   0.9s\n",
      "[CV 1/5] END ...............C=10, kernel=linear;, score=0.925 total time=   1.0s\n",
      "[CV 2/5] END ...............C=10, kernel=linear;, score=0.941 total time=   0.9s\n",
      "[CV 3/5] END ...............C=10, kernel=linear;, score=0.922 total time=   0.9s\n",
      "[CV 4/5] END ...............C=10, kernel=linear;, score=0.925 total time=   1.0s\n",
      "[CV 5/5] END ...............C=10, kernel=linear;, score=0.905 total time=   1.0s\n",
      "[CV 1/5] END ..............C=100, kernel=linear;, score=0.925 total time=   1.1s\n",
      "[CV 2/5] END ..............C=100, kernel=linear;, score=0.941 total time=   1.0s\n",
      "[CV 3/5] END ..............C=100, kernel=linear;, score=0.922 total time=   1.1s\n",
      "[CV 4/5] END ..............C=100, kernel=linear;, score=0.925 total time=   1.0s\n",
      "[CV 5/5] END ..............C=100, kernel=linear;, score=0.905 total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'kernel': ['linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'kernel':['linear']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41b9cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size = 1):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48e95a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_test)\n",
    "    print(confusion_matrix(y_test,pred_y))\n",
    "    print(classification_report(y_test,pred_y))\n",
    "    \n",
    "def train_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_train)\n",
    "    print(confusion_matrix(y_train,pred_y))\n",
    "    print(classification_report(y_train,pred_y))\n",
    "    \n",
    "def val_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_val)\n",
    "    print(confusion_matrix(y_val,pred_y))\n",
    "    print(classification_report(y_val,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f09a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[505   1   2]\n",
      " [  2 493   3]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       508\n",
      "           1       1.00      0.99      0.99       498\n",
      "           2       0.99      1.00      1.00       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d2cad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   2   6]\n",
      " [  8  95   4]\n",
      " [  0   1 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       109\n",
      "           1       0.97      0.89      0.93       107\n",
      "           2       0.92      0.99      0.95       112\n",
      "\n",
      "    accuracy                           0.94       328\n",
      "   macro avg       0.94      0.94      0.94       328\n",
      "weighted avg       0.94      0.94      0.94       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dd1b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbb325b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   1   4]\n",
      " [  9  95   3]\n",
      " [  0   1 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       109\n",
      "           1       0.98      0.89      0.93       107\n",
      "           2       0.94      0.99      0.97       112\n",
      "\n",
      "    accuracy                           0.95       328\n",
      "   macro avg       0.95      0.94      0.94       328\n",
      "weighted avg       0.95      0.95      0.94       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb8a2717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[500   3   5]\n",
      " [  7 478  13]\n",
      " [  2   1 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       508\n",
      "           1       0.99      0.96      0.98       498\n",
      "           2       0.97      0.99      0.98       525\n",
      "\n",
      "    accuracy                           0.98      1531\n",
      "   macro avg       0.98      0.98      0.98      1531\n",
      "weighted avg       0.98      0.98      0.98      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a7d72c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   4   7]\n",
      " [ 10  93   4]\n",
      " [  0   4 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       109\n",
      "           1       0.92      0.87      0.89       107\n",
      "           2       0.91      0.96      0.94       112\n",
      "\n",
      "    accuracy                           0.91       328\n",
      "   macro avg       0.91      0.91      0.91       328\n",
      "weighted avg       0.91      0.91      0.91       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "354df693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   0   3]\n",
      " [  3 101   3]\n",
      " [  4   2 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       109\n",
      "           1       0.98      0.94      0.96       107\n",
      "           2       0.95      0.95      0.95       113\n",
      "\n",
      "    accuracy                           0.95       329\n",
      "   macro avg       0.96      0.95      0.95       329\n",
      "weighted avg       0.95      0.95      0.95       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf37344",
   "metadata": {},
   "source": [
    "#### Real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de5be88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 1]\n",
      " [2 2 1]\n",
      " [0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73         5\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.78      0.73      0.70        14\n",
      "weighted avg       0.79      0.71      0.69        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbf_model = svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train)\n",
    "print(confusion_matrix(y_self_test,rbf_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,rbf_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3035bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 2]\n",
      " [4 1 0]\n",
      " [1 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.60      0.46         5\n",
      "           1       1.00      0.20      0.33         5\n",
      "           2       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.66      0.52      0.49        14\n",
      "weighted avg       0.66      0.50      0.47        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poly_model = svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train)\n",
    "print(confusion_matrix(y_self_test,poly_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,poly_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4eb0eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 0]\n",
      " [2 3 0]\n",
      " [0 1 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.50      0.60      0.55         5\n",
      "           2       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.70      0.65      0.67        14\n",
      "weighted avg       0.68      0.64      0.65        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_model = svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train)\n",
    "print(confusion_matrix(y_self_test,linear_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,linear_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1b142",
   "metadata": {},
   "source": [
    "### Replace original training data with augmented data (random rotating, flipping, and zooming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "735f4787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 508 image(s) found.\n",
      "Output directory set to rps-split\\train\\rock\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=300x200 at 0x225EE8984C0>: 100%|â–ˆ| 508/508 [00:03<00:00, 128.40 Samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 498 image(s) found.\n",
      "Output directory set to rps-split\\train\\paper\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=300x200 at 0x225E8012640>: 100%|â–ˆ| 498/498 [00:03<00:00, 131.02 Samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 525 image(s) found.\n",
      "Output directory set to rps-split\\train\\scissors\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=300x200 at 0x225EE8A7130>: 100%|â–ˆ| 525/525 [00:03<00:00, 134.00 Samples\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "# Passing the path of the image directory\n",
    "p = Augmentor.Pipeline(os.path.join(train_dir,'rock'))\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(508)\n",
    "\n",
    "p = Augmentor.Pipeline(os.path.join(train_dir,'paper'))\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(498)\n",
    "\n",
    "p = Augmentor.Pipeline(os.path.join(train_dir,'scissors'))\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(525)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42287e93",
   "metadata": {},
   "source": [
    "### Note: we need to move the augmented data to a new folder separate from the original images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccee126",
   "metadata": {},
   "source": [
    "#### Load augmented training data and original test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "129b6f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = 'rps-augmented'\n",
    "test_dir = 'rps-split\\\\test'\n",
    "val_dir = 'rps-split\\\\val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9b9a43aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.503224</td>\n",
       "      <td>0.377374</td>\n",
       "      <td>0.236031</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.387029</td>\n",
       "      <td>0.251523</td>\n",
       "      <td>0.491603</td>\n",
       "      <td>0.357519</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238196</td>\n",
       "      <td>0.150798</td>\n",
       "      <td>0.580239</td>\n",
       "      <td>0.234891</td>\n",
       "      <td>0.145466</td>\n",
       "      <td>0.573147</td>\n",
       "      <td>0.228163</td>\n",
       "      <td>0.148683</td>\n",
       "      <td>0.576832</td>\n",
       "      <td>0.229349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319037</td>\n",
       "      <td>0.259975</td>\n",
       "      <td>0.165347</td>\n",
       "      <td>0.326856</td>\n",
       "      <td>0.268294</td>\n",
       "      <td>0.171164</td>\n",
       "      <td>0.323741</td>\n",
       "      <td>0.263979</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>0.320931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.172970</td>\n",
       "      <td>0.513009</td>\n",
       "      <td>0.062299</td>\n",
       "      <td>0.167966</td>\n",
       "      <td>0.507118</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>0.166091</td>\n",
       "      <td>0.500336</td>\n",
       "      <td>0.054046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036911</td>\n",
       "      <td>0.368087</td>\n",
       "      <td>0.055811</td>\n",
       "      <td>0.056346</td>\n",
       "      <td>0.408806</td>\n",
       "      <td>0.083943</td>\n",
       "      <td>0.075098</td>\n",
       "      <td>0.445834</td>\n",
       "      <td>0.102526</td>\n",
       "      <td>0.089386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131510</td>\n",
       "      <td>0.108346</td>\n",
       "      <td>0.539049</td>\n",
       "      <td>0.129968</td>\n",
       "      <td>0.110770</td>\n",
       "      <td>0.531741</td>\n",
       "      <td>0.129751</td>\n",
       "      <td>0.119076</td>\n",
       "      <td>0.519113</td>\n",
       "      <td>0.128266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125703</td>\n",
       "      <td>0.488992</td>\n",
       "      <td>0.138961</td>\n",
       "      <td>0.121660</td>\n",
       "      <td>0.481484</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>0.118317</td>\n",
       "      <td>0.473236</td>\n",
       "      <td>0.133216</td>\n",
       "      <td>0.119788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176316</td>\n",
       "      <td>0.139181</td>\n",
       "      <td>0.553542</td>\n",
       "      <td>0.190199</td>\n",
       "      <td>0.142746</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.566810</td>\n",
       "      <td>0.192870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205560</td>\n",
       "      <td>0.581871</td>\n",
       "      <td>0.240154</td>\n",
       "      <td>0.203238</td>\n",
       "      <td>0.592225</td>\n",
       "      <td>0.240437</td>\n",
       "      <td>0.203349</td>\n",
       "      <td>0.599506</td>\n",
       "      <td>0.243425</td>\n",
       "      <td>0.202471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255855</td>\n",
       "      <td>0.183691</td>\n",
       "      <td>0.614382</td>\n",
       "      <td>0.251409</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.606482</td>\n",
       "      <td>0.248135</td>\n",
       "      <td>0.181390</td>\n",
       "      <td>0.601492</td>\n",
       "      <td>0.243138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.136420</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.189601</td>\n",
       "      <td>0.142850</td>\n",
       "      <td>0.567043</td>\n",
       "      <td>0.199006</td>\n",
       "      <td>0.148132</td>\n",
       "      <td>0.574208</td>\n",
       "      <td>0.201018</td>\n",
       "      <td>0.144297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156228</td>\n",
       "      <td>0.114243</td>\n",
       "      <td>0.482261</td>\n",
       "      <td>0.159717</td>\n",
       "      <td>0.118566</td>\n",
       "      <td>0.487373</td>\n",
       "      <td>0.164250</td>\n",
       "      <td>0.118335</td>\n",
       "      <td>0.479779</td>\n",
       "      <td>0.160728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.106478</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.109557</td>\n",
       "      <td>0.482007</td>\n",
       "      <td>0.151879</td>\n",
       "      <td>0.116003</td>\n",
       "      <td>0.493869</td>\n",
       "      <td>0.158749</td>\n",
       "      <td>0.125853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160509</td>\n",
       "      <td>0.110079</td>\n",
       "      <td>0.495676</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.112103</td>\n",
       "      <td>0.488334</td>\n",
       "      <td>0.155059</td>\n",
       "      <td>0.112166</td>\n",
       "      <td>0.474051</td>\n",
       "      <td>0.149857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.155460</td>\n",
       "      <td>0.497195</td>\n",
       "      <td>0.154524</td>\n",
       "      <td>0.156726</td>\n",
       "      <td>0.504703</td>\n",
       "      <td>0.155792</td>\n",
       "      <td>0.157340</td>\n",
       "      <td>0.514922</td>\n",
       "      <td>0.161861</td>\n",
       "      <td>0.163627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153296</td>\n",
       "      <td>0.123685</td>\n",
       "      <td>0.497488</td>\n",
       "      <td>0.148835</td>\n",
       "      <td>0.117435</td>\n",
       "      <td>0.486279</td>\n",
       "      <td>0.140191</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.480266</td>\n",
       "      <td>0.134979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.230357</td>\n",
       "      <td>0.567656</td>\n",
       "      <td>0.136469</td>\n",
       "      <td>0.221792</td>\n",
       "      <td>0.574477</td>\n",
       "      <td>0.136979</td>\n",
       "      <td>0.228175</td>\n",
       "      <td>0.583402</td>\n",
       "      <td>0.146335</td>\n",
       "      <td>0.232112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102411</td>\n",
       "      <td>0.126379</td>\n",
       "      <td>0.470664</td>\n",
       "      <td>0.104949</td>\n",
       "      <td>0.128950</td>\n",
       "      <td>0.464809</td>\n",
       "      <td>0.102157</td>\n",
       "      <td>0.128156</td>\n",
       "      <td>0.456268</td>\n",
       "      <td>0.096224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.476359</td>\n",
       "      <td>0.175379</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.181696</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>0.496879</td>\n",
       "      <td>0.187580</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187209</td>\n",
       "      <td>0.151214</td>\n",
       "      <td>0.528120</td>\n",
       "      <td>0.180376</td>\n",
       "      <td>0.152756</td>\n",
       "      <td>0.519160</td>\n",
       "      <td>0.175594</td>\n",
       "      <td>0.156123</td>\n",
       "      <td>0.509827</td>\n",
       "      <td>0.168156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows Ã— 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.503224  0.377374  0.236031  0.518100  0.387029  0.251523  0.491603   \n",
       "1     0.319037  0.259975  0.165347  0.326856  0.268294  0.171164  0.323741   \n",
       "2     0.036911  0.368087  0.055811  0.056346  0.408806  0.083943  0.075098   \n",
       "3     0.125703  0.488992  0.138961  0.121660  0.481484  0.135838  0.118317   \n",
       "4     0.205560  0.581871  0.240154  0.203238  0.592225  0.240437  0.203349   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.136420  0.563218  0.189601  0.142850  0.567043  0.199006  0.148132   \n",
       "1527  0.106478  0.471000  0.144794  0.109557  0.482007  0.151879  0.116003   \n",
       "1528  0.155460  0.497195  0.154524  0.156726  0.504703  0.155792  0.157340   \n",
       "1529  0.230357  0.567656  0.136469  0.221792  0.574477  0.136979  0.228175   \n",
       "1530  0.146447  0.476359  0.175379  0.151458  0.486339  0.181696  0.157324   \n",
       "\n",
       "          7         8         9     ...      3062      3063      3064  \\\n",
       "0     0.357519  0.236350  0.455322  ...  0.238196  0.150798  0.580239   \n",
       "1     0.263979  0.166947  0.320931  ...  0.061350  0.172970  0.513009   \n",
       "2     0.445834  0.102526  0.089386  ...  0.131510  0.108346  0.539049   \n",
       "3     0.473236  0.133216  0.119788  ...  0.176316  0.139181  0.553542   \n",
       "4     0.599506  0.243425  0.202471  ...  0.255855  0.183691  0.614382   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.574208  0.201018  0.144297  ...  0.156228  0.114243  0.482261   \n",
       "1527  0.493869  0.158749  0.125853  ...  0.160509  0.110079  0.495676   \n",
       "1528  0.514922  0.161861  0.163627  ...  0.153296  0.123685  0.497488   \n",
       "1529  0.583402  0.146335  0.232112  ...  0.102411  0.126379  0.470664   \n",
       "1530  0.496879  0.187580  0.158730  ...  0.187209  0.151214  0.528120   \n",
       "\n",
       "          3065      3066      3067      3068      3069      3070      3071  \n",
       "0     0.234891  0.145466  0.573147  0.228163  0.148683  0.576832  0.229349  \n",
       "1     0.062299  0.167966  0.507118  0.056535  0.166091  0.500336  0.054046  \n",
       "2     0.129968  0.110770  0.531741  0.129751  0.119076  0.519113  0.128266  \n",
       "3     0.190199  0.142746  0.568637  0.196002  0.136994  0.566810  0.192870  \n",
       "4     0.251409  0.181400  0.606482  0.248135  0.181390  0.601492  0.243138  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.159717  0.118566  0.487373  0.164250  0.118335  0.479779  0.160728  \n",
       "1527  0.158603  0.112103  0.488334  0.155059  0.112166  0.474051  0.149857  \n",
       "1528  0.148835  0.117435  0.486279  0.140191  0.115513  0.480266  0.134979  \n",
       "1529  0.104949  0.128950  0.464809  0.102157  0.128156  0.456268  0.096224  \n",
       "1530  0.180376  0.152756  0.519160  0.175594  0.156123  0.509827  0.168156  \n",
       "\n",
       "[1531 rows x 3072 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a3ded",
   "metadata": {},
   "source": [
    "#### 3 colors and augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4609456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.342 total time=   5.2s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.2s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   4.6s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.472 total time=   4.6s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.500 total time=   4.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.474 total time=   4.2s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.526 total time=   4.1s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.471 total time=   4.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.342 total time=   3.9s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=   4.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=   4.2s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=   4.2s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=   4.1s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.342 total time=   4.6s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   4.1s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   4.3s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   4.4s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.343 total time=   4.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.466 total time=   3.8s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.503 total time=   3.7s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.513 total time=   3.9s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.526 total time=   3.9s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.461 total time=   3.7s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.707 total time=   3.5s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.725 total time=   3.6s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.752 total time=   3.6s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.722 total time=   3.2s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.719 total time=   3.2s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.779 total time=   3.9s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.768 total time=   3.9s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.778 total time=   3.9s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.719 total time=   3.9s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.791 total time=   3.9s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.371 total time=   3.9s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.366 total time=   3.9s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.369 total time=   4.1s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.376 total time=   4.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.376 total time=   4.4s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.691 total time=   3.8s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.703 total time=   3.4s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.719 total time=   3.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.693 total time=   3.4s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.680 total time=   3.3s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.873 total time=   2.4s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.797 total time=   2.6s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.833 total time=   2.4s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.833 total time=   2.3s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.833 total time=   2.4s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.801 total time=   4.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.794 total time=   3.7s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.794 total time=   3.8s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.752 total time=   3.9s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.801 total time=   3.7s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.371 total time=   3.8s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.369 total time=   4.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.369 total time=   4.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.376 total time=   4.2s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.376 total time=   3.9s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.798 total time=   2.4s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.748 total time=   2.4s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.794 total time=   2.4s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.765 total time=   2.3s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.814 total time=   2.4s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.925 total time=   2.1s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.863 total time=   2.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.866 total time=   2.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.837 total time=   2.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.879 total time=   2.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.801 total time=   4.1s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.794 total time=   3.8s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.794 total time=   3.8s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.752 total time=   3.7s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.801 total time=   3.7s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.371 total time=   3.7s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.369 total time=   3.7s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.369 total time=   3.8s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.376 total time=   3.9s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.376 total time=   4.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e25b2a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END ......C=0.1, degree=3, kernel=poly;, score=0.912 total time=   2.2s\n",
      "[CV 2/5] END ......C=0.1, degree=3, kernel=poly;, score=0.846 total time=   2.1s\n",
      "[CV 3/5] END ......C=0.1, degree=3, kernel=poly;, score=0.876 total time=   2.1s\n",
      "[CV 4/5] END ......C=0.1, degree=3, kernel=poly;, score=0.853 total time=   1.9s\n",
      "[CV 5/5] END ......C=0.1, degree=3, kernel=poly;, score=0.879 total time=   2.1s\n",
      "[CV 1/5] END ......C=0.1, degree=4, kernel=poly;, score=0.919 total time=   1.9s\n",
      "[CV 2/5] END ......C=0.1, degree=4, kernel=poly;, score=0.882 total time=   1.7s\n",
      "[CV 3/5] END ......C=0.1, degree=4, kernel=poly;, score=0.905 total time=   1.7s\n",
      "[CV 4/5] END ......C=0.1, degree=4, kernel=poly;, score=0.886 total time=   1.8s\n",
      "[CV 5/5] END ......C=0.1, degree=4, kernel=poly;, score=0.899 total time=   1.8s\n",
      "[CV 1/5] END ......C=0.1, degree=5, kernel=poly;, score=0.906 total time=   1.6s\n",
      "[CV 2/5] END ......C=0.1, degree=5, kernel=poly;, score=0.866 total time=   1.6s\n",
      "[CV 3/5] END ......C=0.1, degree=5, kernel=poly;, score=0.892 total time=   1.6s\n",
      "[CV 4/5] END ......C=0.1, degree=5, kernel=poly;, score=0.889 total time=   1.6s\n",
      "[CV 5/5] END ......C=0.1, degree=5, kernel=poly;, score=0.886 total time=   1.6s\n",
      "[CV 1/5] END ........C=1, degree=3, kernel=poly;, score=0.906 total time=   1.8s\n",
      "[CV 2/5] END ........C=1, degree=3, kernel=poly;, score=0.876 total time=   1.8s\n",
      "[CV 3/5] END ........C=1, degree=3, kernel=poly;, score=0.895 total time=   1.8s\n",
      "[CV 4/5] END ........C=1, degree=3, kernel=poly;, score=0.876 total time=   1.8s\n",
      "[CV 5/5] END ........C=1, degree=3, kernel=poly;, score=0.892 total time=   1.8s\n",
      "[CV 1/5] END ........C=1, degree=4, kernel=poly;, score=0.902 total time=   1.7s\n",
      "[CV 2/5] END ........C=1, degree=4, kernel=poly;, score=0.869 total time=   1.7s\n",
      "[CV 3/5] END ........C=1, degree=4, kernel=poly;, score=0.892 total time=   1.7s\n",
      "[CV 4/5] END ........C=1, degree=4, kernel=poly;, score=0.886 total time=   1.7s\n",
      "[CV 5/5] END ........C=1, degree=4, kernel=poly;, score=0.886 total time=   1.8s\n",
      "[CV 1/5] END ........C=1, degree=5, kernel=poly;, score=0.906 total time=   2.0s\n",
      "[CV 2/5] END ........C=1, degree=5, kernel=poly;, score=0.863 total time=   1.9s\n",
      "[CV 3/5] END ........C=1, degree=5, kernel=poly;, score=0.892 total time=   1.8s\n",
      "[CV 4/5] END ........C=1, degree=5, kernel=poly;, score=0.889 total time=   1.7s\n",
      "[CV 5/5] END ........C=1, degree=5, kernel=poly;, score=0.882 total time=   1.7s\n",
      "[CV 1/5] END .......C=10, degree=3, kernel=poly;, score=0.902 total time=   2.0s\n",
      "[CV 2/5] END .......C=10, degree=3, kernel=poly;, score=0.869 total time=   1.9s\n",
      "[CV 3/5] END .......C=10, degree=3, kernel=poly;, score=0.895 total time=   1.8s\n",
      "[CV 4/5] END .......C=10, degree=3, kernel=poly;, score=0.873 total time=   1.8s\n",
      "[CV 5/5] END .......C=10, degree=3, kernel=poly;, score=0.892 total time=   1.8s\n",
      "[CV 1/5] END .......C=10, degree=4, kernel=poly;, score=0.902 total time=   1.8s\n",
      "[CV 2/5] END .......C=10, degree=4, kernel=poly;, score=0.869 total time=   1.7s\n",
      "[CV 3/5] END .......C=10, degree=4, kernel=poly;, score=0.892 total time=   1.7s\n",
      "[CV 4/5] END .......C=10, degree=4, kernel=poly;, score=0.886 total time=   1.8s\n",
      "[CV 5/5] END .......C=10, degree=4, kernel=poly;, score=0.886 total time=   1.8s\n",
      "[CV 1/5] END .......C=10, degree=5, kernel=poly;, score=0.906 total time=   1.7s\n",
      "[CV 2/5] END .......C=10, degree=5, kernel=poly;, score=0.863 total time=   1.7s\n",
      "[CV 3/5] END .......C=10, degree=5, kernel=poly;, score=0.892 total time=   1.7s\n",
      "[CV 4/5] END .......C=10, degree=5, kernel=poly;, score=0.889 total time=   1.7s\n",
      "[CV 5/5] END .......C=10, degree=5, kernel=poly;, score=0.882 total time=   1.7s\n",
      "[CV 1/5] END ......C=100, degree=3, kernel=poly;, score=0.902 total time=   1.9s\n",
      "[CV 2/5] END ......C=100, degree=3, kernel=poly;, score=0.869 total time=   1.8s\n",
      "[CV 3/5] END ......C=100, degree=3, kernel=poly;, score=0.895 total time=   1.8s\n",
      "[CV 4/5] END ......C=100, degree=3, kernel=poly;, score=0.873 total time=   1.8s\n",
      "[CV 5/5] END ......C=100, degree=3, kernel=poly;, score=0.892 total time=   2.0s\n",
      "[CV 1/5] END ......C=100, degree=4, kernel=poly;, score=0.902 total time=   1.8s\n",
      "[CV 2/5] END ......C=100, degree=4, kernel=poly;, score=0.869 total time=   1.8s\n",
      "[CV 3/5] END ......C=100, degree=4, kernel=poly;, score=0.892 total time=   1.7s\n",
      "[CV 4/5] END ......C=100, degree=4, kernel=poly;, score=0.886 total time=   1.7s\n",
      "[CV 5/5] END ......C=100, degree=4, kernel=poly;, score=0.886 total time=   1.7s\n",
      "[CV 1/5] END ......C=100, degree=5, kernel=poly;, score=0.906 total time=   1.6s\n",
      "[CV 2/5] END ......C=100, degree=5, kernel=poly;, score=0.863 total time=   1.6s\n",
      "[CV 3/5] END ......C=100, degree=5, kernel=poly;, score=0.892 total time=   1.6s\n",
      "[CV 4/5] END ......C=100, degree=5, kernel=poly;, score=0.889 total time=   1.6s\n",
      "[CV 5/5] END ......C=100, degree=5, kernel=poly;, score=0.882 total time=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'degree': [3, 4, 5],\n",
       "                         'kernel': ['poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[0.1,1,10,100],'degree':[3,4,5],'kernel':['poly']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f437d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END ..............C=0.1, kernel=linear;, score=0.837 total time=   2.1s\n",
      "[CV 2/5] END ..............C=0.1, kernel=linear;, score=0.761 total time=   2.0s\n",
      "[CV 3/5] END ..............C=0.1, kernel=linear;, score=0.778 total time=   2.0s\n",
      "[CV 4/5] END ..............C=0.1, kernel=linear;, score=0.755 total time=   2.0s\n",
      "[CV 5/5] END ..............C=0.1, kernel=linear;, score=0.797 total time=   2.0s\n",
      "[CV 1/5] END ................C=1, kernel=linear;, score=0.779 total time=   2.3s\n",
      "[CV 2/5] END ................C=1, kernel=linear;, score=0.680 total time=   2.2s\n",
      "[CV 3/5] END ................C=1, kernel=linear;, score=0.680 total time=   2.3s\n",
      "[CV 4/5] END ................C=1, kernel=linear;, score=0.709 total time=   2.2s\n",
      "[CV 5/5] END ................C=1, kernel=linear;, score=0.690 total time=   2.3s\n",
      "[CV 1/5] END ...............C=10, kernel=linear;, score=0.726 total time=   2.4s\n",
      "[CV 2/5] END ...............C=10, kernel=linear;, score=0.637 total time=   2.3s\n",
      "[CV 3/5] END ...............C=10, kernel=linear;, score=0.676 total time=   2.4s\n",
      "[CV 4/5] END ...............C=10, kernel=linear;, score=0.680 total time=   2.2s\n",
      "[CV 5/5] END ...............C=10, kernel=linear;, score=0.699 total time=   2.6s\n",
      "[CV 1/5] END ..............C=100, kernel=linear;, score=0.726 total time=   2.4s\n",
      "[CV 2/5] END ..............C=100, kernel=linear;, score=0.637 total time=   2.3s\n",
      "[CV 3/5] END ..............C=100, kernel=linear;, score=0.676 total time=   2.3s\n",
      "[CV 4/5] END ..............C=100, kernel=linear;, score=0.680 total time=   2.2s\n",
      "[CV 5/5] END ..............C=100, kernel=linear;, score=0.699 total time=   2.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'kernel': ['linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[0.1,1,10,100],'kernel':['linear']}\n",
    "model=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64e88201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[504   2   2]\n",
      " [  5 489   4]\n",
      " [  2   1 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       508\n",
      "           1       0.99      0.98      0.99       498\n",
      "           2       0.99      0.99      0.99       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c95fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   1   4]\n",
      " [ 10  89   8]\n",
      " [  6   1 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       109\n",
      "           1       0.98      0.83      0.90       107\n",
      "           2       0.90      0.94      0.92       112\n",
      "\n",
      "    accuracy                           0.91       328\n",
      "   macro avg       0.91      0.91      0.91       328\n",
      "weighted avg       0.91      0.91      0.91       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9cf9fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a806baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   3   2]\n",
      " [ 10  89   8]\n",
      " [  6   2 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       109\n",
      "           1       0.95      0.83      0.89       107\n",
      "           2       0.91      0.93      0.92       112\n",
      "\n",
      "    accuracy                           0.91       328\n",
      "   macro avg       0.91      0.90      0.90       328\n",
      "weighted avg       0.91      0.91      0.91       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02992bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[438  10  60]\n",
      " [ 17 446  35]\n",
      " [ 39  22 464]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       508\n",
      "           1       0.93      0.90      0.91       498\n",
      "           2       0.83      0.88      0.86       525\n",
      "\n",
      "    accuracy                           0.88      1531\n",
      "   macro avg       0.88      0.88      0.88      1531\n",
      "weighted avg       0.88      0.88      0.88      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a293e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80  3 26]\n",
      " [14 79 14]\n",
      " [18  4 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       109\n",
      "           1       0.92      0.74      0.82       107\n",
      "           2       0.69      0.80      0.74       112\n",
      "\n",
      "    accuracy                           0.76       328\n",
      "   macro avg       0.78      0.76      0.76       328\n",
      "weighted avg       0.77      0.76      0.76       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b131c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   3   2]\n",
      " [  7  96   4]\n",
      " [  7   1 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       109\n",
      "           1       0.96      0.90      0.93       107\n",
      "           2       0.95      0.93      0.94       113\n",
      "\n",
      "    accuracy                           0.93       329\n",
      "   macro avg       0.93      0.93      0.93       329\n",
      "weighted avg       0.93      0.93      0.93       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068a266",
   "metadata": {},
   "source": [
    "#### Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1bb6f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 5]\n",
      " [0 0 5]\n",
      " [0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.29        14\n",
      "   macro avg       0.10      0.33      0.15        14\n",
      "weighted avg       0.08      0.29      0.13        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rbf_model = svm.SVC(C=100, gamma=0.001, kernel='rbf').fit(x_train, y_train)\n",
    "print(confusion_matrix(y_self_test,rbf_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,rbf_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3156eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 5]\n",
      " [2 0 3]\n",
      " [0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.29        14\n",
      "   macro avg       0.11      0.33      0.17        14\n",
      "weighted avg       0.10      0.29      0.14        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "poly_model = svm.SVC(C=0.1, degree=5, kernel='poly').fit(x_train, y_train)\n",
    "print(confusion_matrix(y_self_test,poly_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,poly_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d869cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 5]\n",
      " [1 0 4]\n",
      " [0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.31      1.00      0.47         4\n",
      "\n",
      "    accuracy                           0.29        14\n",
      "   macro avg       0.10      0.33      0.16        14\n",
      "weighted avg       0.09      0.29      0.13        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jcrul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "linear_model = svm.SVC(C=0.1, kernel='linear').fit(x_train, y_train)\n",
    "print(confusion_matrix(y_self_test,linear_model.predict(self_test)))\n",
    "print(classification_report(y_self_test,linear_model.predict(self_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8754f1fb",
   "metadata": {},
   "source": [
    "### Moving from grayscale to 3 color channels improves accuracy on both dataset and real data. Augmenting images with 3 color channels performs similarly to untransformed grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27d204ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Augmentor\n",
      "  Downloading Augmentor-0.2.11-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\jcrul\\anaconda3\\lib\\site-packages (from Augmentor) (9.0.1)\n",
      "Requirement already satisfied: tqdm>=4.9.0 in c:\\users\\jcrul\\anaconda3\\lib\\site-packages (from Augmentor) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jcrul\\anaconda3\\lib\\site-packages (from tqdm>=4.9.0->Augmentor) (0.4.4)\n",
      "Installing collected packages: Augmentor\n",
      "Successfully installed Augmentor-0.2.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Augmentor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
