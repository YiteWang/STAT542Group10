{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from nnmodels import get_model\n",
    "from train_eval import train, model_eval\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    'acc': accuracy_score,\n",
    "    'prec': precision_score,\n",
    "    'recall': recall_score\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32)),\n",
    "    # transforms.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1)),\n",
    "    transforms.RandomAffine(0, shear=0.2),         # random shear 0.2\n",
    "    transforms.RandomAffine(0, scale=(0.8, 1.2)),  # random zoom 0.2\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),   \n",
    "    transforms.RandomVerticalFlip(),     \n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32)),\n",
    "])\n",
    "vis_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': 0, 'rock': 1, 'scissors': 2}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='train', transform=train_transforms)\n",
    "valid_dataset = torchvision.datasets.ImageFolder(root='val', transform=test_transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='test', transform=test_transform)\n",
    "print(train_dataset.class_to_idx)\n",
    "reversemapping = {a:b for b,a in train_dataset.class_to_idx.items()}\n",
    "assert train_dataset.class_to_idx == valid_dataset.class_to_idx == test_dataset.class_to_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b00c1203a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256*2, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definie Hyper-paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda for training, note that cpu may be slow for training.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print('We are using {} for training, note that cpu may be slow for training.'.format(device))\n",
    "model = get_model('base')\n",
    "model = model.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001, weight_decay=5e-6)\n",
    "total_epochs = 20\n",
    "# scheduler = MultiStepLR(optimizer, milestones=[10,], gamma=0.1)\n",
    "scheduler = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train: Top 1 Accuracy: 1099/1531 (71.78%), Time Used: 0.1352518876393636 mins\n",
      "Valid Evaluation: Average loss: 2.1007, Top 1 Accuracy: 109/328 (33.23%)\n",
      "Test Evaluation: Average loss: 2.0876, Top 1 Accuracy: 109/329 (33.13%)\n",
      "A better Valid Acc is found: 33.23170731707317 with Test Acc 33.130699088145896\n",
      "Epoch: 1, Train: Top 1 Accuracy: 1441/1531 (94.12%), Time Used: 0.10486183563868205 mins\n",
      "Valid Evaluation: Average loss: 0.6438, Top 1 Accuracy: 230/328 (70.12%)\n",
      "Test Evaluation: Average loss: 0.6303, Top 1 Accuracy: 232/329 (70.52%)\n",
      "A better Valid Acc is found: 70.1219512195122 with Test Acc 70.51671732522796\n",
      "Epoch: 2, Train: Top 1 Accuracy: 1457/1531 (95.17%), Time Used: 0.10355172952016195 mins\n",
      "Valid Evaluation: Average loss: 0.4379, Top 1 Accuracy: 279/328 (85.06%)\n",
      "Test Evaluation: Average loss: 0.4387, Top 1 Accuracy: 278/329 (84.50%)\n",
      "A better Valid Acc is found: 85.0609756097561 with Test Acc 84.4984802431611\n",
      "Epoch: 3, Train: Top 1 Accuracy: 1462/1531 (95.49%), Time Used: 0.10090673764546712 mins\n",
      "Valid Evaluation: Average loss: 0.8745, Top 1 Accuracy: 234/328 (71.34%)\n",
      "Test Evaluation: Average loss: 0.8398, Top 1 Accuracy: 243/329 (73.86%)\n",
      "Epoch: 4, Train: Top 1 Accuracy: 1469/1531 (95.95%), Time Used: 0.10229047536849975 mins\n",
      "Valid Evaluation: Average loss: 0.9615, Top 1 Accuracy: 224/328 (68.29%)\n",
      "Test Evaluation: Average loss: 0.9444, Top 1 Accuracy: 229/329 (69.60%)\n",
      "Epoch: 5, Train: Top 1 Accuracy: 1489/1531 (97.26%), Time Used: 0.10100037256876628 mins\n",
      "Valid Evaluation: Average loss: 0.1990, Top 1 Accuracy: 310/328 (94.51%)\n",
      "Test Evaluation: Average loss: 0.2240, Top 1 Accuracy: 304/329 (92.40%)\n",
      "A better Valid Acc is found: 94.51219512195122 with Test Acc 92.40121580547113\n",
      "Epoch: 6, Train: Top 1 Accuracy: 1490/1531 (97.32%), Time Used: 0.10180368820826212 mins\n",
      "Valid Evaluation: Average loss: 0.0278, Top 1 Accuracy: 325/328 (99.09%)\n",
      "Test Evaluation: Average loss: 0.0630, Top 1 Accuracy: 321/329 (97.57%)\n",
      "A better Valid Acc is found: 99.08536585365853 with Test Acc 97.56838905775076\n",
      "Epoch: 7, Train: Top 1 Accuracy: 1505/1531 (98.30%), Time Used: 0.10207821528116862 mins\n",
      "Valid Evaluation: Average loss: 0.0222, Top 1 Accuracy: 326/328 (99.39%)\n",
      "Test Evaluation: Average loss: 0.0498, Top 1 Accuracy: 324/329 (98.48%)\n",
      "A better Valid Acc is found: 99.39024390243902 with Test Acc 98.48024316109422\n",
      "Epoch: 8, Train: Top 1 Accuracy: 1500/1531 (97.98%), Time Used: 0.10183110237121581 mins\n",
      "Valid Evaluation: Average loss: 0.1142, Top 1 Accuracy: 316/328 (96.34%)\n",
      "Test Evaluation: Average loss: 0.1346, Top 1 Accuracy: 316/329 (96.05%)\n",
      "Epoch: 9, Train: Top 1 Accuracy: 1497/1531 (97.78%), Time Used: 0.10126269261042277 mins\n",
      "Valid Evaluation: Average loss: 0.1396, Top 1 Accuracy: 315/328 (96.04%)\n",
      "Test Evaluation: Average loss: 0.1644, Top 1 Accuracy: 319/329 (96.96%)\n",
      "Epoch: 10, Train: Top 1 Accuracy: 1493/1531 (97.52%), Time Used: 0.10748690764109294 mins\n",
      "Valid Evaluation: Average loss: 0.2041, Top 1 Accuracy: 308/328 (93.90%)\n",
      "Test Evaluation: Average loss: 0.2422, Top 1 Accuracy: 307/329 (93.31%)\n",
      "Epoch: 11, Train: Top 1 Accuracy: 1500/1531 (97.98%), Time Used: 0.10173103014628092 mins\n",
      "Valid Evaluation: Average loss: 0.0298, Top 1 Accuracy: 324/328 (98.78%)\n",
      "Test Evaluation: Average loss: 0.0389, Top 1 Accuracy: 324/329 (98.48%)\n",
      "Epoch: 12, Train: Top 1 Accuracy: 1492/1531 (97.45%), Time Used: 0.10222336848576864 mins\n",
      "Valid Evaluation: Average loss: 0.2790, Top 1 Accuracy: 296/328 (90.24%)\n",
      "Test Evaluation: Average loss: 0.3336, Top 1 Accuracy: 296/329 (89.97%)\n",
      "Epoch: 13, Train: Top 1 Accuracy: 1492/1531 (97.45%), Time Used: 0.10315421024958292 mins\n",
      "Valid Evaluation: Average loss: 0.0672, Top 1 Accuracy: 321/328 (97.87%)\n",
      "Test Evaluation: Average loss: 0.0772, Top 1 Accuracy: 318/329 (96.66%)\n",
      "Epoch: 14, Train: Top 1 Accuracy: 1502/1531 (98.11%), Time Used: 0.10453237295150757 mins\n",
      "Valid Evaluation: Average loss: 0.0393, Top 1 Accuracy: 325/328 (99.09%)\n",
      "Test Evaluation: Average loss: 0.0290, Top 1 Accuracy: 325/329 (98.78%)\n",
      "Epoch: 15, Train: Top 1 Accuracy: 1515/1531 (98.95%), Time Used: 0.10471513668696085 mins\n",
      "Valid Evaluation: Average loss: 0.0830, Top 1 Accuracy: 321/328 (97.87%)\n",
      "Test Evaluation: Average loss: 0.0712, Top 1 Accuracy: 322/329 (97.87%)\n",
      "Epoch: 16, Train: Top 1 Accuracy: 1516/1531 (99.02%), Time Used: 0.10452796220779419 mins\n",
      "Valid Evaluation: Average loss: 0.0557, Top 1 Accuracy: 323/328 (98.48%)\n",
      "Test Evaluation: Average loss: 0.0613, Top 1 Accuracy: 320/329 (97.26%)\n",
      "Epoch: 17, Train: Top 1 Accuracy: 1514/1531 (98.89%), Time Used: 0.11617493232091268 mins\n",
      "Valid Evaluation: Average loss: 0.0076, Top 1 Accuracy: 327/328 (99.70%)\n",
      "Test Evaluation: Average loss: 0.0126, Top 1 Accuracy: 327/329 (99.39%)\n",
      "A better Valid Acc is found: 99.6951219512195 with Test Acc 99.3920972644377\n",
      "Epoch: 18, Train: Top 1 Accuracy: 1513/1531 (98.82%), Time Used: 0.1073829452196757 mins\n",
      "Valid Evaluation: Average loss: 0.0065, Top 1 Accuracy: 327/328 (99.70%)\n",
      "Test Evaluation: Average loss: 0.0125, Top 1 Accuracy: 328/329 (99.70%)\n",
      "Epoch: 19, Train: Top 1 Accuracy: 1516/1531 (99.02%), Time Used: 0.11026437282562256 mins\n",
      "Valid Evaluation: Average loss: 0.0276, Top 1 Accuracy: 324/328 (98.78%)\n",
      "Test Evaluation: Average loss: 0.0569, Top 1 Accuracy: 322/329 (97.87%)\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "final_test_acc = 0.0\n",
    "for epoch in range(total_epochs):\n",
    "    train(model, loss, optimizer, train_loader, device, epoch, False, scheduler=scheduler)\n",
    "    _, val_acc = model_eval(model, loss, val_loader, device, name= 'Valid')\n",
    "    _, test_acc = model_eval(model, loss, test_loader, device, name= 'Test')\n",
    "    if val_acc > best_val_acc:\n",
    "        print('A better Valid Acc is found: {} with Test Acc {}'.format(val_acc, test_acc))\n",
    "        best_val_acc = val_acc\n",
    "        final_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'best_model_nojit.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Valid Acc: 99.6951219512195, Test Acc: 99.3920972644377\n"
     ]
    }
   ],
   "source": [
    "print('The best Valid Acc: {}, Test Acc: {}'.format(best_val_acc, final_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_nojit.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, y in test_loader:\n",
    "    pred = model(data.cuda()).argmax(1).cpu().numpy()\n",
    "    actual = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99056604 1.         0.98245614]\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(actual, pred, average=None)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98130841 1.         0.99115044]\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(actual, pred, average=None)\n",
    "print(recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Wrong solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 32, 104, 246], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "i = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, pred = output.topk(1, dim=1)\n",
    "        print((torch.logical_not(pred.eq(target.view(-1,1))).view(-1)).nonzero(as_tuple=True)[0])\n",
    "\n",
    "        for image, prediction in zip(data[torch.logical_not(pred.eq(target.view(-1,1))).view(-1)], pred[torch.logical_not(pred.eq(target.view(-1,1))).view(-1)]):\n",
    "            save_image(image, reversemapping[prediction.item()]+str(i)+'.png')\n",
    "            i += 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "for i in data[torch.logical_not(pred.eq(target.view(-1,1))).view(-1)]:\n",
    "    save_image(i, 'img1.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are choosing 259/329 for testing with target: scissors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x192840ac970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_len = len(test_dataset)\n",
    "index = random.randint(0, data_len)\n",
    "data, target = test_dataset[index]\n",
    "print('We are choosing {}/{} for testing with target: {}.'.format(index+1, data_len, reversemapping[target]))\n",
    "plt.imshow(data.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our network prediction is: scissors\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print('Our network prediction is: {}'.format(reversemapping[model(data.unsqueeze(0).cuda()).argmax(1).item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real images testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset= torchvision.datasets.ImageFolder('real', transform=test_transform)\n",
    "real_loader = torch.utils.data.DataLoader(real_dataset, batch_size=100, shuffle=False)\n",
    "real_vis_dataset=  torchvision.datasets.ImageFolder('real', transform=vis_transform)\n",
    "real_vis_loader = torch.utils.data.DataLoader(real_vis_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc\n",
      "0.35714285714285715\n",
      "prec\n",
      "[0.35714286 0.         0.        ]\n",
      "recall\n",
      "[1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\software\\anaconda\\main\\envs\\py39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for data, y in real_loader:\n",
    "    pred = model(data.cuda()).argmax(1).cpu().numpy()\n",
    "    actual = y.numpy()\n",
    "\n",
    "for metric_name, metric_func in all_metrics.items():\n",
    "    print(metric_name)\n",
    "    try:\n",
    "        print(metric_func(actual, pred, average=None))\n",
    "    except:\n",
    "        print(metric_func(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# total = 0\n",
    "# correct = 0\n",
    "# for (x,y), (x_vis, y_vis) in zip(real_loader,real_vis_loader):\n",
    "#     plt.figure()\n",
    "#     # plt.imshow(x_vis[0].permute(1,2,0))\n",
    "#     total += 1\n",
    "#     correct += model(x.cuda()).argmax(1).item() == y.item()\n",
    "#     # print('Our network prediction is: {}, acutal is: {}'.format(reversemapping[model(x.cuda()).argmax(1).item()], reversemapping[y.item()]))\n",
    "\n",
    "# print(correct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
