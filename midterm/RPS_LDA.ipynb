{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740d3fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 16:10:40.706057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"divide by zero encountered in double_scalars\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "648deaae",
   "metadata": {},
   "source": [
    "# Preprocessing Image Data -Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634bfbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/train'\n",
    "test_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/test'\n",
    "val_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9551e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284348</td>\n",
       "      <td>0.297354</td>\n",
       "      <td>0.313321</td>\n",
       "      <td>0.336375</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>0.359453</td>\n",
       "      <td>0.364130</td>\n",
       "      <td>0.370838</td>\n",
       "      <td>0.378704</td>\n",
       "      <td>0.384568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.359737</td>\n",
       "      <td>0.354575</td>\n",
       "      <td>0.350273</td>\n",
       "      <td>0.344003</td>\n",
       "      <td>0.336455</td>\n",
       "      <td>0.329440</td>\n",
       "      <td>0.326312</td>\n",
       "      <td>0.321663</td>\n",
       "      <td>0.312047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304267</td>\n",
       "      <td>0.309151</td>\n",
       "      <td>0.315684</td>\n",
       "      <td>0.326809</td>\n",
       "      <td>0.334907</td>\n",
       "      <td>0.342741</td>\n",
       "      <td>0.345765</td>\n",
       "      <td>0.349956</td>\n",
       "      <td>0.353411</td>\n",
       "      <td>0.358536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367493</td>\n",
       "      <td>0.365742</td>\n",
       "      <td>0.360479</td>\n",
       "      <td>0.355597</td>\n",
       "      <td>0.352232</td>\n",
       "      <td>0.343676</td>\n",
       "      <td>0.338224</td>\n",
       "      <td>0.335972</td>\n",
       "      <td>0.331903</td>\n",
       "      <td>0.324436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.317973</td>\n",
       "      <td>0.321166</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.338706</td>\n",
       "      <td>0.344916</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>0.363010</td>\n",
       "      <td>0.367416</td>\n",
       "      <td>0.371537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365138</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.374654</td>\n",
       "      <td>0.371060</td>\n",
       "      <td>0.363793</td>\n",
       "      <td>0.357014</td>\n",
       "      <td>0.353654</td>\n",
       "      <td>0.348882</td>\n",
       "      <td>0.339495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434079</td>\n",
       "      <td>0.443543</td>\n",
       "      <td>0.454310</td>\n",
       "      <td>0.465256</td>\n",
       "      <td>0.473619</td>\n",
       "      <td>0.483946</td>\n",
       "      <td>0.487627</td>\n",
       "      <td>0.493068</td>\n",
       "      <td>0.495262</td>\n",
       "      <td>0.501782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494751</td>\n",
       "      <td>0.489472</td>\n",
       "      <td>0.481426</td>\n",
       "      <td>0.465708</td>\n",
       "      <td>0.433235</td>\n",
       "      <td>0.401956</td>\n",
       "      <td>0.390577</td>\n",
       "      <td>0.384184</td>\n",
       "      <td>0.377176</td>\n",
       "      <td>0.370118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319114</td>\n",
       "      <td>0.321382</td>\n",
       "      <td>0.328557</td>\n",
       "      <td>0.338685</td>\n",
       "      <td>0.343122</td>\n",
       "      <td>0.351620</td>\n",
       "      <td>0.354666</td>\n",
       "      <td>0.358548</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.369092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376347</td>\n",
       "      <td>0.374983</td>\n",
       "      <td>0.370926</td>\n",
       "      <td>0.365676</td>\n",
       "      <td>0.360789</td>\n",
       "      <td>0.353402</td>\n",
       "      <td>0.346790</td>\n",
       "      <td>0.344862</td>\n",
       "      <td>0.340304</td>\n",
       "      <td>0.332514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.317458</td>\n",
       "      <td>0.324743</td>\n",
       "      <td>0.334259</td>\n",
       "      <td>0.344573</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.363156</td>\n",
       "      <td>0.366968</td>\n",
       "      <td>0.372741</td>\n",
       "      <td>0.377429</td>\n",
       "      <td>0.384629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385077</td>\n",
       "      <td>0.382807</td>\n",
       "      <td>0.379498</td>\n",
       "      <td>0.377461</td>\n",
       "      <td>0.369716</td>\n",
       "      <td>0.360159</td>\n",
       "      <td>0.354411</td>\n",
       "      <td>0.346691</td>\n",
       "      <td>0.342160</td>\n",
       "      <td>0.338577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.317021</td>\n",
       "      <td>0.322916</td>\n",
       "      <td>0.331836</td>\n",
       "      <td>0.342479</td>\n",
       "      <td>0.349516</td>\n",
       "      <td>0.358961</td>\n",
       "      <td>0.364288</td>\n",
       "      <td>0.369521</td>\n",
       "      <td>0.375182</td>\n",
       "      <td>0.382394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369951</td>\n",
       "      <td>0.365180</td>\n",
       "      <td>0.355349</td>\n",
       "      <td>0.342983</td>\n",
       "      <td>0.332119</td>\n",
       "      <td>0.320491</td>\n",
       "      <td>0.315504</td>\n",
       "      <td>0.316368</td>\n",
       "      <td>0.315536</td>\n",
       "      <td>0.311280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.361844</td>\n",
       "      <td>0.364937</td>\n",
       "      <td>0.370878</td>\n",
       "      <td>0.381801</td>\n",
       "      <td>0.390075</td>\n",
       "      <td>0.397263</td>\n",
       "      <td>0.403214</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.416429</td>\n",
       "      <td>0.422234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332812</td>\n",
       "      <td>0.334786</td>\n",
       "      <td>0.331869</td>\n",
       "      <td>0.342953</td>\n",
       "      <td>0.359435</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>0.360172</td>\n",
       "      <td>0.362851</td>\n",
       "      <td>0.361314</td>\n",
       "      <td>0.353466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.421583</td>\n",
       "      <td>0.428312</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.442705</td>\n",
       "      <td>0.450507</td>\n",
       "      <td>0.456454</td>\n",
       "      <td>0.457194</td>\n",
       "      <td>0.460205</td>\n",
       "      <td>0.463888</td>\n",
       "      <td>0.467979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416330</td>\n",
       "      <td>0.412189</td>\n",
       "      <td>0.407762</td>\n",
       "      <td>0.403442</td>\n",
       "      <td>0.396639</td>\n",
       "      <td>0.389534</td>\n",
       "      <td>0.387599</td>\n",
       "      <td>0.383056</td>\n",
       "      <td>0.377605</td>\n",
       "      <td>0.375555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.292180</td>\n",
       "      <td>0.294607</td>\n",
       "      <td>0.299533</td>\n",
       "      <td>0.306746</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.321956</td>\n",
       "      <td>0.326273</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.335597</td>\n",
       "      <td>0.342758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368511</td>\n",
       "      <td>0.366481</td>\n",
       "      <td>0.364243</td>\n",
       "      <td>0.362290</td>\n",
       "      <td>0.359119</td>\n",
       "      <td>0.354633</td>\n",
       "      <td>0.351462</td>\n",
       "      <td>0.346553</td>\n",
       "      <td>0.344060</td>\n",
       "      <td>0.343899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.284348  0.297354  0.313321  0.336375  0.348745  0.359453  0.364130   \n",
       "1     0.304267  0.309151  0.315684  0.326809  0.334907  0.342741  0.345765   \n",
       "2     0.317973  0.321166  0.327402  0.338706  0.344916  0.354000  0.358446   \n",
       "3     0.434079  0.443543  0.454310  0.465256  0.473619  0.483946  0.487627   \n",
       "4     0.319114  0.321382  0.328557  0.338685  0.343122  0.351620  0.354666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.317458  0.324743  0.334259  0.344573  0.353778  0.363156  0.366968   \n",
       "1527  0.317021  0.322916  0.331836  0.342479  0.349516  0.358961  0.364288   \n",
       "1528  0.361844  0.364937  0.370878  0.381801  0.390075  0.397263  0.403214   \n",
       "1529  0.421583  0.428312  0.434783  0.442705  0.450507  0.456454  0.457194   \n",
       "1530  0.292180  0.294607  0.299533  0.306746  0.313347  0.321956  0.326273   \n",
       "\n",
       "          7         8         9     ...      1014      1015      1016  \\\n",
       "0     0.370838  0.378704  0.384568  ...  0.362042  0.359737  0.354575   \n",
       "1     0.349956  0.353411  0.358536  ...  0.367493  0.365742  0.360479   \n",
       "2     0.363010  0.367416  0.371537  ...  0.365138  0.376308  0.378158   \n",
       "3     0.493068  0.495262  0.501782  ...  0.494751  0.489472  0.481426   \n",
       "4     0.358548  0.362823  0.369092  ...  0.376347  0.374983  0.370926   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.372741  0.377429  0.384629  ...  0.385077  0.382807  0.379498   \n",
       "1527  0.369521  0.375182  0.382394  ...  0.369951  0.365180  0.355349   \n",
       "1528  0.409365  0.416429  0.422234  ...  0.332812  0.334786  0.331869   \n",
       "1529  0.460205  0.463888  0.467979  ...  0.416330  0.412189  0.407762   \n",
       "1530  0.330961  0.335597  0.342758  ...  0.368511  0.366481  0.364243   \n",
       "\n",
       "          1017      1018      1019      1020      1021      1022      1023  \n",
       "0     0.350273  0.344003  0.336455  0.329440  0.326312  0.321663  0.312047  \n",
       "1     0.355597  0.352232  0.343676  0.338224  0.335972  0.331903  0.324436  \n",
       "2     0.374654  0.371060  0.363793  0.357014  0.353654  0.348882  0.339495  \n",
       "3     0.465708  0.433235  0.401956  0.390577  0.384184  0.377176  0.370118  \n",
       "4     0.365676  0.360789  0.353402  0.346790  0.344862  0.340304  0.332514  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.377461  0.369716  0.360159  0.354411  0.346691  0.342160  0.338577  \n",
       "1527  0.342983  0.332119  0.320491  0.315504  0.316368  0.315536  0.311280  \n",
       "1528  0.342953  0.359435  0.361635  0.360172  0.362851  0.361314  0.353466  \n",
       "1529  0.403442  0.396639  0.389534  0.387599  0.383056  0.377605  0.375555  \n",
       "1530  0.362290  0.359119  0.354633  0.351462  0.346553  0.344060  0.343899  \n",
       "\n",
       "[1531 rows x 1024 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda1c039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "1526    2\n",
       "1527    2\n",
       "1528    1\n",
       "1529    2\n",
       "1530    2\n",
       "Name: Target, Length: 1531, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "021d7fa6",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "\n",
    "## LDA\n",
    "### Basic Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3c3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbe328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_test)\n",
    "    print(confusion_matrix(y_test,pred_y))\n",
    "    print(classification_report(y_test,pred_y))\n",
    "\n",
    "def train_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_train)\n",
    "    print(confusion_matrix(y_train,pred_y))\n",
    "    print(classification_report(y_train,pred_y))\n",
    "    \n",
    "def val_score(trained_model):\n",
    "    pred_y = trained_model.predict(x_val)\n",
    "    print(confusion_matrix(y_val,pred_y))\n",
    "    print(classification_report(y_val,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "868ab3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[495   2  11]\n",
      " [  1 494   3]\n",
      " [  2   1 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       508\n",
      "           1       0.99      0.99      0.99       498\n",
      "           2       0.97      0.99      0.98       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n",
      "[[74 11 24]\n",
      " [27 62 18]\n",
      " [26 24 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63       109\n",
      "           1       0.64      0.58      0.61       107\n",
      "           2       0.60      0.55      0.57       112\n",
      "\n",
      "    accuracy                           0.60       328\n",
      "   macro avg       0.61      0.60      0.60       328\n",
      "weighted avg       0.61      0.60      0.60       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Metric\n",
    "\n",
    "lda_base = LinearDiscriminantAnalysis()\n",
    "lda_base.fit(x_train, y_train)\n",
    "\n",
    "#y_pred= model.predict(x_train)\n",
    "#model.decision_function(x_train)\n",
    "#confusion_matrix(y_train, y_pred)\n",
    "#print(classification_report(y_train, y_pred))\n",
    "train_score(lda_base)\n",
    "val_score(lda_base)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67f7ac8e",
   "metadata": {},
   "source": [
    "### LDA  - lsqr & eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac6700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter tuning with GridSearchCV \n",
    "\n",
    "\n",
    "estimator_1 = LinearDiscriminantAnalysis(shrinkage='auto')\n",
    "parameters_1 = {\n",
    "    'solver': ('lsqr','eigen'),  #note svd does not run with shrinkage and models using it will be tuned separately\n",
    "    'n_components': (1,2),\n",
    "                   }\n",
    "# with GridSearch\n",
    "grid_search_lda_A = GridSearchCV(\n",
    "    estimator=estimator_1,\n",
    "    param_grid=parameters_1,\n",
    "    scoring = 'accuracy',\n",
    "    refit = True,\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e195336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[452  18  38]\n",
      " [ 14 439  45]\n",
      " [ 22  14 489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       508\n",
      "           1       0.93      0.88      0.91       498\n",
      "           2       0.85      0.93      0.89       525\n",
      "\n",
      "    accuracy                           0.90      1531\n",
      "   macro avg       0.90      0.90      0.90      1531\n",
      "weighted avg       0.90      0.90      0.90      1531\n",
      "\n",
      "[[83  6 20]\n",
      " [14 72 21]\n",
      " [17 15 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       109\n",
      "           1       0.77      0.67      0.72       107\n",
      "           2       0.66      0.71      0.69       112\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.72      0.72      0.72       328\n",
      "weighted avg       0.72      0.72      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_A1=grid_search_lda_A.fit(x_train, y_train)\n",
    "train_score(lda_A1)\n",
    "val_score(lda_A1)\n",
    "#y_pred_1 =lda_A1.predict(x_train)\n",
    "#print(confusion_matrix(y_train, y_pred_1))\n",
    "#print(classification_report(y_train, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a717612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 1, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_lda_A.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88065f9b",
   "metadata": {},
   "source": [
    "## LDA ~ svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e42e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_2 = LinearDiscriminantAnalysis(solver='svd', )#note svd does not run with shrinkage and models using it will be tuned separately\n",
    "parameters_2 = {\n",
    "    'n_components': (1,2),\n",
    "    'store_covariance' :(True, False),\n",
    "                   }\n",
    "# with GridSearch\n",
    "grid_search_lda_B = GridSearchCV(\n",
    "    estimator=estimator_2,\n",
    "    param_grid=parameters_2,\n",
    "    scoring = 'accuracy',\n",
    "    refit = True,\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff3aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[495   2  11]\n",
      " [  1 494   3]\n",
      " [  2   1 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       508\n",
      "           1       0.99      0.99      0.99       498\n",
      "           2       0.97      0.99      0.98       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n",
      "[[74 11 24]\n",
      " [27 62 18]\n",
      " [26 24 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63       109\n",
      "           1       0.64      0.58      0.61       107\n",
      "           2       0.60      0.55      0.57       112\n",
      "\n",
      "    accuracy                           0.60       328\n",
      "   macro avg       0.61      0.60      0.60       328\n",
      "weighted avg       0.61      0.60      0.60       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_B1=grid_search_lda_B.fit(x_train, y_train)\n",
    "train_score(lda_B1)\n",
    "val_score(lda_B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db6c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 1, 'store_covariance': True}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_lda_B.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37dc2a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[452  18  38]\n",
      " [ 14 439  45]\n",
      " [ 22  14 489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       508\n",
      "           1       0.93      0.88      0.91       498\n",
      "           2       0.85      0.93      0.89       525\n",
      "\n",
      "    accuracy                           0.90      1531\n",
      "   macro avg       0.90      0.90      0.90      1531\n",
      "weighted avg       0.90      0.90      0.90      1531\n",
      "\n",
      "[[452  18  38]\n",
      " [ 14 439  45]\n",
      " [ 22  14 489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       508\n",
      "           1       0.93      0.88      0.91       498\n",
      "           2       0.85      0.93      0.89       525\n",
      "\n",
      "    accuracy                           0.90      1531\n",
      "   macro avg       0.90      0.90      0.90      1531\n",
      "weighted avg       0.90      0.90      0.90      1531\n",
      "\n",
      "[[452  18  38]\n",
      " [ 14 439  45]\n",
      " [ 22  14 489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       508\n",
      "           1       0.93      0.88      0.91       498\n",
      "           2       0.85      0.93      0.89       525\n",
      "\n",
      "    accuracy                           0.90      1531\n",
      "   macro avg       0.90      0.90      0.90      1531\n",
      "weighted avg       0.90      0.90      0.90      1531\n",
      "\n",
      "[[424  31  53]\n",
      " [ 20 410  68]\n",
      " [ 43  27 455]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       508\n",
      "           1       0.88      0.82      0.85       498\n",
      "           2       0.79      0.87      0.83       525\n",
      "\n",
      "    accuracy                           0.84      1531\n",
      "   macro avg       0.85      0.84      0.84      1531\n",
      "weighted avg       0.84      0.84      0.84      1531\n",
      "\n",
      "[[406  41  61]\n",
      " [ 34 374  90]\n",
      " [ 53  31 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       508\n",
      "           1       0.84      0.75      0.79       498\n",
      "           2       0.74      0.84      0.79       525\n",
      "\n",
      "    accuracy                           0.80      1531\n",
      "   macro avg       0.80      0.80      0.80      1531\n",
      "weighted avg       0.80      0.80      0.80      1531\n",
      "\n",
      "[[399  43  66]\n",
      " [ 34 355 109]\n",
      " [ 61  35 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       508\n",
      "           1       0.82      0.71      0.76       498\n",
      "           2       0.71      0.82      0.76       525\n",
      "\n",
      "    accuracy                           0.77      1531\n",
      "   macro avg       0.78      0.77      0.77      1531\n",
      "weighted avg       0.78      0.77      0.77      1531\n",
      "\n",
      "[[386  52  70]\n",
      " [ 36 344 118]\n",
      " [ 63  43 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       508\n",
      "           1       0.78      0.69      0.73       498\n",
      "           2       0.69      0.80      0.74       525\n",
      "\n",
      "    accuracy                           0.75      1531\n",
      "   macro avg       0.76      0.75      0.75      1531\n",
      "weighted avg       0.76      0.75      0.75      1531\n",
      "\n",
      "[[364  60  84]\n",
      " [ 43 333 122]\n",
      " [ 79  52 394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73       508\n",
      "           1       0.75      0.67      0.71       498\n",
      "           2       0.66      0.75      0.70       525\n",
      "\n",
      "    accuracy                           0.71      1531\n",
      "   macro avg       0.72      0.71      0.71      1531\n",
      "weighted avg       0.72      0.71      0.71      1531\n",
      "\n",
      "[[452  18  38]\n",
      " [ 14 439  45]\n",
      " [ 22  14 489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       508\n",
      "           1       0.93      0.88      0.91       498\n",
      "           2       0.85      0.93      0.89       525\n",
      "\n",
      "    accuracy                           0.90      1531\n",
      "   macro avg       0.90      0.90      0.90      1531\n",
      "weighted avg       0.90      0.90      0.90      1531\n",
      "\n",
      "[[495   2  11]\n",
      " [  1 494   3]\n",
      " [  2   1 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       508\n",
      "           1       0.99      0.99      0.99       498\n",
      "           2       0.97      0.99      0.98       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n",
      "[[495   2  11]\n",
      " [  1 494   3]\n",
      " [  2   1 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       508\n",
      "           1       0.99      0.99      0.99       498\n",
      "           2       0.97      0.99      0.98       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "train_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6455683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  6 20]\n",
      " [14 72 21]\n",
      " [17 15 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       109\n",
      "           1       0.77      0.67      0.72       107\n",
      "           2       0.66      0.71      0.69       112\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.72      0.72      0.72       328\n",
      "weighted avg       0.72      0.72      0.72       328\n",
      "\n",
      "[[83  6 20]\n",
      " [14 72 21]\n",
      " [17 15 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       109\n",
      "           1       0.77      0.67      0.72       107\n",
      "           2       0.66      0.71      0.69       112\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.72      0.72      0.72       328\n",
      "weighted avg       0.72      0.72      0.72       328\n",
      "\n",
      "[[83  6 20]\n",
      " [14 72 21]\n",
      " [17 15 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       109\n",
      "           1       0.77      0.67      0.72       107\n",
      "           2       0.66      0.71      0.69       112\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.72      0.72      0.72       328\n",
      "weighted avg       0.72      0.72      0.72       328\n",
      "\n",
      "[[80  7 22]\n",
      " [14 70 23]\n",
      " [20 12 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       109\n",
      "           1       0.79      0.65      0.71       107\n",
      "           2       0.64      0.71      0.68       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.71      0.70      0.70       328\n",
      "weighted avg       0.71      0.70      0.70       328\n",
      "\n",
      "[[80  7 22]\n",
      " [15 71 21]\n",
      " [16 13 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       109\n",
      "           1       0.78      0.66      0.72       107\n",
      "           2       0.66      0.74      0.70       112\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.72      0.71      0.71       328\n",
      "weighted avg       0.72      0.71      0.71       328\n",
      "\n",
      "[[78  8 23]\n",
      " [15 71 21]\n",
      " [17 10 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       109\n",
      "           1       0.80      0.66      0.72       107\n",
      "           2       0.66      0.76      0.71       112\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.72      0.71      0.71       328\n",
      "weighted avg       0.72      0.71      0.71       328\n",
      "\n",
      "[[77 10 22]\n",
      " [13 71 23]\n",
      " [16 12 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       109\n",
      "           1       0.76      0.66      0.71       107\n",
      "           2       0.65      0.75      0.70       112\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.71      0.71      0.71       328\n",
      "weighted avg       0.71      0.71      0.71       328\n",
      "\n",
      "[[73 10 26]\n",
      " [13 74 20]\n",
      " [16 12 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       109\n",
      "           1       0.77      0.69      0.73       107\n",
      "           2       0.65      0.75      0.69       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.71      0.70      0.71       328\n",
      "weighted avg       0.71      0.70      0.70       328\n",
      "\n",
      "[[83  6 20]\n",
      " [14 72 21]\n",
      " [17 15 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       109\n",
      "           1       0.77      0.67      0.72       107\n",
      "           2       0.66      0.71      0.69       112\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.72      0.72      0.72       328\n",
      "weighted avg       0.72      0.72      0.72       328\n",
      "\n",
      "[[74 11 24]\n",
      " [27 62 18]\n",
      " [26 24 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63       109\n",
      "           1       0.64      0.58      0.61       107\n",
      "           2       0.60      0.55      0.57       112\n",
      "\n",
      "    accuracy                           0.60       328\n",
      "   macro avg       0.61      0.60      0.60       328\n",
      "weighted avg       0.61      0.60      0.60       328\n",
      "\n",
      "[[74 11 24]\n",
      " [27 62 18]\n",
      " [26 24 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63       109\n",
      "           1       0.64      0.58      0.61       107\n",
      "           2       0.60      0.55      0.57       112\n",
      "\n",
      "    accuracy                           0.60       328\n",
      "   macro avg       0.61      0.60      0.60       328\n",
      "weighted avg       0.61      0.60      0.60       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "val_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6672b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  7 17]\n",
      " [17 71 19]\n",
      " [22 16 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       109\n",
      "           1       0.76      0.66      0.71       107\n",
      "           2       0.68      0.66      0.67       113\n",
      "\n",
      "    accuracy                           0.70       329\n",
      "   macro avg       0.71      0.70      0.70       329\n",
      "weighted avg       0.70      0.70      0.70       329\n",
      "\n",
      "[[85  7 17]\n",
      " [17 71 19]\n",
      " [22 16 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       109\n",
      "           1       0.76      0.66      0.71       107\n",
      "           2       0.68      0.66      0.67       113\n",
      "\n",
      "    accuracy                           0.70       329\n",
      "   macro avg       0.71      0.70      0.70       329\n",
      "weighted avg       0.70      0.70      0.70       329\n",
      "\n",
      "[[85  7 17]\n",
      " [17 71 19]\n",
      " [22 16 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       109\n",
      "           1       0.76      0.66      0.71       107\n",
      "           2       0.68      0.66      0.67       113\n",
      "\n",
      "    accuracy                           0.70       329\n",
      "   macro avg       0.71      0.70      0.70       329\n",
      "weighted avg       0.70      0.70      0.70       329\n",
      "\n",
      "[[85  7 17]\n",
      " [17 71 19]\n",
      " [22 16 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       109\n",
      "           1       0.76      0.66      0.71       107\n",
      "           2       0.68      0.66      0.67       113\n",
      "\n",
      "    accuracy                           0.70       329\n",
      "   macro avg       0.71      0.70      0.70       329\n",
      "weighted avg       0.70      0.70      0.70       329\n",
      "\n",
      "[[79 17 13]\n",
      " [22 63 22]\n",
      " [33 18 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65       109\n",
      "           1       0.64      0.59      0.61       107\n",
      "           2       0.64      0.55      0.59       113\n",
      "\n",
      "    accuracy                           0.62       329\n",
      "   macro avg       0.62      0.62      0.62       329\n",
      "weighted avg       0.62      0.62      0.62       329\n",
      "\n",
      "[[79 17 13]\n",
      " [22 63 22]\n",
      " [33 18 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65       109\n",
      "           1       0.64      0.59      0.61       107\n",
      "           2       0.64      0.55      0.59       113\n",
      "\n",
      "    accuracy                           0.62       329\n",
      "   macro avg       0.62      0.62      0.62       329\n",
      "weighted avg       0.62      0.62      0.62       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis( solver='svd',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95503933",
   "metadata": {},
   "source": [
    "# Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b78167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = '/Users/hanyijia/Desktop/Midterm_Project/real'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,1))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6d01313",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115cc37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 4]\n",
      " [2 3 0]\n",
      " [1 2 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.50      0.60      0.55         5\n",
      "           2       0.20      0.25      0.22         4\n",
      "\n",
      "    accuracy                           0.29        14\n",
      "   macro avg       0.23      0.28      0.26        14\n",
      "weighted avg       0.24      0.29      0.26        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_self = best_model.predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self))\n",
    "print(classification_report(y_self_test, y_pred_self))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d123819",
   "metadata": {},
   "source": [
    "# Preprocessing Image - 3 color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35d8e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "train_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/train'\n",
    "test_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/test'\n",
    "val_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372f02df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102194</td>\n",
       "      <td>0.444992</td>\n",
       "      <td>0.135836</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.459815</td>\n",
       "      <td>0.147550</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>0.478260</td>\n",
       "      <td>0.161213</td>\n",
       "      <td>0.143804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>0.136473</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.159842</td>\n",
       "      <td>0.137262</td>\n",
       "      <td>0.491267</td>\n",
       "      <td>0.156954</td>\n",
       "      <td>0.135339</td>\n",
       "      <td>0.478176</td>\n",
       "      <td>0.146796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121430</td>\n",
       "      <td>0.455724</td>\n",
       "      <td>0.175348</td>\n",
       "      <td>0.119495</td>\n",
       "      <td>0.464168</td>\n",
       "      <td>0.179721</td>\n",
       "      <td>0.122617</td>\n",
       "      <td>0.472050</td>\n",
       "      <td>0.186888</td>\n",
       "      <td>0.129316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205825</td>\n",
       "      <td>0.129695</td>\n",
       "      <td>0.502115</td>\n",
       "      <td>0.200263</td>\n",
       "      <td>0.134544</td>\n",
       "      <td>0.494757</td>\n",
       "      <td>0.194046</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.481780</td>\n",
       "      <td>0.186596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134954</td>\n",
       "      <td>0.483106</td>\n",
       "      <td>0.161084</td>\n",
       "      <td>0.133641</td>\n",
       "      <td>0.488475</td>\n",
       "      <td>0.164305</td>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.496776</td>\n",
       "      <td>0.170826</td>\n",
       "      <td>0.145869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198906</td>\n",
       "      <td>0.155011</td>\n",
       "      <td>0.527030</td>\n",
       "      <td>0.195420</td>\n",
       "      <td>0.156122</td>\n",
       "      <td>0.519059</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>0.153446</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.181782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279692</td>\n",
       "      <td>0.605938</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>0.286369</td>\n",
       "      <td>0.617099</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.292813</td>\n",
       "      <td>0.630146</td>\n",
       "      <td>0.253869</td>\n",
       "      <td>0.302303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189960</td>\n",
       "      <td>0.212207</td>\n",
       "      <td>0.563124</td>\n",
       "      <td>0.187836</td>\n",
       "      <td>0.208112</td>\n",
       "      <td>0.552801</td>\n",
       "      <td>0.184736</td>\n",
       "      <td>0.207208</td>\n",
       "      <td>0.541680</td>\n",
       "      <td>0.179889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113330</td>\n",
       "      <td>0.494130</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0.116477</td>\n",
       "      <td>0.496185</td>\n",
       "      <td>0.166473</td>\n",
       "      <td>0.121879</td>\n",
       "      <td>0.504746</td>\n",
       "      <td>0.172571</td>\n",
       "      <td>0.130712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192794</td>\n",
       "      <td>0.130974</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>0.131893</td>\n",
       "      <td>0.517254</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>0.132387</td>\n",
       "      <td>0.504592</td>\n",
       "      <td>0.178439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.141204</td>\n",
       "      <td>0.476346</td>\n",
       "      <td>0.166657</td>\n",
       "      <td>0.143017</td>\n",
       "      <td>0.486477</td>\n",
       "      <td>0.173556</td>\n",
       "      <td>0.147825</td>\n",
       "      <td>0.498679</td>\n",
       "      <td>0.182253</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178465</td>\n",
       "      <td>0.144751</td>\n",
       "      <td>0.530192</td>\n",
       "      <td>0.170916</td>\n",
       "      <td>0.145742</td>\n",
       "      <td>0.522791</td>\n",
       "      <td>0.166768</td>\n",
       "      <td>0.148173</td>\n",
       "      <td>0.515571</td>\n",
       "      <td>0.164658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.129372</td>\n",
       "      <td>0.479174</td>\n",
       "      <td>0.170895</td>\n",
       "      <td>0.131359</td>\n",
       "      <td>0.487556</td>\n",
       "      <td>0.175582</td>\n",
       "      <td>0.134747</td>\n",
       "      <td>0.499410</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.143919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168821</td>\n",
       "      <td>0.114848</td>\n",
       "      <td>0.486516</td>\n",
       "      <td>0.167657</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.483922</td>\n",
       "      <td>0.166708</td>\n",
       "      <td>0.119823</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.163681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.137241</td>\n",
       "      <td>0.536132</td>\n",
       "      <td>0.227693</td>\n",
       "      <td>0.137057</td>\n",
       "      <td>0.541904</td>\n",
       "      <td>0.228550</td>\n",
       "      <td>0.141502</td>\n",
       "      <td>0.548716</td>\n",
       "      <td>0.234195</td>\n",
       "      <td>0.151002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218816</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.536301</td>\n",
       "      <td>0.221310</td>\n",
       "      <td>0.150079</td>\n",
       "      <td>0.529920</td>\n",
       "      <td>0.225495</td>\n",
       "      <td>0.151554</td>\n",
       "      <td>0.514688</td>\n",
       "      <td>0.223520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.195964</td>\n",
       "      <td>0.602389</td>\n",
       "      <td>0.275032</td>\n",
       "      <td>0.201899</td>\n",
       "      <td>0.610177</td>\n",
       "      <td>0.280377</td>\n",
       "      <td>0.205010</td>\n",
       "      <td>0.618302</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230975</td>\n",
       "      <td>0.157773</td>\n",
       "      <td>0.568914</td>\n",
       "      <td>0.225772</td>\n",
       "      <td>0.159223</td>\n",
       "      <td>0.560778</td>\n",
       "      <td>0.218945</td>\n",
       "      <td>0.165199</td>\n",
       "      <td>0.554145</td>\n",
       "      <td>0.218303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.168876</td>\n",
       "      <td>0.459974</td>\n",
       "      <td>0.070098</td>\n",
       "      <td>0.173914</td>\n",
       "      <td>0.463065</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.179385</td>\n",
       "      <td>0.470083</td>\n",
       "      <td>0.068624</td>\n",
       "      <td>0.184749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103621</td>\n",
       "      <td>0.173352</td>\n",
       "      <td>0.551045</td>\n",
       "      <td>0.098831</td>\n",
       "      <td>0.175015</td>\n",
       "      <td>0.546776</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>0.178308</td>\n",
       "      <td>0.542016</td>\n",
       "      <td>0.101690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.102194  0.444992  0.135836  0.112751  0.459815  0.147550  0.125921   \n",
       "1     0.121430  0.455724  0.175348  0.119495  0.464168  0.179721  0.122617   \n",
       "2     0.134954  0.483106  0.161084  0.133641  0.488475  0.164305  0.135341   \n",
       "3     0.279692  0.605938  0.234714  0.286369  0.617099  0.243470  0.292813   \n",
       "4     0.113330  0.494130  0.164646  0.116477  0.496185  0.166473  0.121879   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1526  0.141204  0.476346  0.166657  0.143017  0.486477  0.173556  0.147825   \n",
       "1527  0.129372  0.479174  0.170895  0.131359  0.487556  0.175582  0.134747   \n",
       "1528  0.137241  0.536132  0.227693  0.137057  0.541904  0.228550  0.141502   \n",
       "1529  0.195964  0.602389  0.275032  0.201899  0.610177  0.280377  0.205010   \n",
       "1530  0.168876  0.459974  0.070098  0.173914  0.463065  0.068548  0.179385   \n",
       "\n",
       "          7         8         9     ...      3062      3063      3064  \\\n",
       "0     0.478260  0.161213  0.143804  ...  0.163256  0.136473  0.499412   \n",
       "1     0.472050  0.186888  0.129316  ...  0.205825  0.129695  0.502115   \n",
       "2     0.496776  0.170826  0.145869  ...  0.198906  0.155011  0.527030   \n",
       "3     0.630146  0.253869  0.302303  ...  0.189960  0.212207  0.563124   \n",
       "4     0.504746  0.172571  0.130712  ...  0.192794  0.130974  0.524209   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1526  0.498679  0.182253  0.155500  ...  0.178465  0.144751  0.530192   \n",
       "1527  0.499410  0.183991  0.143919  ...  0.168821  0.114848  0.486516   \n",
       "1528  0.548716  0.234195  0.151002  ...  0.218816  0.147365  0.536301   \n",
       "1529  0.618302  0.286804  0.211289  ...  0.230975  0.157773  0.568914   \n",
       "1530  0.470083  0.068624  0.184749  ...  0.103621  0.173352  0.551045   \n",
       "\n",
       "          3065      3066      3067      3068      3069      3070      3071  \n",
       "0     0.159842  0.137262  0.491267  0.156954  0.135339  0.478176  0.146796  \n",
       "1     0.200263  0.134544  0.494757  0.194046  0.138401  0.481780  0.186596  \n",
       "2     0.195420  0.156122  0.519059  0.191351  0.153446  0.506500  0.181782  \n",
       "3     0.187836  0.208112  0.552801  0.184736  0.207208  0.541680  0.179889  \n",
       "4     0.189583  0.131893  0.517254  0.184485  0.132387  0.504592  0.178439  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1526  0.170916  0.145742  0.522791  0.166768  0.148173  0.515571  0.164658  \n",
       "1527  0.167657  0.117761  0.483922  0.166708  0.119823  0.476000  0.163681  \n",
       "1528  0.221310  0.150079  0.529920  0.225495  0.151554  0.514688  0.223520  \n",
       "1529  0.225772  0.159223  0.560778  0.218945  0.165199  0.554145  0.218303  \n",
       "1530  0.098831  0.175015  0.546776  0.095835  0.178308  0.542016  0.101690  \n",
       "\n",
       "[1531 rows x 3072 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "080bc025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "1526    2\n",
       "1527    2\n",
       "1528    1\n",
       "1529    2\n",
       "1530    2\n",
       "Name: Target, Length: 1531, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5953005",
   "metadata": {},
   "source": [
    "# LDA - Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36dfe4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[91 10  8]\n",
      " [17 75 15]\n",
      " [ 6 16 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       109\n",
      "           1       0.74      0.70      0.72       107\n",
      "           2       0.80      0.80      0.80       112\n",
      "\n",
      "    accuracy                           0.78       328\n",
      "   macro avg       0.78      0.78      0.78       328\n",
      "weighted avg       0.78      0.78      0.78       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Metric\n",
    "\n",
    "lda_base = LinearDiscriminantAnalysis()\n",
    "lda_base.fit(x_train, y_train)\n",
    "\n",
    "#y_pred= model.predict(x_train)\n",
    "#model.decision_function(x_train)\n",
    "#confusion_matrix(y_train, y_pred)\n",
    "#print(classification_report(y_train, y_pred))\n",
    "train_score(lda_base)\n",
    "val_score(lda_base)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2abaec25",
   "metadata": {},
   "source": [
    "# LDA - lsqr&eigen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "151cb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter tuning with GridSearchCV \n",
    "\n",
    "\n",
    "estimator_1 = LinearDiscriminantAnalysis(shrinkage='auto')\n",
    "parameters_1 = {\n",
    "    'solver': ('lsqr','eigen'),  #note svd does not run with shrinkage and models using it will be tuned separately\n",
    "    'n_components': (1,2),\n",
    "                   }\n",
    "# with GridSearch\n",
    "grid_search_lda_A = GridSearchCV(\n",
    "    estimator=estimator_1,\n",
    "    param_grid=parameters_1,\n",
    "    scoring = 'accuracy',\n",
    "    refit = True,\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb8d886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[504   0   4]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       0.99      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[ 93   6  10]\n",
      " [  8  91   8]\n",
      " [  1   5 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       109\n",
      "           1       0.89      0.85      0.87       107\n",
      "           2       0.85      0.95      0.90       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.89      0.88      0.88       328\n",
      "weighted avg       0.89      0.88      0.88       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_A1=grid_search_lda_A.fit(x_train, y_train)\n",
    "train_score(lda_A1)\n",
    "val_score(lda_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f604f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 1, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_lda_A.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f339031",
   "metadata": {},
   "source": [
    "## LDA ~ svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77bab185",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_2 = LinearDiscriminantAnalysis(solver='svd', )#note svd does not run with shrinkage and models using it will be tuned separately\n",
    "parameters_2 = {\n",
    "    'n_components': (1,2),\n",
    "    'store_covariance' :(True, False),\n",
    "                   }\n",
    "# with GridSearch\n",
    "grid_search_lda_B = GridSearchCV(\n",
    "    estimator=estimator_2,\n",
    "    param_grid=parameters_2,\n",
    "    scoring = 'accuracy',\n",
    "    refit = True,\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77c5f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[91 10  8]\n",
      " [17 75 15]\n",
      " [ 6 16 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       109\n",
      "           1       0.74      0.70      0.72       107\n",
      "           2       0.80      0.80      0.80       112\n",
      "\n",
      "    accuracy                           0.78       328\n",
      "   macro avg       0.78      0.78      0.78       328\n",
      "weighted avg       0.78      0.78      0.78       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_B1=grid_search_lda_B.fit(x_train, y_train)\n",
    "train_score(lda_B1)\n",
    "val_score(lda_B1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30c3d231",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77877ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[504   0   4]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       0.99      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[504   0   4]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       0.99      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[504   0   4]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       0.99      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[501   2   5]\n",
      " [  2 489   7]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       508\n",
      "           1       1.00      0.98      0.99       498\n",
      "           2       0.98      1.00      0.99       525\n",
      "\n",
      "    accuracy                           0.99      1531\n",
      "   macro avg       0.99      0.99      0.99      1531\n",
      "weighted avg       0.99      0.99      0.99      1531\n",
      "\n",
      "[[492   7   9]\n",
      " [  5 479  14]\n",
      " [  3   2 520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       508\n",
      "           1       0.98      0.96      0.97       498\n",
      "           2       0.96      0.99      0.97       525\n",
      "\n",
      "    accuracy                           0.97      1531\n",
      "   macro avg       0.97      0.97      0.97      1531\n",
      "weighted avg       0.97      0.97      0.97      1531\n",
      "\n",
      "[[480  10  18]\n",
      " [  6 474  18]\n",
      " [  3   3 519]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       508\n",
      "           1       0.97      0.95      0.96       498\n",
      "           2       0.94      0.99      0.96       525\n",
      "\n",
      "    accuracy                           0.96      1531\n",
      "   macro avg       0.96      0.96      0.96      1531\n",
      "weighted avg       0.96      0.96      0.96      1531\n",
      "\n",
      "[[470  14  24]\n",
      " [  9 468  21]\n",
      " [  3   4 518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       508\n",
      "           1       0.96      0.94      0.95       498\n",
      "           2       0.92      0.99      0.95       525\n",
      "\n",
      "    accuracy                           0.95      1531\n",
      "   macro avg       0.95      0.95      0.95      1531\n",
      "weighted avg       0.95      0.95      0.95      1531\n",
      "\n",
      "[[458  19  31]\n",
      " [ 14 451  33]\n",
      " [  4  12 509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       508\n",
      "           1       0.94      0.91      0.92       498\n",
      "           2       0.89      0.97      0.93       525\n",
      "\n",
      "    accuracy                           0.93      1531\n",
      "   macro avg       0.93      0.93      0.93      1531\n",
      "weighted avg       0.93      0.93      0.93      1531\n",
      "\n",
      "[[504   0   4]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       0.99      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[508   0   0]\n",
      " [  0 498   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "train_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee8a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93   6  10]\n",
      " [  8  91   8]\n",
      " [  1   5 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       109\n",
      "           1       0.89      0.85      0.87       107\n",
      "           2       0.85      0.95      0.90       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.89      0.88      0.88       328\n",
      "weighted avg       0.89      0.88      0.88       328\n",
      "\n",
      "[[ 93   6  10]\n",
      " [  8  91   8]\n",
      " [  1   5 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       109\n",
      "           1       0.89      0.85      0.87       107\n",
      "           2       0.85      0.95      0.90       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.89      0.88      0.88       328\n",
      "weighted avg       0.89      0.88      0.88       328\n",
      "\n",
      "[[ 93   6  10]\n",
      " [  8  91   8]\n",
      " [  1   5 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       109\n",
      "           1       0.89      0.85      0.87       107\n",
      "           2       0.85      0.95      0.90       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.89      0.88      0.88       328\n",
      "weighted avg       0.89      0.88      0.88       328\n",
      "\n",
      "[[ 94   3  12]\n",
      " [ 11  88   8]\n",
      " [  1   6 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       109\n",
      "           1       0.91      0.82      0.86       107\n",
      "           2       0.84      0.94      0.89       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.88      0.87      0.87       328\n",
      "weighted avg       0.88      0.88      0.87       328\n",
      "\n",
      "[[ 95   4  10]\n",
      " [ 11  89   7]\n",
      " [  0   5 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       109\n",
      "           1       0.91      0.83      0.87       107\n",
      "           2       0.86      0.96      0.91       112\n",
      "\n",
      "    accuracy                           0.89       328\n",
      "   macro avg       0.89      0.89      0.89       328\n",
      "weighted avg       0.89      0.89      0.89       328\n",
      "\n",
      "[[ 95   5   9]\n",
      " [ 11  89   7]\n",
      " [  0   5 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       109\n",
      "           1       0.90      0.83      0.86       107\n",
      "           2       0.87      0.96      0.91       112\n",
      "\n",
      "    accuracy                           0.89       328\n",
      "   macro avg       0.89      0.89      0.89       328\n",
      "weighted avg       0.89      0.89      0.89       328\n",
      "\n",
      "[[ 94   6   9]\n",
      " [  9  92   6]\n",
      " [  1   5 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       109\n",
      "           1       0.89      0.86      0.88       107\n",
      "           2       0.88      0.95      0.91       112\n",
      "\n",
      "    accuracy                           0.89       328\n",
      "   macro avg       0.89      0.89      0.89       328\n",
      "weighted avg       0.89      0.89      0.89       328\n",
      "\n",
      "[[ 93   4  12]\n",
      " [  9  92   6]\n",
      " [  3   7 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       109\n",
      "           1       0.89      0.86      0.88       107\n",
      "           2       0.85      0.91      0.88       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.88      0.87      0.87       328\n",
      "weighted avg       0.88      0.88      0.87       328\n",
      "\n",
      "[[ 93   6  10]\n",
      " [  8  91   8]\n",
      " [  1   5 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       109\n",
      "           1       0.89      0.85      0.87       107\n",
      "           2       0.85      0.95      0.90       112\n",
      "\n",
      "    accuracy                           0.88       328\n",
      "   macro avg       0.89      0.88      0.88       328\n",
      "weighted avg       0.89      0.88      0.88       328\n",
      "\n",
      "[[91 10  8]\n",
      " [17 75 15]\n",
      " [ 6 16 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       109\n",
      "           1       0.74      0.70      0.72       107\n",
      "           2       0.80      0.80      0.80       112\n",
      "\n",
      "    accuracy                           0.78       328\n",
      "   macro avg       0.78      0.78      0.78       328\n",
      "weighted avg       0.78      0.78      0.78       328\n",
      "\n",
      "[[91 10  8]\n",
      " [17 75 15]\n",
      " [ 6 16 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       109\n",
      "           1       0.74      0.70      0.72       107\n",
      "           2       0.80      0.80      0.80       112\n",
      "\n",
      "    accuracy                           0.78       328\n",
      "   macro avg       0.78      0.78      0.78       328\n",
      "weighted avg       0.78      0.78      0.78       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train))        # Best Validation Accuracy\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "val_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab82a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   3   5]\n",
      " [  3  96   8]\n",
      " [  5   3 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       109\n",
      "           1       0.94      0.90      0.92       107\n",
      "           2       0.89      0.93      0.91       113\n",
      "\n",
      "    accuracy                           0.92       329\n",
      "   macro avg       0.92      0.92      0.92       329\n",
      "weighted avg       0.92      0.92      0.92       329\n",
      "\n",
      "[[101   3   5]\n",
      " [  3  96   8]\n",
      " [  5   3 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       109\n",
      "           1       0.94      0.90      0.92       107\n",
      "           2       0.89      0.93      0.91       113\n",
      "\n",
      "    accuracy                           0.92       329\n",
      "   macro avg       0.92      0.92      0.92       329\n",
      "weighted avg       0.92      0.92      0.92       329\n",
      "\n",
      "[[101   3   5]\n",
      " [  3  96   8]\n",
      " [  5   3 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       109\n",
      "           1       0.94      0.90      0.92       107\n",
      "           2       0.89      0.93      0.91       113\n",
      "\n",
      "    accuracy                           0.92       329\n",
      "   macro avg       0.92      0.92      0.92       329\n",
      "weighted avg       0.92      0.92      0.92       329\n",
      "\n",
      "[[102   2   5]\n",
      " [  3  95   9]\n",
      " [  4   5 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       109\n",
      "           1       0.93      0.89      0.91       107\n",
      "           2       0.88      0.92      0.90       113\n",
      "\n",
      "    accuracy                           0.91       329\n",
      "   macro avg       0.92      0.91      0.92       329\n",
      "weighted avg       0.92      0.91      0.91       329\n",
      "\n",
      "[[101   1   7]\n",
      " [  3  96   8]\n",
      " [  5   6 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       109\n",
      "           1       0.93      0.90      0.91       107\n",
      "           2       0.87      0.90      0.89       113\n",
      "\n",
      "    accuracy                           0.91       329\n",
      "   macro avg       0.91      0.91      0.91       329\n",
      "weighted avg       0.91      0.91      0.91       329\n",
      "\n",
      "[[ 99   2   8]\n",
      " [  5  94   8]\n",
      " [  5   6 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       109\n",
      "           1       0.92      0.88      0.90       107\n",
      "           2       0.86      0.90      0.88       113\n",
      "\n",
      "    accuracy                           0.90       329\n",
      "   macro avg       0.90      0.90      0.90       329\n",
      "weighted avg       0.90      0.90      0.90       329\n",
      "\n",
      "[[ 99   1   9]\n",
      " [  4  95   8]\n",
      " [  3   6 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       109\n",
      "           1       0.93      0.89      0.91       107\n",
      "           2       0.86      0.92      0.89       113\n",
      "\n",
      "    accuracy                           0.91       329\n",
      "   macro avg       0.91      0.91      0.91       329\n",
      "weighted avg       0.91      0.91      0.91       329\n",
      "\n",
      "[[ 99   1   9]\n",
      " [  7  92   8]\n",
      " [  4   7 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       109\n",
      "           1       0.92      0.86      0.89       107\n",
      "           2       0.86      0.90      0.88       113\n",
      "\n",
      "    accuracy                           0.89       329\n",
      "   macro avg       0.89      0.89      0.89       329\n",
      "weighted avg       0.89      0.89      0.89       329\n",
      "\n",
      "[[101   3   5]\n",
      " [  3  96   8]\n",
      " [  5   3 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       109\n",
      "           1       0.94      0.90      0.92       107\n",
      "           2       0.89      0.93      0.91       113\n",
      "\n",
      "    accuracy                           0.92       329\n",
      "   macro avg       0.92      0.92      0.92       329\n",
      "weighted avg       0.92      0.92      0.92       329\n",
      "\n",
      "[[95  6  8]\n",
      " [12 83 12]\n",
      " [15 10 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       109\n",
      "           1       0.84      0.78      0.81       107\n",
      "           2       0.81      0.78      0.80       113\n",
      "\n",
      "    accuracy                           0.81       329\n",
      "   macro avg       0.81      0.81      0.81       329\n",
      "weighted avg       0.81      0.81      0.81       329\n",
      "\n",
      "[[95  6  8]\n",
      " [12 83 12]\n",
      " [15 10 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       109\n",
      "           1       0.84      0.78      0.81       107\n",
      "           2       0.81      0.78      0.80       113\n",
      "\n",
      "    accuracy                           0.81       329\n",
      "   macro avg       0.81      0.81      0.81       329\n",
      "weighted avg       0.81      0.81      0.81       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train)) \n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "test_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55ddf260",
   "metadata": {},
   "source": [
    "# Compare misclassified and correctly classified images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df299836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LinearDiscriminantAnalysis(shrinkage=0.7, solver='eigen',n_components=1    ).fit(x_train, y_train)\n",
    "y_pred_test = best_model.predict(x_test)\n",
    "y_test\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46cc8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "missclassified_indices = []\n",
    "for i in range(0,y_test.size):\n",
    "    if y_test[i] != y_pred_test[i]:\n",
    "        missclassified_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 23,\n",
       " 32,\n",
       " 36,\n",
       " 50,\n",
       " 66,\n",
       " 78,\n",
       " 83,\n",
       " 89,\n",
       " 105,\n",
       " 109,\n",
       " 111,\n",
       " 115,\n",
       " 119,\n",
       " 123,\n",
       " 138,\n",
       " 147,\n",
       " 155,\n",
       " 156,\n",
       " 159,\n",
       " 171,\n",
       " 206,\n",
       " 217,\n",
       " 231,\n",
       " 247,\n",
       " 252,\n",
       " 260,\n",
       " 267,\n",
       " 271,\n",
       " 299,\n",
       " 325]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missclassified_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f783e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 1\n",
      "Actual class 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[325]), (32, 32, 3)))\n",
    "print(\"Predicted class\",y_pred_test[325])\n",
    "print(\"Actual class\",y_test[325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 2\n",
      "Actual class 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYYElEQVR4nO2da6xc1XXH/+vMzH3b1zaXGMvQmFfVUloMurKogiJKlIiiSIBUIfiAkILiqApSkdIPiKqFSv1AqgLiQ0VlihWnojwaQFgVakNRJJQvhAsBY3BTCDUNlrEBG+77zuOsfjgH6do6a83Mnpkzjvf/J1mee9bsvdecOWse+z9rLVFVEELOfpJhO0AIKQcGOyGRwGAnJBIY7IREAoOdkEhgsBMSCdVeBovI9QAeAVAB8M+q+oB3/8pEorXp7pcUEcPgjgoytfGk+GjwfGcv5ikJVXpbtqnWst+zxrTYVhN7TDWxbUliP9mtVmraUueBV6oVYy3bD0sx/+TkIhaWVgudDA52EakA+EcA3wTwEYDXRGS/qr5rjalNV/HV72y15rPXqhQ/6KRSfJIAQJwnxZovm9SJXOPke757F4f3qqOwLxwX4yIQL8q8c+8Nc9wwbd7DatkzVhbtYed9NmbaLm1sLDy+fWTcHDMzadtGx0ZM2/yS7WRd7VerjZuLfRyZnDDHNNPic/XXj7xgjunlY/wuAO+r6geqWgfwFIAbe5iPEDJAegn27QB+s+7vj/JjhJAzkJ6+s3eCiOwGsBsAqhvtj92EkMHSyzv7EQAXrPv7/PzYKajqHlWdVdXZygQ3/wkZFr1E32sALhWRC0VkBMCtAPb3xy1CSL8J/hivqk0RuQvAfyKT3vaq6jvuIIH98uK87GhSvCWsibO1W3F2up21xJE7IMXracAOfj7SsdmPzc1U7LMMGCoriuGjo3ghadqPK1mzx+1IzjFt20cnC4/PjNs7+EnaNG0nP/3EtGnVfnCTG+2d9dFRS3qzr4FWatnsc9jTd3ZVfRHAi73MQQgpB36JJiQSGOyERAKDnZBIYLATEgkMdkIiYeC/oDsdU3rxXnYMmzpZGl5yiivzeZkfxjhPTkoNuS63Oo54Jnuc9bhdtS4we9AdZi3oOCIt25Yur9q2pXnbDyOjbLm+YvvhPJ8j46OmbWzKTqBJDfkYAJr1Yl0xrduPud4svgZSU5LjOzsh0cBgJyQSGOyERAKDnZBIYLATEgml78ZbSS1uGak+7uBnE3o77t3XrlNn69wrB+UltHg75J7SYM4ZVh0LvizgDEyLx6WrDXNIc9G2Jat2WacPTpwwbdNTxQkv45s2mWM2TNpJMlYyFODnPLVatv+r1q67m7Bl1IZwrim+sxMSCQx2QiKBwU5IJDDYCYkEBjshkcBgJyQSSpXeRJwOKZ7UZL0khdZHc2yejBY6oz0ssBeSqw5a0pvTtcaR0MSQ0ABAGk6NtOViGW10yV5ra3OzafudDZtM20WTtm1mpFhGG6s47ZicXlOp2o/ZK5SejNqdZLRRfE4Sp3OR9ZS53YlMCyHkrILBTkgkMNgJiQQGOyGRwGAnJBIY7IREQk/Sm4gcBrAAoAWgqaqzbQeFyGimzND9GMBP1nIxpbIwCc3LiPPHdW9MnFGV1MmiW7ZlqGTRlqG2tzYWHv+DyrnmmK2J3SJpSmumbbPR4gkAqsZF0mosm2PShpN95+hriSOlVmq2/0m1OAy963R1zemHZdAPnf1PVPXTPsxDCBkg/BhPSCT0GuwK4Kci8rqI7O6HQ4SQwdDrx/hrVPWIiHwFwEsi8t+q+sr6O+QvArsBoDrt/aCQEDJIenpnV9Uj+f/HATwPYFfBffao6qyqzlYn+a2BkGERHH0iMikiG768DeBbAA72yzFCSH/p5WP8VgDP51k2VQD/qqr/0W6QmDqaNyYET9bqb7qcKwF6fZfcQpU2ifMabY0TW0FDdb5p2maW7OKLl2CLabuwsqnw+KTaX+VGnb5LtYo9TpwstUaz2NZq1oPm8zIEPfyrwGrZZY+yzoeX9RYc7Kr6AYArQscTQsqFX6IJiQQGOyGRwGAnJBIY7IREAoOdkEgoudebmDpVkKDhZr0Fann9lgBDa1E6/vuyXDGVRVtO+t35adO2s7bNtG3GqGkbk+JLq9HwsrVsH5fXVkzb/MKSY1ssPL5xws5C2zpjnw8vezBtOn3sVuwnu2k81+pdw5Ysx15vhBAGOyGRwGAnJBIY7IREAoOdkEgoeTcegFW2zPPE2JT0kgsSf6u767WyYSGZMPYOs5kUBCBx5qw4yyWN4sd9zprdfujyxK4Lt3nNTkBJnJ31xcZC4fF6fdUc02zaCTn1hm1DzU7WOe+8YjVhetJWEipqJ8loavshdkk+v5VTs3hg0wwWez4/JgghUcBgJyQSGOyERAKDnZBIYLATEgkMdkIioVTprVqpYmbTTKFtsWEnM6w1i+UaNzElcRJJXOktYJyb7OLJa844p5WQq68YNdcmmk7SSsN2ZPnEF7YbjlQ2OlEsh01O2K2aKhX7cqyN2LaRMbtt1MhIseSYOrJhY81+XE3j/AKAJE6hP6cIoKbFEpsm9ntxYvShcuVc00IIOatgsBMSCQx2QiKBwU5IJDDYCYkEBjshkdBWehORvQC+DeC4ql6eH9sC4GkAOwAcBnCLqp5su5oAMJKo0oaTMmRlvYUpaME16GybrYWpk7nkNqhyaolp6tjqxRKPLtj10Rprtgy1cdyWyiY3TJm22nix1OfVoGs4Up73XHvZctacmjoSmvPEtDxHWvactVFPgi1+z01b9rVjPa60xxp0PwJw/WnH7gHwsqpeCuDl/G9CyBlM22DP+62fOO3wjQD25bf3Abipv24RQvpN6Hf2rap6NL/9MbKOroSQM5ieN+g06ytrflEQkd0iMicic41Fp9oIIWSghAb7MRHZBgD5/8etO6rqHlWdVdXZ2lT5VbAIIRmhwb4fwB357TsAvNAfdwghg6IT6e1JANcCmBGRjwDcB+ABAM+IyJ0APgRwSyeLpUixqsXSy1pqFyIUKz3M647jCVuOPGGoIJnNatPjzecKbM5a3jhHehs1Mtiu2HShOeYrKxtMW82RRK1sLQBYWy1u17RiHAf852xlxR5Xd6TDhiGHTYzbRSrHx+zWUOOjtg1OUUmvYGbDuJBbznW1MF/c1qrlSIptg11VbzNM32g3lhBy5sBf0BESCQx2QiKBwU5IJDDYCYkEBjshkVD6r1zSqiHXuJ4USxCi9muVm/Xm55t5A7tfy8uScjLiXB8dySsxTEnTnm9p0S722VqwJa9Gy+6JJhXjOavaz9mYI4c5wzA+bWfmjY8XF6Os1WwJrelk5qUtO3tQnaw3Ry2FldzmyXXW6fAy9vjOTkgkMNgJiQQGOyGRwGAnJBIY7IREAoOdkEgoVXpTKJpqyBPey05A4pgrrnWvrgU7oo4W4ip23lKJbaxXinWcN06+Z475/VW70NAl0+eZtmrN6UVmKFuTU3ZfNq8H39LivGlrNBw5zEhjrDs92+pNRxLtvi4qAKBSMSqtArBauo2O2eFpuSFefzjTQgg5q2CwExIJDHZCIoHBTkgkMNgJiYSSd+Nh78Z7v+A3k0nCElq8mnH+dmvxjqo4ayWJfYpFnbUcm1SdFj8bitc7Nm0ntFw8ZSeFjE1ssteynksAa2vLhcfnF4uPA0DL2VWvr9n+Ly/biTyrRn26utMyqursnG/YaCfdjI0Wt7wCgJpT3DAZKR6XODvrS0ZNvl7bPxFCzgIY7IREAoOdkEhgsBMSCQx2QiKBwU5IJHTS/mkvgG8DOK6ql+fH7gfwXQCf5He7V1Vf7GAuVI3aX62mXfcrKBPGGSOODOIlY5hTOkO8+Vw/3EltU71VLClVp2w56X8/PWbaRuftcc0Vu2XXvJG4MtawL7ntY9Ombaxq++ElmUxv2Vh4fHzKk9BsKTK1CsYBWF62z8fSqn19rywZrbKctY7Pf154fK1uy5edvLP/CMD1BccfVtWd+b+2gU4IGS5tg11VXwFwogRfCCEDpJfv7HeJyAER2Ssim/vmESFkIIQG+6MALgawE8BRAA9adxSR3SIyJyJzzQX7J4qEkMESFOyqekxVW6qaAngMwC7nvntUdVZVZ6vG77YJIYMnKNhFZNu6P28GcLA/7hBCBkUn0tuTAK4FMCMiHwG4D8C1IrITmRh1GMD3OllMRFCrFmf41GFnQwVpXgFtnNphZcu5uXchyXwAEkeys+qqAYBWisfVp+wxh9NF0/bhyq9Mm4zYD65SK7ZdN/mH5pjt4+fb8zlZgM3UlrUaaXGLqqW6I5M5WXRNp3Zd06ldlzrX4xetYv//7wt7X/yzenG8rKmTzWdaclT1toLDj7cbRwg5s+Av6AiJBAY7IZHAYCckEhjshEQCg52QSCj3Vy7qZA25KppldDLKQhLl2mBJb16GWqgb6s3pyXIV4ykddQpYbnGKYrac7MHUeXSLxesdnT9pDpletAs2ilMgcn7Nlg6/aBRLVAstW3o70bSLW66kth8tL9OyYr+vrknxufpivFg2BIDGVPFaa1X7eeY7OyGRwGAnJBIY7IREAoOdkEhgsBMSCQx2QiKhVOkt1RT1hiVrOLKFeTysKKO3ltcGzlK8PHnNzYjzstfcupfdy3KJU7ARjil1pDekTpbXxuLHdqj5mTnm/WU7y0sT24/GhJ2JVk+KbamjzTa968N5XlJHivQKVVrXcVJ1JFHLUHX6DpoWQshZBYOdkEhgsBMSCQx2QiKBwU5IJJS6Gy8CVIyEgFbT3bfufi3H5iendO+H1zEqOBMmsIaeJMXjXMUgtFyfk9yRGDv8jRl7uoa9qQ51drNVbTkhVcNHR3apeCqDs+PuJV8l9pT2k+MJIQEJZXxnJyQSGOyERAKDnZBIYLATEgkMdkIigcFOSCR00v7pAgA/BrAVmRiwR1UfEZEtAJ4GsANZC6hbVNUuMIbsB/8jRo20eoA04Td/curTuUt1n5ATTpguJ14NOuv1O1DZ9BJQJDBhxMRJyNHUnjB1pDI1pDKrnmAva3mynOUHAIh1srwaf9Y10KP01gTwA1W9DMDVAL4vIpcBuAfAy6p6KYCX878JIWcobYNdVY+q6hv57QUAhwBsB3AjgH353fYBuGlAPhJC+kBX39lFZAeAKwG8CmCrqh7NTR8j+5hPCDlD6TjYRWQKwLMA7lbV+fU2zb4AFX7BEJHdIjInInPNRef3kISQgdJRsItIDVmgP6Gqz+WHj4nItty+DcDxorGqukdVZ1V1tjrl7MAQQgZK22CXbOv3cQCHVPWhdab9AO7Ib98B4IX+u0cI6RedZL19DcDtAN4WkTfzY/cCeADAMyJyJ4APAdzSbiIBUEmN1xdHerNkEnXSjLxMNE+6ClLDQmUtT1pxXoYTI7PN88WVwgI1Ra9enzlnxauf56zl1X5LnJNlSW+eTGa0Y8pszlrOOP866HqIf+4N2ga7qv7cWfcb3S9JCBkG/AUdIZHAYCckEhjshEQCg52QSGCwExIJpRac1BRorRT/ii5J7R/ctNJG8XyeBOVka3mEqFBeppzbTsqTjLwWT17GluGL1zKqTY8qxxhCWFqW95iDpE9X5gtsK+aMc0+jWRPTu3ic+bpbhhBytsFgJyQSGOyERAKDnZBIYLATEgkMdkIiodxebwrUmsWvL1UrGw5Aq2X1L7OlidTLiDMtbbLlzF5vXgFIB1dCc4Y5toA6hOHSoTOnaXUzDr0sRqcIpNdkzUqXC1UU3XFhTf9cic1aKUBS5Ds7IZHAYCckEhjshEQCg52QSGCwExIJpe7GN1tNfHris0KbjDpJBFbdMm8X3NuNdxJo3J3uPr80ujvd7q5v95kfgZvgfhutoKyhsF3psLQmZ1xg8o9bN9DzIyS5xlMZAuA7OyGRwGAnJBIY7IREAoOdkEhgsBMSCQx2QiKhrfQmIhcA+DGylswKYI+qPiIi9wP4LoBP8rveq6ovtl2xYrXI8QqQWce9BIgwicdNajFkF0/KCy3hJqFik9UqKzChJThJxnrgga2yrDZObecMFu0svOfau3ac1lAhPgZcV53o7E0AP1DVN0RkA4DXReSl3Pawqv5D98sSQsqmk15vRwEczW8viMghANsH7RghpL909Z1dRHYAuBLAq/mhu0TkgIjsFZHN/XaOENI/Og52EZkC8CyAu1V1HsCjAC4GsBPZO/+DxrjdIjInInOtZe97CyFkkHQU7CJSQxboT6jqcwCgqsdUtaWqKYDHAOwqGquqe1R1VlVnKxPc/CdkWLSNPsm2GB8HcEhVH1p3fNu6u90M4GD/3SOE9ItOduO/BuB2AG+LyJv5sXsB3CYiO5HpBocBfK/tTOJJMgGZaJ704yo1oa2EjIwyT57ypBpnqZC6ZP6swSl2QZj+hxbX81czLWJJkYHPi5892G+Zr7/zdbIb/3MUP/72mjoh5IyBX6IJiQQGOyGRwGAnJBIY7IREAoOdkEgoteAkYIsJbpaXKcuFZoYFmcLq/wVKgP1Xw0LbD4Vl9JlT9ludCiYsmw/q/Aq0xMcWIvPxnZ2QSGCwExIJDHZCIoHBTkgkMNgJiQQGOyGRcMZIbyG4mW1uMUpnzgA/3FqCrl7naVdh2psY6/l91PySk0F+GHOG14b0MtsCpzQHefJaaNqe56Sxnltks/usQr6zExIJDHZCIoHBTkgkMNgJiQQGOyGRwGAnJBLKld40rBChJa34Kohj9KQy5+XPUkJCE9SCBa8APSm4GKLXvywoCzAs28zqs5eNC83oswh8ZgJ7DzqpoDaWzRnDd3ZCIoHBTkgkMNgJiQQGOyGRwGAnJBLa7saLyBiAVwCM5vf/iareJyIXAngKwDkAXgdwu6rWQx1RJ/lAUDHGOBN6SQRe/okzZdLnl8bwenfd7xYPoLNSUCuk0AQlr16fazPWC6onmK/WvQVtdtYDFCpvLYNOLt81ANep6hXI2jNfLyJXA/ghgIdV9RIAJwHcGbA+IaQk2ga7Zizmf9byfwrgOgA/yY/vA3DTIBwkhPSHTvuzV/IOrscBvATg1wA+V9VmfpePAGwfiIeEkL7QUbCraktVdwI4H8AuAL/X6QIisltE5kRkrrXs/XSNEDJIutpyUtXPAfwMwB8D2CQiX27wnQ/giDFmj6rOqupsZYKb/4QMi7bRJyLnisim/PY4gG8COIQs6P8sv9sdAF4YkI+EkD7QSSLMNgD7RKSC7MXhGVX9dxF5F8BTIvJ3AH4J4PFOFqxYtckcqcyqqyaJ05rIqeHm5yvYXzWsWm3iaXKOj0gCk3UCCo25ddocozjvB+45Ng2BBeMCbaaHoUlUzmP2W5h1v5z3nJk2Z0zbYFfVAwCuLDj+AbLv74SQ3wL4JZqQSGCwExIJDHZCIoHBTkgkMNgJiQQJrk0WspjIJwA+zP+cAfBpaYvb0I9ToR+n8tvmx1dV9dwiQ6nBfsrCInOqOjuUxekH/YjQD36MJyQSGOyERMIwg33PENdeD/04FfpxKmeNH0P7zk4IKRd+jCckEoYS7CJyvYj8SkTeF5F7huFD7sdhEXlbRN4UkbkS190rIsdF5OC6Y1tE5CUReS//f/OQ/LhfRI7k5+RNEbmhBD8uEJGfici7IvKOiPxFfrzUc+L4Ueo5EZExEfmFiLyV+/G3+fELReTVPG6eFpGRriZW1VL/AaggK2t1EYARAG8BuKxsP3JfDgOYGcK6XwdwFYCD6479PYB78tv3APjhkPy4H8Bflnw+tgG4Kr+9AcD/ALis7HPi+FHqOUGWmTuV364BeBXA1QCeAXBrfvyfAPx5N/MO4519F4D3VfUDzUpPPwXgxiH4MTRU9RUAJ047fCOywp1ASQU8DT9KR1WPquob+e0FZMVRtqPkc+L4USqa0fcir8MI9u0AfrPu72EWq1QAPxWR10Vk95B8+JKtqno0v/0xgK1D9OUuETmQf8wf+NeJ9YjIDmT1E17FEM/JaX4AJZ+TQRR5jX2D7hpVvQrAnwL4voh8fdgOAdkrO3ro69AjjwK4GFmPgKMAHixrYRGZAvAsgLtVdX69rcxzUuBH6edEeyjyajGMYD8C4IJ1f5vFKgeNqh7J/z8O4HkMt/LOMRHZBgD5/8eH4YSqHssvtBTAYyjpnIhIDVmAPaGqz+WHSz8nRX4M65zka3+OLou8Wgwj2F8DcGm+szgC4FYA+8t2QkQmRWTDl7cBfAvAQX/UQNmPrHAnMMQCnl8GV87NKOGciIggq2F4SFUfWmcq9ZxYfpR9TgZW5LWsHcbTdhtvQLbT+WsAfzUkHy5CpgS8BeCdMv0A8CSyj4MNZN+97kTWM+9lAO8B+C8AW4bkx78AeBvAAWTBtq0EP65B9hH9AIA38383lH1OHD9KPScA/ghZEdcDyF5Y/mbdNfsLAO8D+DcAo93My1/QERIJsW/QERINDHZCIoHBTkgkMNgJiQQGOyGRwGAnJBIY7IREAoOdkEj4f5Aqc+qC5YVPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[159]), (32, 32, 3 )))\n",
    "print(\"Predicted class\",y_pred_test[159])\n",
    "print(\"Actual class\",y_test[159])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ba43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class 2\n",
      "Actual class 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(np.array(x_test.T[32]), (32, 32, 3)))\n",
    "print(\"Predicted class\",y_pred_test[32])\n",
    "print(\"Actual class\",y_test[32])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2da6d14a",
   "metadata": {},
   "source": [
    "## Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abba38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = '/Users/hanyijia/Desktop/Midterm_Project/real'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f9a3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 0]\n",
      " [2 3 0]\n",
      " [0 1 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.50      0.60      0.55         5\n",
      "           2       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.70      0.65      0.67        14\n",
      "weighted avg       0.68      0.64      0.65        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_self = best_model.predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self))\n",
    "print(classification_report(y_self_test, y_pred_self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3769a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 1]\n",
      " [3 1 1]\n",
      " [1 1 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.80      0.62         5\n",
      "           1       0.50      0.20      0.29         5\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.50      0.50      0.47        14\n",
      "weighted avg       0.50      0.50      0.46        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_self2 = LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train).predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self2))\n",
    "print(classification_report(y_self_test, y_pred_self2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c39c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 0]\n",
      " [3 2 0]\n",
      " [3 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62         5\n",
      "           1       0.67      0.40      0.50         5\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.37      0.47      0.38        14\n",
      "weighted avg       0.40      0.50      0.40        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_self3 = LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train).predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self3))\n",
    "print(classification_report(y_self_test, y_pred_self3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1c0cbde",
   "metadata": {},
   "source": [
    "# Preprocessing Images - 3 color + Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709328d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 508 image(s) found.\n",
      "Output directory set to /Users/hanyijia/Desktop/Midterm_Project/rps-split/train/rock/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=300x200 at 0x1A5A7B8E0>: 100%|██████████| 508/508 [00:10<00:00, 46.48 Samples/s]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 498 image(s) found.\n",
      "Output directory set to /Users/hanyijia/Desktop/Midterm_Project/rps-split/train/paper/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=300x200 at 0x1A589BB50>: 100%|██████████| 498/498 [00:13<00:00, 37.44 Samples/s]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 525 image(s) found.\n",
      "Output directory set to /Users/hanyijia/Desktop/Midterm_Project/rps-split/train/scissors/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=300x200 at 0x1A58BC400>: 100%|██████████| 525/525 [00:12<00:00, 42.81 Samples/s]                \n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "# Passing the path of the image directory\n",
    "p = Augmentor.Pipeline(os.path.join(train_dir,'rock'))\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(508)\n",
    "\n",
    "p = Augmentor.Pipeline(os.path.join(train_dir,'paper'))\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(498)\n",
    "\n",
    "p = Augmentor.Pipeline(os.path.join(train_dir,'scissors'))\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a82614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n",
      "loaded category:rock successfully for test\n",
      "loaded category:paper successfully for test\n",
      "loaded category:scissors successfully for test\n",
      "loaded category:rock successfully for val\n",
      "loaded category:paper successfully for val\n",
      "loaded category:scissors successfully for val\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "\n",
    "\n",
    "train_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-augmented'\n",
    "test_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/test'\n",
    "val_dir = '/Users/hanyijia/Desktop/Midterm_Project/rps-split/val'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(train_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_train=df.iloc[:,:-1] #input data \n",
    "y_train=df.iloc[:,-1] #output data\n",
    "x_train=x_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train=y_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for test')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_test=df.iloc[:,:-1] #input data \n",
    "y_test=df.iloc[:,-1] #output data\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(val_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for val')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "x_val=df.iloc[:,:-1] #input data \n",
    "y_val=df.iloc[:,-1] #output data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e8eda19",
   "metadata": {},
   "source": [
    "# LDA - Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9505c073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  1 497   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[65 22 22]\n",
      " [54 35 18]\n",
      " [44 29 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.60      0.48       109\n",
      "           1       0.41      0.33      0.36       107\n",
      "           2       0.49      0.35      0.41       112\n",
      "\n",
      "    accuracy                           0.42       328\n",
      "   macro avg       0.43      0.42      0.42       328\n",
      "weighted avg       0.43      0.42      0.42       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Metric\n",
    "\n",
    "lda_base = LinearDiscriminantAnalysis()\n",
    "lda_base.fit(x_train, y_train)\n",
    "\n",
    "#y_pred= model.predict(x_train)\n",
    "#model.decision_function(x_train)\n",
    "#confusion_matrix(y_train, y_pred)\n",
    "#print(classification_report(y_train, y_pred))\n",
    "train_score(lda_base)\n",
    "val_score(lda_base)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f104020",
   "metadata": {},
   "source": [
    "# LDA - lsqr & eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03f0d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter tuning with GridSearchCV \n",
    "\n",
    "\n",
    "estimator_1 = LinearDiscriminantAnalysis(shrinkage='auto')\n",
    "parameters_1 = {\n",
    "    'solver': ('lsqr','eigen'),  #note svd does not run with shrinkage and models using it will be tuned separately\n",
    "    'n_components': (1,2),\n",
    "                   }\n",
    "# with GridSearch\n",
    "grid_search_lda_A = GridSearchCV(\n",
    "    estimator=estimator_1,\n",
    "    param_grid=parameters_1,\n",
    "    scoring = 'accuracy',\n",
    "    refit = True,\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "793c45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[487   3  18]\n",
      " [  4 483  11]\n",
      " [ 15  10 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       508\n",
      "           1       0.97      0.97      0.97       498\n",
      "           2       0.95      0.95      0.95       525\n",
      "\n",
      "    accuracy                           0.96      1531\n",
      "   macro avg       0.96      0.96      0.96      1531\n",
      "weighted avg       0.96      0.96      0.96      1531\n",
      "\n",
      "[[83  8 18]\n",
      " [15 74 18]\n",
      " [13 27 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       109\n",
      "           1       0.68      0.69      0.69       107\n",
      "           2       0.67      0.64      0.65       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.70      0.70      0.70       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_A1=grid_search_lda_A.fit(x_train, y_train)\n",
    "train_score(lda_A1)\n",
    "val_score(lda_A1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6847667f",
   "metadata": {},
   "source": [
    "# LDA - svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126f745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_2 = LinearDiscriminantAnalysis(solver='svd', )#note svd does not run with shrinkage and models using it will be tuned separately\n",
    "parameters_2 = {\n",
    "    'n_components': (1,2),\n",
    "    'store_covariance' :(True, False),\n",
    "                   }\n",
    "# with GridSearch\n",
    "grid_search_lda_B = GridSearchCV(\n",
    "    estimator=estimator_2,\n",
    "    param_grid=parameters_2,\n",
    "    scoring = 'accuracy',\n",
    "    refit = True,\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77bf63f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0]\n",
      " [  1 497   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[65 22 22]\n",
      " [54 35 18]\n",
      " [44 29 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.60      0.48       109\n",
      "           1       0.41      0.33      0.36       107\n",
      "           2       0.49      0.35      0.41       112\n",
      "\n",
      "    accuracy                           0.42       328\n",
      "   macro avg       0.43      0.42      0.42       328\n",
      "weighted avg       0.43      0.42      0.42       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_B1=grid_search_lda_B.fit(x_train, y_train)\n",
    "train_score(lda_B1)\n",
    "val_score(lda_B1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c687a04",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb36cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[487   3  18]\n",
      " [  4 483  11]\n",
      " [ 15  10 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       508\n",
      "           1       0.97      0.97      0.97       498\n",
      "           2       0.95      0.95      0.95       525\n",
      "\n",
      "    accuracy                           0.96      1531\n",
      "   macro avg       0.96      0.96      0.96      1531\n",
      "weighted avg       0.96      0.96      0.96      1531\n",
      "\n",
      "[[487   3  18]\n",
      " [  4 483  11]\n",
      " [ 15  10 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       508\n",
      "           1       0.97      0.97      0.97       498\n",
      "           2       0.95      0.95      0.95       525\n",
      "\n",
      "    accuracy                           0.96      1531\n",
      "   macro avg       0.96      0.96      0.96      1531\n",
      "weighted avg       0.96      0.96      0.96      1531\n",
      "\n",
      "[[487   3  18]\n",
      " [  4 483  11]\n",
      " [ 15  10 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       508\n",
      "           1       0.97      0.97      0.97       498\n",
      "           2       0.95      0.95      0.95       525\n",
      "\n",
      "    accuracy                           0.96      1531\n",
      "   macro avg       0.96      0.96      0.96      1531\n",
      "weighted avg       0.96      0.96      0.96      1531\n",
      "\n",
      "[[462   9  37]\n",
      " [  8 464  26]\n",
      " [ 30  29 466]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       508\n",
      "           1       0.92      0.93      0.93       498\n",
      "           2       0.88      0.89      0.88       525\n",
      "\n",
      "    accuracy                           0.91      1531\n",
      "   macro avg       0.91      0.91      0.91      1531\n",
      "weighted avg       0.91      0.91      0.91      1531\n",
      "\n",
      "[[445  12  51]\n",
      " [ 16 441  41]\n",
      " [ 40  46 439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       508\n",
      "           1       0.88      0.89      0.88       498\n",
      "           2       0.83      0.84      0.83       525\n",
      "\n",
      "    accuracy                           0.87      1531\n",
      "   macro avg       0.87      0.87      0.87      1531\n",
      "weighted avg       0.87      0.87      0.87      1531\n",
      "\n",
      "[[427  17  64]\n",
      " [ 19 432  47]\n",
      " [ 49  54 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       508\n",
      "           1       0.86      0.87      0.86       498\n",
      "           2       0.79      0.80      0.80       525\n",
      "\n",
      "    accuracy                           0.84      1531\n",
      "   macro avg       0.84      0.84      0.84      1531\n",
      "weighted avg       0.84      0.84      0.84      1531\n",
      "\n",
      "[[414  20  74]\n",
      " [ 22 423  53]\n",
      " [ 52  61 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       508\n",
      "           1       0.84      0.85      0.84       498\n",
      "           2       0.76      0.78      0.77       525\n",
      "\n",
      "    accuracy                           0.82      1531\n",
      "   macro avg       0.82      0.82      0.82      1531\n",
      "weighted avg       0.82      0.82      0.82      1531\n",
      "\n",
      "[[388  26  94]\n",
      " [ 32 404  62]\n",
      " [ 61  72 392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78       508\n",
      "           1       0.80      0.81      0.81       498\n",
      "           2       0.72      0.75      0.73       525\n",
      "\n",
      "    accuracy                           0.77      1531\n",
      "   macro avg       0.78      0.77      0.77      1531\n",
      "weighted avg       0.77      0.77      0.77      1531\n",
      "\n",
      "[[487   3  18]\n",
      " [  4 483  11]\n",
      " [ 15  10 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       508\n",
      "           1       0.97      0.97      0.97       498\n",
      "           2       0.95      0.95      0.95       525\n",
      "\n",
      "    accuracy                           0.96      1531\n",
      "   macro avg       0.96      0.96      0.96      1531\n",
      "weighted avg       0.96      0.96      0.96      1531\n",
      "\n",
      "[[508   0   0]\n",
      " [  1 497   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n",
      "[[508   0   0]\n",
      " [  1 497   0]\n",
      " [  0   0 525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       498\n",
      "           2       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1531\n",
      "   macro avg       1.00      1.00      1.00      1531\n",
      "weighted avg       1.00      1.00      1.00      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "train_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "train_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a188ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  8 18]\n",
      " [15 74 18]\n",
      " [13 27 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       109\n",
      "           1       0.68      0.69      0.69       107\n",
      "           2       0.67      0.64      0.65       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.70      0.70      0.70       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n",
      "[[83  8 18]\n",
      " [15 74 18]\n",
      " [13 27 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       109\n",
      "           1       0.68      0.69      0.69       107\n",
      "           2       0.67      0.64      0.65       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.70      0.70      0.70       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n",
      "[[83  8 18]\n",
      " [15 74 18]\n",
      " [13 27 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       109\n",
      "           1       0.68      0.69      0.69       107\n",
      "           2       0.67      0.64      0.65       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.70      0.70      0.70       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n",
      "[[86  6 17]\n",
      " [15 74 18]\n",
      " [11 23 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       109\n",
      "           1       0.72      0.69      0.70       107\n",
      "           2       0.69      0.70      0.69       112\n",
      "\n",
      "    accuracy                           0.73       328\n",
      "   macro avg       0.73      0.73      0.73       328\n",
      "weighted avg       0.73      0.73      0.73       328\n",
      "\n",
      "[[83  6 20]\n",
      " [13 75 19]\n",
      " [ 8 19 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       109\n",
      "           1       0.75      0.70      0.72       107\n",
      "           2       0.69      0.76      0.72       112\n",
      "\n",
      "    accuracy                           0.74       328\n",
      "   macro avg       0.74      0.74      0.74       328\n",
      "weighted avg       0.74      0.74      0.74       328\n",
      "\n",
      "[[84  5 20]\n",
      " [13 76 18]\n",
      " [ 7 17 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       109\n",
      "           1       0.78      0.71      0.74       107\n",
      "           2       0.70      0.79      0.74       112\n",
      "\n",
      "    accuracy                           0.76       328\n",
      "   macro avg       0.76      0.76      0.76       328\n",
      "weighted avg       0.76      0.76      0.76       328\n",
      "\n",
      "[[84  5 20]\n",
      " [12 77 18]\n",
      " [10 14 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       109\n",
      "           1       0.80      0.72      0.76       107\n",
      "           2       0.70      0.79      0.74       112\n",
      "\n",
      "    accuracy                           0.76       328\n",
      "   macro avg       0.76      0.76      0.76       328\n",
      "weighted avg       0.76      0.76      0.76       328\n",
      "\n",
      "[[81  4 24]\n",
      " [13 75 19]\n",
      " [14 12 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       109\n",
      "           1       0.82      0.70      0.76       107\n",
      "           2       0.67      0.77      0.71       112\n",
      "\n",
      "    accuracy                           0.74       328\n",
      "   macro avg       0.75      0.74      0.74       328\n",
      "weighted avg       0.75      0.74      0.74       328\n",
      "\n",
      "[[83  8 18]\n",
      " [15 74 18]\n",
      " [13 27 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       109\n",
      "           1       0.68      0.69      0.69       107\n",
      "           2       0.67      0.64      0.65       112\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.70      0.70      0.70       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n",
      "[[65 22 22]\n",
      " [54 35 18]\n",
      " [44 29 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.60      0.48       109\n",
      "           1       0.41      0.33      0.36       107\n",
      "           2       0.49      0.35      0.41       112\n",
      "\n",
      "    accuracy                           0.42       328\n",
      "   macro avg       0.43      0.42      0.42       328\n",
      "weighted avg       0.43      0.42      0.42       328\n",
      "\n",
      "[[65 22 22]\n",
      " [54 35 18]\n",
      " [44 29 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.60      0.48       109\n",
      "           1       0.41      0.33      0.36       107\n",
      "           2       0.49      0.35      0.41       112\n",
      "\n",
      "    accuracy                           0.42       328\n",
      "   macro avg       0.43      0.42      0.42       328\n",
      "weighted avg       0.43      0.42      0.42       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train))        \n",
    "val_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "val_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "val_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d19c4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  6 20]\n",
      " [13 74 20]\n",
      " [22 22 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       109\n",
      "           1       0.73      0.69      0.71       107\n",
      "           2       0.63      0.61      0.62       113\n",
      "\n",
      "    accuracy                           0.69       329\n",
      "   macro avg       0.69      0.69      0.69       329\n",
      "weighted avg       0.69      0.69      0.69       329\n",
      "\n",
      "[[83  6 20]\n",
      " [13 74 20]\n",
      " [22 22 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       109\n",
      "           1       0.73      0.69      0.71       107\n",
      "           2       0.63      0.61      0.62       113\n",
      "\n",
      "    accuracy                           0.69       329\n",
      "   macro avg       0.69      0.69      0.69       329\n",
      "weighted avg       0.69      0.69      0.69       329\n",
      "\n",
      "[[83  6 20]\n",
      " [13 74 20]\n",
      " [22 22 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       109\n",
      "           1       0.73      0.69      0.71       107\n",
      "           2       0.63      0.61      0.62       113\n",
      "\n",
      "    accuracy                           0.69       329\n",
      "   macro avg       0.69      0.69      0.69       329\n",
      "weighted avg       0.69      0.69      0.69       329\n",
      "\n",
      "[[84  7 18]\n",
      " [12 75 20]\n",
      " [16 23 74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       109\n",
      "           1       0.71      0.70      0.71       107\n",
      "           2       0.66      0.65      0.66       113\n",
      "\n",
      "    accuracy                           0.71       329\n",
      "   macro avg       0.71      0.71      0.71       329\n",
      "weighted avg       0.71      0.71      0.71       329\n",
      "\n",
      "[[88  4 17]\n",
      " [ 7 80 20]\n",
      " [12 15 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       109\n",
      "           1       0.81      0.75      0.78       107\n",
      "           2       0.70      0.76      0.73       113\n",
      "\n",
      "    accuracy                           0.77       329\n",
      "   macro avg       0.78      0.77      0.77       329\n",
      "weighted avg       0.78      0.77      0.77       329\n",
      "\n",
      "[[89  3 17]\n",
      " [ 6 84 17]\n",
      " [14 16 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       109\n",
      "           1       0.82      0.79      0.80       107\n",
      "           2       0.71      0.73      0.72       113\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.78      0.78      0.78       329\n",
      "weighted avg       0.78      0.78      0.78       329\n",
      "\n",
      "[[91  3 15]\n",
      " [ 8 79 20]\n",
      " [16 13 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       109\n",
      "           1       0.83      0.74      0.78       107\n",
      "           2       0.71      0.74      0.72       113\n",
      "\n",
      "    accuracy                           0.77       329\n",
      "   macro avg       0.78      0.77      0.77       329\n",
      "weighted avg       0.78      0.77      0.77       329\n",
      "\n",
      "[[91  2 16]\n",
      " [11 77 19]\n",
      " [19  8 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       109\n",
      "           1       0.89      0.72      0.79       107\n",
      "           2       0.71      0.76      0.74       113\n",
      "\n",
      "    accuracy                           0.77       329\n",
      "   macro avg       0.78      0.77      0.77       329\n",
      "weighted avg       0.78      0.77      0.77       329\n",
      "\n",
      "[[83  6 20]\n",
      " [13 74 20]\n",
      " [22 22 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       109\n",
      "           1       0.73      0.69      0.71       107\n",
      "           2       0.63      0.61      0.62       113\n",
      "\n",
      "    accuracy                           0.69       329\n",
      "   macro avg       0.69      0.69      0.69       329\n",
      "weighted avg       0.69      0.69      0.69       329\n",
      "\n",
      "[[55 25 29]\n",
      " [45 36 26]\n",
      " [38 37 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.45       109\n",
      "           1       0.37      0.34      0.35       107\n",
      "           2       0.41      0.34      0.37       113\n",
      "\n",
      "    accuracy                           0.39       329\n",
      "   macro avg       0.39      0.39      0.39       329\n",
      "weighted avg       0.39      0.39      0.39       329\n",
      "\n",
      "[[55 25 29]\n",
      " [45 36 26]\n",
      " [38 37 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.45       109\n",
      "           1       0.37      0.34      0.35       107\n",
      "           2       0.41      0.34      0.37       113\n",
      "\n",
      "    accuracy                           0.39       329\n",
      "   macro avg       0.39      0.39      0.39       329\n",
      "weighted avg       0.39      0.39      0.39       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.1, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.3, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.7, solver='eigen',n_components=1    ).fit(x_train, y_train)) \n",
    "test_score(LinearDiscriminantAnalysis(shrinkage= 0.9, solver='eigen',n_components=1    ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen',n_components=2    ).fit(x_train, y_train))\n",
    "\n",
    "\n",
    "test_score(LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train))\n",
    "test_score(LinearDiscriminantAnalysis( solver='svd',n_components=2    ).fit(x_train, y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9363b54",
   "metadata": {},
   "source": [
    "## Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "340eeb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded category:rock successfully for train\n",
      "loaded category:paper successfully for train\n",
      "loaded category:scissors successfully for train\n"
     ]
    }
   ],
   "source": [
    "Categories=['rock','paper','scissors']\n",
    "self_test_dir = '/Users/hanyijia/Desktop/Midterm_Project/real'\n",
    "\n",
    "flat_data_arr=[] #input array\n",
    "target_arr=[] #output array\n",
    "for i in Categories:\n",
    "    path=os.path.join(self_test_dir,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(32,32,3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully for train')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data) #dataframe\n",
    "df['Target']=target\n",
    "self_test=df.iloc[:,:-1] #input data\n",
    "y_self_test=df.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a361b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 1]\n",
      " [3 2 0]\n",
      " [1 1 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.60      0.50         5\n",
      "           1       0.50      0.40      0.44         5\n",
      "           2       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.53      0.50      0.51        14\n",
      "weighted avg       0.52      0.50      0.50        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_self = LinearDiscriminantAnalysis(shrinkage= 0.5, solver='eigen',n_components=1    ).fit(x_train, y_train).predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self))\n",
    "print(classification_report(y_self_test, y_pred_self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69ab270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 2]\n",
      " [3 2 0]\n",
      " [1 1 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.60      0.50         5\n",
      "           1       0.67      0.40      0.50         5\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.53      0.50      0.50        14\n",
      "weighted avg       0.53      0.50      0.50        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_self2 = LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',n_components=1    ).fit(x_train, y_train).predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self2))\n",
    "print(classification_report(y_self_test, y_pred_self2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02fe7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 1]\n",
      " [1 2 2]\n",
      " [1 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.67      0.40      0.50         5\n",
      "           2       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.59      0.58      0.57        14\n",
      "weighted avg       0.60      0.57      0.56        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_self3 = LinearDiscriminantAnalysis( solver='svd',n_components=1   ).fit(x_train, y_train).predict(self_test)\n",
    "print(confusion_matrix(y_self_test, y_pred_self3))\n",
    "print(classification_report(y_self_test, y_pred_self3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
